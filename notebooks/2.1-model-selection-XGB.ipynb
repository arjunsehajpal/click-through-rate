{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjun/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/arjun/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/arjun/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/arjun/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/arjun/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/arjun/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# importing the libraries\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import roc_auc_score, make_scorer, matthews_corrcoef, f1_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the parameters\n",
    "\n",
    "root_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "pd.set_option(\"display.max_rows\", 16)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataframe, validation_ratio):\n",
    "    \"\"\"\n",
    "    randomly splits the dataset into train and valid sets\n",
    "    \n",
    "    input: dataframe, validation ratio (the %age of data to feed into the )\n",
    "    output: trainset and validset\n",
    "    \"\"\"\n",
    "    num_train = len(dataframe)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(validation_ratio*num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_df, valid_df = dataframe.iloc[train_idx], dataframe.iloc[valid_idx]\n",
    "    return train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_of_evidence(target_df, predictor_df, categorical_col, min_percentage):\n",
    "    \"\"\"\n",
    "    calculates weight of evidence for the said column\n",
    "    \n",
    "    inp: target_df (dataframe of the variable to be predicted)\n",
    "         predictor_df (dataframe of the independent variables)\n",
    "         categorical_column (column to be WoE encoded)\n",
    "         min_percentage you want to take into consideration. Classes less than this proportion won't be considered\n",
    "    outp: transformed predicted_df[col], dict containing WoE.\n",
    "    \"\"\"\n",
    "    # creating new dataframe with groupby-agg clause. We will calculate the positives (i.e. events) of every class\n",
    "    woe_df = target_df.groupby(predictor_df[categorical_col]).agg([\"sum\", \"count\"]).rename({\"sum\": \"positives\"}, axis = 1)\n",
    "    \n",
    "    woe_df[\"negatives\"] = woe_df[\"count\"] - woe_df[\"positives\"]                      # calculating negatives (i.e. non-events)\n",
    "    woe_df[[\"positives\", \"negatives\"]] /= woe_df[[\"positives\", \"negatives\"]].sum()   # normalize\n",
    "    min_fraction = min_percentage / 100                                              # converting to fraction\n",
    "    \n",
    "    # checking classes with proportion less than min_percentage, or ones who have positives or negatives equal to zero\n",
    "    undefined = (woe_df[\"count\"]/len(predictor_df) < min_fraction) | (woe_df[\"positives\"] == 0) | (woe_df[\"negatives\"] == 0)\n",
    "    # replacing undefined with -1\n",
    "    woe_df.loc[undefined, [\"positives\", \"negatives\"]] = -1\n",
    "    \n",
    "    # calculating weight of evidence\n",
    "    woe_df[\"woe_value\"] = np.log(woe_df[\"positives\"] / woe_df[\"negatives\"])\n",
    "    woe_df[\"info_value\"] = (woe_df[\"positives\"] - woe_df[\"negatives\"]) * woe_df[\"woe_value\"]\n",
    "    \n",
    "    # calculate total information_value\n",
    "    total_iv = sum(woe_df[\"info_value\"])\n",
    "    print(\"Information value of the {} is = {}\".format(categorical_col, total_iv))\n",
    "    \n",
    "    # convert the woe_df into dictionary and map the changes to predictor column\n",
    "    woe_dict = woe_df[\"woe_value\"].to_dict()\n",
    "    predictor_df[categorical_col] = predictor_df[categorical_col].map(woe_dict)\n",
    "    \n",
    "    return predictor_df, woe_dict\n",
    "\n",
    "\n",
    "def woe_transform(test_df, categorical_column, encoder_dict):\n",
    "    \"\"\"\n",
    "    transforms the testset with WoE calculated from test set\n",
    "    \n",
    "    inp: test_df, \n",
    "         categorical_column to be encoded,\n",
    "         encoder_dict created from categorical column in trainset\n",
    "    outp: test_df mapped with woe values\n",
    "    \"\"\"\n",
    "    test_df[categorical_column] = test_df[categorical_column].map(encoder_dict)\n",
    "    \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(object_to_be_saved, path):\n",
    "    \"\"\"\n",
    "    saves the object as pickle at the defined path\n",
    "    \n",
    "    inp: object to be saved,\n",
    "         path\n",
    "    returns: None\n",
    "    \"\"\"\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(object_to_be_saved, f)\n",
    "\n",
    "def load_pickle(path):\n",
    "    \"\"\"\n",
    "    saves the object as pickle at the defined path\n",
    "    \n",
    "    inp: path\n",
    "    returns: pickle_object\n",
    "    \"\"\"\n",
    "    with open(path, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing the data for Machine Learning Model\n",
    "With the aggregation of data behind us, we still need to work on the data in order to feed the data to the Machine Learning model, so it can train on the data in the best way possible. One transformation that is required is the **Scaling** of the data, as most algorithms, like Deep Neural Nets, works considerably better when fed with scaled data. Other Machine Learning models like XGBoost are immune to scaling. So, scaling has no effect on XGBoost. \n",
    "\n",
    "Only continuous columns go through scaling. For categorical columns, we face other challenges. Foremost of these challenges is the high cardinality. For instance, the `app_code` column has 477 different values, which gives a very high cardinality to that particular column. To deal with this, we will use **Weight of Evidence**. In the weight of evidence algorithm, total number of records with the positive and negative class labels are also taken into account. For class imbalanced data, this algorithm works better. The advantages of using Weight of evidence are:-\n",
    "- Handles missing values\n",
    "- Handles outliers\n",
    "- The transformation is based on logarithmic value of distributions. This is aligned with the logistic regression output function\n",
    "- No need for dummy variables\n",
    "- By using proper binning technique, it can establish monotonic relationship (either increase or decrease) between the independent and dependent variable\n",
    "\n",
    "For the categorical variables, with fewer classes, we will use OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impression_id</th>\n",
       "      <th>impression_time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>app_code</th>\n",
       "      <th>os_version</th>\n",
       "      <th>is_4G</th>\n",
       "      <th>is_click</th>\n",
       "      <th>diff_time_mean</th>\n",
       "      <th>diff_time_max</th>\n",
       "      <th>diff_time_min</th>\n",
       "      <th>count_unique_app</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>vc_app_code</th>\n",
       "      <th>vc_user_id</th>\n",
       "      <th>app_code_count_unique_user</th>\n",
       "      <th>click_count_user_mean</th>\n",
       "      <th>time_elapsed_user</th>\n",
       "      <th>click_count_app_mean</th>\n",
       "      <th>time_elapsed_app</th>\n",
       "      <th>inst_count</th>\n",
       "      <th>user_unique_sessions</th>\n",
       "      <th>user_unique_item_ids</th>\n",
       "      <th>user_unique_category_1</th>\n",
       "      <th>user_unique_category_2</th>\n",
       "      <th>user_unique_category_3</th>\n",
       "      <th>user_unique_product_type</th>\n",
       "      <th>user_item_id_mode</th>\n",
       "      <th>user_category_1_mode</th>\n",
       "      <th>user_category_2_mode</th>\n",
       "      <th>user_category_3_mode</th>\n",
       "      <th>user_product_type_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>c4ca4238a0b923820dcc509a6f75849b</td>\n",
       "      <td>2018-11-15 00:00:00</td>\n",
       "      <td>87862</td>\n",
       "      <td>422</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74670.000000</td>\n",
       "      <td>148200.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>395</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43886</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5622.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>c81e728d9d4c2f636f067f89cc14862c</td>\n",
       "      <td>2018-11-15 00:00:00</td>\n",
       "      <td>89464</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101901.818182</td>\n",
       "      <td>347520.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7050</td>\n",
       "      <td>23</td>\n",
       "      <td>2000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>226</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>132</td>\n",
       "      <td>38517</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>8028.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>eccbc87e4b5ce2fe28308fd9f2a7baf3</td>\n",
       "      <td>2018-11-15 00:00:00</td>\n",
       "      <td>58442</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68812.727273</td>\n",
       "      <td>165720.0</td>\n",
       "      <td>8400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10851</td>\n",
       "      <td>34</td>\n",
       "      <td>2039</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>73224</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>5164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>a87ff679a2f3e71d9181a67b7542122c</td>\n",
       "      <td>2018-11-15 00:00:00</td>\n",
       "      <td>4238</td>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9343</td>\n",
       "      <td>2</td>\n",
       "      <td>1819</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>109</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>37336</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>45c48cce2e2d7fbdea1afc51c7c6ad26</td>\n",
       "      <td>2018-11-15 00:01:00</td>\n",
       "      <td>63410</td>\n",
       "      <td>467</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45745.882353</td>\n",
       "      <td>167340.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>422</td>\n",
       "      <td>52</td>\n",
       "      <td>24</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>43209</td>\n",
       "      <td>4.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>577.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      impression_id      impression_time  user_id  app_code  \\\n",
       "0  c4ca4238a0b923820dcc509a6f75849b  2018-11-15 00:00:00    87862       422   \n",
       "1  c81e728d9d4c2f636f067f89cc14862c  2018-11-15 00:00:00    89464       129   \n",
       "2  eccbc87e4b5ce2fe28308fd9f2a7baf3  2018-11-15 00:00:00    58442       127   \n",
       "3  a87ff679a2f3e71d9181a67b7542122c  2018-11-15 00:00:00     4238       371   \n",
       "4  45c48cce2e2d7fbdea1afc51c7c6ad26  2018-11-15 00:01:00    63410       467   \n",
       "\n",
       "   os_version  is_4G  is_click  diff_time_mean  diff_time_max  diff_time_min  \\\n",
       "0           2      0         0    74670.000000       148200.0         1140.0   \n",
       "1           0      0         0   101901.818182       347520.0          180.0   \n",
       "2           1      0         0    68812.727273       165720.0         8400.0   \n",
       "3           1      0         0      540.000000          540.0          540.0   \n",
       "4           1      1         1    45745.882353       167340.0          360.0   \n",
       "\n",
       "   count_unique_app  hour  minute  vc_app_code  vc_user_id  \\\n",
       "0                 1     0       0          395           3   \n",
       "1                 1     0       0         7050          23   \n",
       "2                 1     0       0        10851          34   \n",
       "3                 1     0       0         9343           2   \n",
       "4                 2     0       1          422          52   \n",
       "\n",
       "   app_code_count_unique_user  click_count_user_mean  time_elapsed_user  \\\n",
       "0                          51                   -1.0               -1.0   \n",
       "1                        2000                   -1.0               -1.0   \n",
       "2                        2039                   -1.0               -1.0   \n",
       "3                        1819                   -1.0               -1.0   \n",
       "4                          24                   -1.0               -1.0   \n",
       "\n",
       "   click_count_app_mean  time_elapsed_app  inst_count  user_unique_sessions  \\\n",
       "0                  -1.0              -1.0           1                     1   \n",
       "1                  -1.0              -1.0         226                    40   \n",
       "2                  -1.0              -1.0          32                    15   \n",
       "3                  -1.0              -1.0         109                    30   \n",
       "4                  -1.0              -1.0           7                     5   \n",
       "\n",
       "   user_unique_item_ids  user_unique_category_1  user_unique_category_2  \\\n",
       "0                     1                       1                       1   \n",
       "1                   150                      15                      50   \n",
       "2                    12                       8                      10   \n",
       "3                    52                      12                      28   \n",
       "4                     3                       2                       2   \n",
       "\n",
       "   user_unique_category_3  user_unique_product_type  user_item_id_mode  \\\n",
       "0                       1                         1              43886   \n",
       "1                      90                       132              38517   \n",
       "2                      10                        12              73224   \n",
       "3                      40                        50              37336   \n",
       "4                       2                         3              43209   \n",
       "\n",
       "   user_category_1_mode  user_category_2_mode  user_category_3_mode  \\\n",
       "0                  11.0                  35.0                  20.0   \n",
       "1                  17.0                   9.0                  62.0   \n",
       "2                   1.0                  64.0                 263.0   \n",
       "3                  17.0                   8.0                  84.0   \n",
       "4                   4.0                  74.0                 292.0   \n",
       "\n",
       "   user_product_type_mode  \n",
       "0                  5622.0  \n",
       "1                  8028.0  \n",
       "2                  5164.0  \n",
       "3                   231.0  \n",
       "4                   577.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the dataset\n",
    "df = pd.read_csv(os.path.join(root_dir, \"data\", \"processed_data\", \"train_aggdf.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train_df = (190088, 32)\n",
      "shape of test_df = (47521, 32)\n",
      "----------\n",
      "Shape of x_train = (190088, 27) ... y_train = (190088,)\n",
      "Shape of x_test = (47521, 27) ... y_test = (47521,)\n"
     ]
    }
   ],
   "source": [
    "# spliting the dataset\n",
    "train_df, test_df = train_test_split(df, validation_ratio = 0.2)\n",
    "\n",
    "print(\"shape of train_df = {}\".format(train_df.shape))\n",
    "print(\"shape of test_df = {}\".format(test_df.shape))\n",
    "\n",
    "# define predictors and targets in trainset and testset\n",
    "x_train, y_train = train_df.drop(columns = [\"impression_id\", \"user_id\", \"impression_time\", \"is_click\", \"minute\"]), train_df[\"is_click\"]\n",
    "x_test, y_test = test_df.drop(columns = [\"impression_id\", \"user_id\", \"impression_time\", \"is_click\", \"minute\"]), test_df[\"is_click\"]\n",
    "\n",
    "print(\"-\"*10)\n",
    "print(\"Shape of x_train = {} ... y_train = {}\".format(x_train.shape, y_train.shape))\n",
    "print(\"Shape of x_test = {} ... y_test = {}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Encoding the Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>app_code</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>os_version</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>is_4G</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count_unique_app</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    s\n",
       "app_code          473\n",
       "os_version          3\n",
       "is_4G               2\n",
       "count_unique_app    9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = [\"app_code\", \"os_version\", \"is_4G\", \"count_unique_app\"]\n",
    "pd.DataFrame({\"s\": x_train[categorical_columns].nunique()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, it is pretty much clear that the predictor ``app_code`` and ``count_unique_app`` exhibits high cardinality. Because of this, we can't use techniques like one_hot_encoding, as it will give immense sparsity to the data and can't use LabelEncoding, as it will encode the values in ordinal manner, which might give unneccessary high weight to some classes. One of the techniques, we can use here is the Weigh of Evidence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information value of the app_code is = 0.5864970132974534\n",
      "Information value of the count_unique_app is = 0.005958498119950649\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "####### Calculating Weight of Evidence ##########\n",
    "#################################################\n",
    "\n",
    "x_train, app_code_dict = weight_of_evidence(y_train, x_train, categorical_col = \"app_code\", min_percentage = 0.01)\n",
    "x_train, count_unique_app_dict = weight_of_evidence(y_train, x_train, categorical_col = \"count_unique_app\", min_percentage = 0.01)\n",
    "\n",
    "save_pickle(app_code_dict, os.path.join(root_dir, \"models\", \"app_code_dict.pkl\"))\n",
    "save_pickle(count_unique_app_dict, os.path.join(root_dir, \"models\", \"count_unique_app_dict.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Scaling the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_code</th>\n",
       "      <th>os_version</th>\n",
       "      <th>is_4G</th>\n",
       "      <th>diff_time_mean</th>\n",
       "      <th>diff_time_max</th>\n",
       "      <th>diff_time_min</th>\n",
       "      <th>count_unique_app</th>\n",
       "      <th>hour</th>\n",
       "      <th>vc_app_code</th>\n",
       "      <th>vc_user_id</th>\n",
       "      <th>app_code_count_unique_user</th>\n",
       "      <th>click_count_user_mean</th>\n",
       "      <th>time_elapsed_user</th>\n",
       "      <th>click_count_app_mean</th>\n",
       "      <th>time_elapsed_app</th>\n",
       "      <th>inst_count</th>\n",
       "      <th>user_unique_sessions</th>\n",
       "      <th>user_unique_item_ids</th>\n",
       "      <th>user_unique_category_1</th>\n",
       "      <th>user_unique_category_2</th>\n",
       "      <th>user_unique_category_3</th>\n",
       "      <th>user_unique_product_type</th>\n",
       "      <th>user_item_id_mode</th>\n",
       "      <th>user_category_1_mode</th>\n",
       "      <th>user_category_2_mode</th>\n",
       "      <th>user_category_3_mode</th>\n",
       "      <th>user_product_type_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.215721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.057993</td>\n",
       "      <td>0.145555</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.761696</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.012414</td>\n",
       "      <td>0.506831</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.016657</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.015038</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.500030</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.461988</td>\n",
       "      <td>0.492298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.083904</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041284</td>\n",
       "      <td>0.152407</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.908781</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.052362</td>\n",
       "      <td>0.504106</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.005639</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.077739</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.307018</td>\n",
       "      <td>0.278329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.491206</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.516175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520342</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.908727</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.339181</td>\n",
       "      <td>0.310746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.083904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.908781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504865</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.009398</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.030488</td>\n",
       "      <td>0.012077</td>\n",
       "      <td>0.171406</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.102339</td>\n",
       "      <td>0.570078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.738952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.014088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.045951</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.182927</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.856725</td>\n",
       "      <td>0.050562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_code  os_version  is_4G  diff_time_mean  diff_time_max  diff_time_min  \\\n",
       "0  0.215721         0.0    1.0        0.057993       0.145555       0.012288   \n",
       "1  0.083904         0.5    0.0        0.041284       0.152407       0.001517   \n",
       "2  0.491206         0.5    0.0        0.000000       0.000000       0.000000   \n",
       "3  0.083904         0.0    1.0        0.000000       0.000000       0.000000   \n",
       "4  0.738952         0.0    1.0        0.000000       0.000000       0.000000   \n",
       "\n",
       "   count_unique_app      hour  vc_app_code  vc_user_id  \\\n",
       "0               1.0  0.956522     1.000000    0.222222   \n",
       "1               1.0  0.391304     0.908781    0.194444   \n",
       "2               1.0  0.913043     0.516175    0.000000   \n",
       "3               1.0  0.956522     0.908781    0.000000   \n",
       "4               1.0  0.826087     0.014088    0.000000   \n",
       "\n",
       "   app_code_count_unique_user  click_count_user_mean  time_elapsed_user  \\\n",
       "0                    0.761696                    0.5           0.012414   \n",
       "1                    1.000000                    0.5           0.052362   \n",
       "2                    0.195613                    0.0           0.000000   \n",
       "3                    1.000000                    0.0           0.000000   \n",
       "4                    0.015707                    0.0           0.000000   \n",
       "\n",
       "   click_count_app_mean  time_elapsed_app  inst_count  user_unique_sessions  \\\n",
       "0              0.506831          0.000027    0.016657              0.028571   \n",
       "1              0.504106          0.000027    0.001723              0.010714   \n",
       "2              0.520342          0.000027    0.004021              0.010714   \n",
       "3              0.504865          0.000027    0.004021              0.014286   \n",
       "4              0.560606          0.000080    0.045951              0.114286   \n",
       "\n",
       "   user_unique_item_ids  user_unique_category_1  user_unique_category_2  \\\n",
       "0              0.015038                0.400000                0.104478   \n",
       "1              0.005639                0.200000                0.044776   \n",
       "2              0.007519                0.200000                0.044776   \n",
       "3              0.009398                0.333333                0.074627   \n",
       "4              0.071429                0.866667                0.328358   \n",
       "\n",
       "   user_unique_category_3  user_unique_product_type  user_item_id_mode  \\\n",
       "0                0.048780                  0.019324           0.500030   \n",
       "1                0.018293                  0.007246           0.077739   \n",
       "2                0.018293                  0.009662           0.908727   \n",
       "3                0.030488                  0.012077           0.171406   \n",
       "4                0.182927                  0.086957           0.459459   \n",
       "\n",
       "   user_category_1_mode  user_category_2_mode  user_category_3_mode  \\\n",
       "0              0.111111                0.5375              0.461988   \n",
       "1              0.500000                0.2750              0.307018   \n",
       "2              0.111111                0.5375              0.339181   \n",
       "3              0.777778                0.6625              0.102339   \n",
       "4              0.277778                0.9375              0.856725   \n",
       "\n",
       "   user_product_type_mode  \n",
       "0                0.492298  \n",
       "1                0.278329  \n",
       "2                0.310746  \n",
       "3                0.570078  \n",
       "4                0.050562  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################\n",
    "############## Scaling the data #####################\n",
    "#####################################################\n",
    "\n",
    "# define the scaler\n",
    "scaler = MinMaxScaler()\n",
    "train_scaler = scaler.fit(x_train)\n",
    "\n",
    "# data columns\n",
    "cols = x_train.columns\n",
    "\n",
    "# save scaler object\n",
    "save_pickle(train_scaler, os.path.join(root_dir, \"models\", \"train_scaler.pkl\"))\n",
    "\n",
    "x_train_scaled = train_scaler.transform(x_train)\n",
    "\n",
    "# scaled dataset would be of type ndarray. Converting it back to Pandas\n",
    "x_train_scaled = pd.DataFrame(x_train_scaled)\n",
    "x_train_scaled.columns = cols\n",
    "\n",
    "x_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_code</th>\n",
       "      <th>os_version</th>\n",
       "      <th>is_4G</th>\n",
       "      <th>diff_time_mean</th>\n",
       "      <th>diff_time_max</th>\n",
       "      <th>diff_time_min</th>\n",
       "      <th>count_unique_app</th>\n",
       "      <th>hour</th>\n",
       "      <th>vc_app_code</th>\n",
       "      <th>vc_user_id</th>\n",
       "      <th>app_code_count_unique_user</th>\n",
       "      <th>click_count_user_mean</th>\n",
       "      <th>time_elapsed_user</th>\n",
       "      <th>click_count_app_mean</th>\n",
       "      <th>time_elapsed_app</th>\n",
       "      <th>inst_count</th>\n",
       "      <th>user_unique_sessions</th>\n",
       "      <th>user_unique_item_ids</th>\n",
       "      <th>user_unique_category_1</th>\n",
       "      <th>user_unique_category_2</th>\n",
       "      <th>user_unique_category_3</th>\n",
       "      <th>user_unique_product_type</th>\n",
       "      <th>user_item_id_mode</th>\n",
       "      <th>user_category_1_mode</th>\n",
       "      <th>user_category_2_mode</th>\n",
       "      <th>user_category_3_mode</th>\n",
       "      <th>user_product_type_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>153870</td>\n",
       "      <td>-1.188047</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>137625.000000</td>\n",
       "      <td>345420.0</td>\n",
       "      <td>29160.0</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>22</td>\n",
       "      <td>33788</td>\n",
       "      <td>17</td>\n",
       "      <td>13579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29460.0</td>\n",
       "      <td>0.013662</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>66430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>5208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172124</td>\n",
       "      <td>-1.722591</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97971.428571</td>\n",
       "      <td>361680.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>9</td>\n",
       "      <td>30706</td>\n",
       "      <td>15</td>\n",
       "      <td>17827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124260.0</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10327</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2944.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141277</td>\n",
       "      <td>-0.070893</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>21</td>\n",
       "      <td>17441</td>\n",
       "      <td>1</td>\n",
       "      <td>3488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.040684</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>120727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>3287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87612</td>\n",
       "      <td>-1.722591</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>22</td>\n",
       "      <td>30706</td>\n",
       "      <td>1</td>\n",
       "      <td>17827</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.009731</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22771</td>\n",
       "      <td>13.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6031.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41157</td>\n",
       "      <td>0.933767</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>19</td>\n",
       "      <td>477</td>\n",
       "      <td>1</td>\n",
       "      <td>281</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>61040</td>\n",
       "      <td>4.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>534.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        app_code  os_version  is_4G  diff_time_mean  diff_time_max  \\\n",
       "153870 -1.188047           0      1   137625.000000       345420.0   \n",
       "172124 -1.722591           1      0    97971.428571       361680.0   \n",
       "141277 -0.070893           1      0        0.000000            0.0   \n",
       "87612  -1.722591           0      1        0.000000            0.0   \n",
       "41157   0.933767           0      1        0.000000            0.0   \n",
       "\n",
       "        diff_time_min  count_unique_app  hour  vc_app_code  vc_user_id  \\\n",
       "153870        29160.0          0.017299    22        33788          17   \n",
       "172124         3600.0          0.017299     9        30706          15   \n",
       "141277            0.0          0.017299    21        17441           1   \n",
       "87612             0.0          0.017299    22        30706           1   \n",
       "41157             0.0          0.017299    19          477           1   \n",
       "\n",
       "        app_code_count_unique_user  click_count_user_mean  time_elapsed_user  \\\n",
       "153870                       13579                    0.0            29460.0   \n",
       "172124                       17827                    0.0           124260.0   \n",
       "141277                        3488                   -1.0               -1.0   \n",
       "87612                        17827                   -1.0               -1.0   \n",
       "41157                          281                   -1.0               -1.0   \n",
       "\n",
       "        click_count_app_mean  time_elapsed_app  inst_count  \\\n",
       "153870              0.013662              60.0          29   \n",
       "172124              0.008211              60.0           3   \n",
       "141277              0.040684              60.0           7   \n",
       "87612               0.009731              60.0           7   \n",
       "41157               0.121212             180.0          80   \n",
       "\n",
       "        user_unique_sessions  user_unique_item_ids  user_unique_category_1  \\\n",
       "153870                     8                     8                       6   \n",
       "172124                     3                     3                       3   \n",
       "141277                     3                     4                       3   \n",
       "87612                      4                     5                       5   \n",
       "41157                     32                    38                      13   \n",
       "\n",
       "        user_unique_category_2  user_unique_category_3  \\\n",
       "153870                       7                       8   \n",
       "172124                       3                       3   \n",
       "141277                       3                       3   \n",
       "87612                        5                       5   \n",
       "41157                       22                      30   \n",
       "\n",
       "        user_unique_product_type  user_item_id_mode  user_category_1_mode  \\\n",
       "153870                         8              66430                   1.0   \n",
       "172124                         3              10327                   8.0   \n",
       "141277                         4             120727                   1.0   \n",
       "87612                          5              22771                  13.0   \n",
       "41157                         36              61040                   4.0   \n",
       "\n",
       "        user_category_2_mode  user_category_3_mode  user_product_type_mode  \n",
       "153870                  42.0                 157.0                  5208.0  \n",
       "172124                  21.0                 104.0                  2944.0  \n",
       "141277                  42.0                 115.0                  3287.0  \n",
       "87612                   52.0                  34.0                  6031.0  \n",
       "41157                   74.0                 292.0                   534.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Machine Learning Models\n",
    "### 2.1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_eval(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    custom eval metric for XGBClassifier\n",
    "    \"\"\"\n",
    "    err = 1 - f1_score(y_true, np.round(y_pred))\n",
    "    return \"f1_err\", err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(params):\n",
    "    \"\"\"\n",
    "    hypertunes a XGBoost model\n",
    "    \n",
    "    inp: parameters\n",
    "    outp: score per fold\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"max_depth\": int(params[\"max_depth\"]),                              # max depth of the tree\n",
    "        \"gamma\": \"{:.3f}\".format(params[\"gamma\"]),                          # min loss reduction required to make a split\n",
    "        \"subsample\": \"{:.2f}\".format(params[\"subsample\"]),                  # denotes the fraction of observations to be randomly samples for each tree\n",
    "        \"reg_alpha\": \"{:.3f}\".format(params[\"reg_alpha\"]),                  # L1 regularization weight\n",
    "        \"reg_lambda\": \"{:.3f}\".format(params[\"reg_lambda\"]),                # L2 regularization weight\n",
    "        \"learning_rate\": \"{:.3f}\".format(params[\"learning_rate\"]),          # learning rate of XGB\n",
    "        \"num_leaves\": \"{:.3f}\".format(params[\"num_leaves\"]),                 \n",
    "        \"colsample_bytree\": \"{:.3f}\".format(params[\"colsample_bytree\"]),\n",
    "        \"min_child_samples\": \"{:.3f}\".format(params[\"min_child_samples\"]),\n",
    "        \"feature_fraction\": \"{:.3f}\".format(params[\"feature_fraction\"]),\n",
    "        \"bagging_fraction\": \"{:.3f}\".format(params[\"bagging_fraction\"]),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"scale_pos_weight\": 20,                                             # sum(negative instances) / sum(positive instances)\n",
    "        #\"f_eval\": f1_eval,\n",
    "        \"eval_metric\": \"error\"\n",
    "    }\n",
    "    \n",
    "    print(\"#\"*25)\n",
    "    print(\"Params = {}\".format(params))\n",
    "    FOLDS = 10  # defining the folds required\n",
    "    count = 1   # count of HPT cycles\n",
    "    skf = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = 42)\n",
    "    y_oof = np.zeros(x_train.shape[0])\n",
    "    ROC_mean = 0\n",
    "    for trn_idx, val_idx in skf.split(x_train, y_train):\n",
    "        # define the classifier\n",
    "        clf = xgb.XGBClassifier(random_state = 42, \n",
    "                                verbose = True, \n",
    "                                tree_method = \"gpu_hist\",\n",
    "                                **params)\n",
    "        # spliting data into train and valid sets\n",
    "        train_x, valid_x = x_train.iloc[trn_idx], x_train.iloc[val_idx]\n",
    "        train_y, valid_y = y_train.iloc[trn_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        # fit the estimator and predict\n",
    "        clf.fit(train_x, train_y)\n",
    "        pred = clf.predict(valid_x)\n",
    "        # eval metrics\n",
    "        score_ROC = make_scorer(roc_auc_score, needs_proba = True)(clf, valid_x, valid_y)\n",
    "        score_F1 = f1_score(valid_y.values, pred, average = \"binary\")\n",
    "        score_MCC = matthews_corrcoef(valid_y.values, pred)\n",
    "        ROC_mean += score_ROC\n",
    "        print(\"Count = {} ... score_ROC = {:.4f} ... score_F1 = {:.4f} ... score_MCC = {:.4f}\".format(count, score_ROC, score_F1, score_MCC))\n",
    "        count += 1\n",
    "    \n",
    "    gc.collect()\n",
    "    print(\"Mean ROC_AUC = {:.4}\".format(ROC_mean / FOLDS))\n",
    "    del train_x, valid_x, train_y, valid_y, clf, score_ROC\n",
    "    \n",
    "    return -(ROC_mean/FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    \"max_depth\": hp.quniform(\"max_depth\", 6, 8, 1),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0.01, 0.05),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0.01, 0.05),\n",
    "    \"learning_rate\": hp.uniform(\"learning_rate\", 0.001, 0.2),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.3, 0.9),\n",
    "    \"gamma\": hp.uniform(\"gamma\", 0.01, 0.7),\n",
    "    \"num_leaves\": hp.choice(\"num_leaves\", list(range(20, 250, 10))),\n",
    "    \"min_child_samples\": hp.choice(\"min_child_samples\", list(range(100, 250, 10))),\n",
    "    \"subsample\": hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.4, .8),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, .9)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################                           \n",
      "Params = {'max_depth': 7, 'gamma': '0.512', 'subsample': '0.80', 'reg_alpha': '0.049', 'reg_lambda': '0.038', 'learning_rate': '0.016', 'num_leaves': '140.000', 'colsample_bytree': '0.741', 'min_child_samples': '200.000', 'feature_fraction': '0.605', 'bagging_fraction': '0.776', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7365 ... score_F1 = 0.1573 ... score_MCC = 0.1549\n",
      "Count = 2 ... score_ROC = 0.7446 ... score_F1 = 0.1590 ... score_MCC = 0.1591\n",
      "Count = 3 ... score_ROC = 0.7372 ... score_F1 = 0.1560 ... score_MCC = 0.1531\n",
      "Count = 4 ... score_ROC = 0.7288 ... score_F1 = 0.1512 ... score_MCC = 0.1428\n",
      "Count = 5 ... score_ROC = 0.7433 ... score_F1 = 0.1578 ... score_MCC = 0.1554\n",
      "Count = 6 ... score_ROC = 0.7360 ... score_F1 = 0.1575 ... score_MCC = 0.1542\n",
      "Count = 7 ... score_ROC = 0.7361 ... score_F1 = 0.1555 ... score_MCC = 0.1512\n",
      "Count = 8 ... score_ROC = 0.7303 ... score_F1 = 0.1525 ... score_MCC = 0.1458\n",
      "Count = 9 ... score_ROC = 0.7323 ... score_F1 = 0.1544 ... score_MCC = 0.1493\n",
      "Count = 10 ... score_ROC = 0.7316 ... score_F1 = 0.1504 ... score_MCC = 0.1417\n",
      "Mean ROC_AUC = 0.7357                               \n",
      "#########################                                                   \n",
      "Params = {'max_depth': 6, 'gamma': '0.055', 'subsample': '0.20', 'reg_alpha': '0.046', 'reg_lambda': '0.045', 'learning_rate': '0.187', 'num_leaves': '40.000', 'colsample_bytree': '0.535', 'min_child_samples': '160.000', 'feature_fraction': '0.592', 'bagging_fraction': '0.529', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6889 ... score_F1 = 0.1465 ... score_MCC = 0.1217\n",
      "Count = 2 ... score_ROC = 0.6995 ... score_F1 = 0.1522 ... score_MCC = 0.1315\n",
      "Count = 3 ... score_ROC = 0.7034 ... score_F1 = 0.1512 ... score_MCC = 0.1307\n",
      "Count = 4 ... score_ROC = 0.6878 ... score_F1 = 0.1448 ... score_MCC = 0.1200\n",
      "Count = 5 ... score_ROC = 0.6918 ... score_F1 = 0.1490 ... score_MCC = 0.1257\n",
      "Count = 6 ... score_ROC = 0.6982 ... score_F1 = 0.1509 ... score_MCC = 0.1308\n",
      "Count = 7 ... score_ROC = 0.7003 ... score_F1 = 0.1478 ... score_MCC = 0.1239\n",
      "Count = 8 ... score_ROC = 0.6853 ... score_F1 = 0.1434 ... score_MCC = 0.1155\n",
      "Count = 9 ... score_ROC = 0.6954 ... score_F1 = 0.1472 ... score_MCC = 0.1210\n",
      "Count = 10 ... score_ROC = 0.6889 ... score_F1 = 0.1410 ... score_MCC = 0.1116\n",
      "Mean ROC_AUC = 0.6939                                                       \n",
      "#########################                                                   \n",
      "Params = {'max_depth': 7, 'gamma': '0.508', 'subsample': '0.60', 'reg_alpha': '0.017', 'reg_lambda': '0.043', 'learning_rate': '0.027', 'num_leaves': '110.000', 'colsample_bytree': '0.638', 'min_child_samples': '230.000', 'feature_fraction': '0.730', 'bagging_fraction': '0.402', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7356 ... score_F1 = 0.1586 ... score_MCC = 0.1546\n",
      "Count = 2 ... score_ROC = 0.7435 ... score_F1 = 0.1602 ... score_MCC = 0.1580\n",
      "Count = 3 ... score_ROC = 0.7389 ... score_F1 = 0.1576 ... score_MCC = 0.1536\n",
      "Count = 4 ... score_ROC = 0.7250 ... score_F1 = 0.1514 ... score_MCC = 0.1398\n",
      "Count = 5 ... score_ROC = 0.7428 ... score_F1 = 0.1595 ... score_MCC = 0.1552\n",
      "Count = 6 ... score_ROC = 0.7362 ... score_F1 = 0.1563 ... score_MCC = 0.1501\n",
      "Count = 7 ... score_ROC = 0.7349 ... score_F1 = 0.1588 ... score_MCC = 0.1542\n",
      "Count = 8 ... score_ROC = 0.7303 ... score_F1 = 0.1566 ... score_MCC = 0.1513\n",
      "Count = 9 ... score_ROC = 0.7302 ... score_F1 = 0.1545 ... score_MCC = 0.1470\n",
      "Count = 10 ... score_ROC = 0.7279 ... score_F1 = 0.1515 ... score_MCC = 0.1419\n",
      "Mean ROC_AUC = 0.7345                                                       \n",
      "#########################                                                   \n",
      "Params = {'max_depth': 6, 'gamma': '0.452', 'subsample': '0.80', 'reg_alpha': '0.011', 'reg_lambda': '0.019', 'learning_rate': '0.015', 'num_leaves': '50.000', 'colsample_bytree': '0.748', 'min_child_samples': '170.000', 'feature_fraction': '0.538', 'bagging_fraction': '0.756', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7373 ... score_F1 = 0.1568 ... score_MCC = 0.1556\n",
      "Count = 2 ... score_ROC = 0.7454 ... score_F1 = 0.1584 ... score_MCC = 0.1602\n",
      "Count = 3 ... score_ROC = 0.7364 ... score_F1 = 0.1535 ... score_MCC = 0.1504\n",
      "Count = 4 ... score_ROC = 0.7301 ... score_F1 = 0.1492 ... score_MCC = 0.1410\n",
      "Count = 5 ... score_ROC = 0.7445 ... score_F1 = 0.1587 ... score_MCC = 0.1596\n",
      "Count = 6 ... score_ROC = 0.7383 ... score_F1 = 0.1563 ... score_MCC = 0.1535\n",
      "Count = 7 ... score_ROC = 0.7360 ... score_F1 = 0.1569 ... score_MCC = 0.1566\n",
      "Count = 8 ... score_ROC = 0.7322 ... score_F1 = 0.1537 ... score_MCC = 0.1506\n",
      "Count = 9 ... score_ROC = 0.7317 ... score_F1 = 0.1516 ... score_MCC = 0.1459\n",
      "Count = 10 ... score_ROC = 0.7304 ... score_F1 = 0.1507 ... score_MCC = 0.1444\n",
      "Mean ROC_AUC = 0.7362                                                       \n",
      "#########################                                                   \n",
      "Params = {'max_depth': 7, 'gamma': '0.166', 'subsample': '0.60', 'reg_alpha': '0.044', 'reg_lambda': '0.036', 'learning_rate': '0.049', 'num_leaves': '50.000', 'colsample_bytree': '0.504', 'min_child_samples': '210.000', 'feature_fraction': '0.690', 'bagging_fraction': '0.869', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7298 ... score_F1 = 0.1575 ... score_MCC = 0.1468\n",
      "Count = 2 ... score_ROC = 0.7388 ... score_F1 = 0.1638 ... score_MCC = 0.1605\n",
      "Count = 3 ... score_ROC = 0.7354 ... score_F1 = 0.1611 ... score_MCC = 0.1556\n",
      "Count = 4 ... score_ROC = 0.7241 ... score_F1 = 0.1531 ... score_MCC = 0.1386\n",
      "Count = 5 ... score_ROC = 0.7429 ... score_F1 = 0.1610 ... score_MCC = 0.1537\n",
      "Count = 6 ... score_ROC = 0.7369 ... score_F1 = 0.1575 ... score_MCC = 0.1474\n",
      "Count = 7 ... score_ROC = 0.7341 ... score_F1 = 0.1592 ... score_MCC = 0.1507\n",
      "Count = 8 ... score_ROC = 0.7270 ... score_F1 = 0.1567 ... score_MCC = 0.1458\n",
      "Count = 9 ... score_ROC = 0.7262 ... score_F1 = 0.1568 ... score_MCC = 0.1466\n",
      "Count = 10 ... score_ROC = 0.7267 ... score_F1 = 0.1534 ... score_MCC = 0.1405\n",
      "Mean ROC_AUC = 0.7322                                                       \n",
      "#########################                                                   \n",
      "Params = {'max_depth': 7, 'gamma': '0.441', 'subsample': '0.50', 'reg_alpha': '0.024', 'reg_lambda': '0.027', 'learning_rate': '0.150', 'num_leaves': '160.000', 'colsample_bytree': '0.781', 'min_child_samples': '200.000', 'feature_fraction': '0.770', 'bagging_fraction': '0.628', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7006 ... score_F1 = 0.1572 ... score_MCC = 0.1320\n",
      "Count = 2 ... score_ROC = 0.7115 ... score_F1 = 0.1547 ... score_MCC = 0.1282\n",
      "Count = 3 ... score_ROC = 0.7178 ... score_F1 = 0.1596 ... score_MCC = 0.1359\n",
      "Count = 4 ... score_ROC = 0.7003 ... score_F1 = 0.1567 ... score_MCC = 0.1318\n",
      "Count = 5 ... score_ROC = 0.7176 ... score_F1 = 0.1609 ... score_MCC = 0.1376\n",
      "Count = 6 ... score_ROC = 0.7069 ... score_F1 = 0.1553 ... score_MCC = 0.1289\n",
      "Count = 7 ... score_ROC = 0.7006 ... score_F1 = 0.1516 ... score_MCC = 0.1241\n",
      "Count = 8 ... score_ROC = 0.6953 ... score_F1 = 0.1521 ... score_MCC = 0.1227\n",
      "Count = 9 ... score_ROC = 0.7074 ... score_F1 = 0.1531 ... score_MCC = 0.1263\n",
      "Count = 10 ... score_ROC = 0.6911 ... score_F1 = 0.1449 ... score_MCC = 0.1123\n",
      "Mean ROC_AUC = 0.7049                                                       \n",
      "#########################                                                   \n",
      "Params = {'max_depth': 6, 'gamma': '0.018', 'subsample': '0.80', 'reg_alpha': '0.020', 'reg_lambda': '0.012', 'learning_rate': '0.118', 'num_leaves': '50.000', 'colsample_bytree': '0.700', 'min_child_samples': '130.000', 'feature_fraction': '0.698', 'bagging_fraction': '0.509', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7228 ... score_F1 = 0.1583 ... score_MCC = 0.1439\n",
      "Count = 2 ... score_ROC = 0.7354 ... score_F1 = 0.1623 ... score_MCC = 0.1536\n",
      "Count = 3 ... score_ROC = 0.7323 ... score_F1 = 0.1607 ... score_MCC = 0.1508\n",
      "Count = 4 ... score_ROC = 0.7230 ... score_F1 = 0.1565 ... score_MCC = 0.1420\n",
      "Count = 5 ... score_ROC = 0.7324 ... score_F1 = 0.1590 ... score_MCC = 0.1455\n",
      "Count = 6 ... score_ROC = 0.7353 ... score_F1 = 0.1618 ... score_MCC = 0.1496\n",
      "Count = 7 ... score_ROC = 0.7242 ... score_F1 = 0.1580 ... score_MCC = 0.1442\n",
      "Count = 8 ... score_ROC = 0.7198 ... score_F1 = 0.1578 ... score_MCC = 0.1426\n",
      "Count = 9 ... score_ROC = 0.7230 ... score_F1 = 0.1559 ... score_MCC = 0.1418\n",
      "Count = 10 ... score_ROC = 0.7247 ... score_F1 = 0.1549 ... score_MCC = 0.1406\n",
      "Mean ROC_AUC = 0.7273                                                       \n",
      "#########################                                                   \n",
      "Params = {'max_depth': 8, 'gamma': '0.627', 'subsample': '0.70', 'reg_alpha': '0.035', 'reg_lambda': '0.027', 'learning_rate': '0.102', 'num_leaves': '230.000', 'colsample_bytree': '0.317', 'min_child_samples': '100.000', 'feature_fraction': '0.729', 'bagging_fraction': '0.753', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7109 ... score_F1 = 0.1605 ... score_MCC = 0.1371\n",
      "Count = 2 ... score_ROC = 0.7209 ... score_F1 = 0.1617 ... score_MCC = 0.1379\n",
      "Count = 3 ... score_ROC = 0.7175 ... score_F1 = 0.1618 ... score_MCC = 0.1378\n",
      "Count = 4 ... score_ROC = 0.7058 ... score_F1 = 0.1581 ... score_MCC = 0.1314\n",
      "Count = 5 ... score_ROC = 0.7251 ... score_F1 = 0.1629 ... score_MCC = 0.1401\n",
      "Count = 6 ... score_ROC = 0.7164 ... score_F1 = 0.1590 ... score_MCC = 0.1331\n",
      "Count = 7 ... score_ROC = 0.7148 ... score_F1 = 0.1611 ... score_MCC = 0.1366\n",
      "Count = 8 ... score_ROC = 0.7090 ... score_F1 = 0.1598 ... score_MCC = 0.1340\n",
      "Count = 9 ... score_ROC = 0.7169 ... score_F1 = 0.1591 ... score_MCC = 0.1341\n",
      "Count = 10 ... score_ROC = 0.7178 ... score_F1 = 0.1572 ... score_MCC = 0.1321\n",
      "Mean ROC_AUC = 0.7155                                                       \n",
      "#########################                                                   \n",
      "Params = {'max_depth': 8, 'gamma': '0.290', 'subsample': '0.80', 'reg_alpha': '0.036', 'reg_lambda': '0.028', 'learning_rate': '0.077', 'num_leaves': '30.000', 'colsample_bytree': '0.637', 'min_child_samples': '190.000', 'feature_fraction': '0.799', 'bagging_fraction': '0.483', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7160 ... score_F1 = 0.1599 ... score_MCC = 0.1371\n",
      "Count = 2 ... score_ROC = 0.7290 ... score_F1 = 0.1656 ... score_MCC = 0.1484\n",
      "Count = 3 ... score_ROC = 0.7275 ... score_F1 = 0.1659 ... score_MCC = 0.1485\n",
      "Count = 4 ... score_ROC = 0.7132 ... score_F1 = 0.1544 ... score_MCC = 0.1288\n",
      "Count = 5 ... score_ROC = 0.7277 ... score_F1 = 0.1598 ... score_MCC = 0.1352\n",
      "Count = 6 ... score_ROC = 0.7214 ... score_F1 = 0.1620 ... score_MCC = 0.1400\n",
      "Count = 7 ... score_ROC = 0.7220 ... score_F1 = 0.1672 ... score_MCC = 0.1487\n",
      "Count = 8 ... score_ROC = 0.7129 ... score_F1 = 0.1637 ... score_MCC = 0.1433\n",
      "Count = 9 ... score_ROC = 0.7202 ... score_F1 = 0.1565 ... score_MCC = 0.1319\n",
      "Count = 10 ... score_ROC = 0.7163 ... score_F1 = 0.1555 ... score_MCC = 0.1320\n",
      "Mean ROC_AUC = 0.7206                                                       \n",
      "#########################                                                   \n",
      "Params = {'max_depth': 7, 'gamma': '0.694', 'subsample': '0.90', 'reg_alpha': '0.041', 'reg_lambda': '0.021', 'learning_rate': '0.031', 'num_leaves': '220.000', 'colsample_bytree': '0.441', 'min_child_samples': '230.000', 'feature_fraction': '0.594', 'bagging_fraction': '0.624', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7349 ... score_F1 = 0.1583 ... score_MCC = 0.1549\n",
      "Count = 2 ... score_ROC = 0.7433 ... score_F1 = 0.1582 ... score_MCC = 0.1551\n",
      "Count = 3 ... score_ROC = 0.7381 ... score_F1 = 0.1556 ... score_MCC = 0.1495\n",
      "Count = 4 ... score_ROC = 0.7256 ... score_F1 = 0.1506 ... score_MCC = 0.1389\n",
      "Count = 5 ... score_ROC = 0.7425 ... score_F1 = 0.1597 ... score_MCC = 0.1560\n",
      "Count = 6 ... score_ROC = 0.7390 ... score_F1 = 0.1571 ... score_MCC = 0.1510\n",
      "Count = 7 ... score_ROC = 0.7338 ... score_F1 = 0.1577 ... score_MCC = 0.1528\n",
      "Count = 8 ... score_ROC = 0.7302 ... score_F1 = 0.1543 ... score_MCC = 0.1470\n",
      "Count = 9 ... score_ROC = 0.7303 ... score_F1 = 0.1535 ... score_MCC = 0.1457\n",
      "Count = 10 ... score_ROC = 0.7293 ... score_F1 = 0.1535 ... score_MCC = 0.1460\n",
      "Mean ROC_AUC = 0.7347                                                       \n",
      "#########################                                                    \n",
      "Params = {'max_depth': 6, 'gamma': '0.651', 'subsample': '0.40', 'reg_alpha': '0.026', 'reg_lambda': '0.014', 'learning_rate': '0.029', 'num_leaves': '110.000', 'colsample_bytree': '0.685', 'min_child_samples': '100.000', 'feature_fraction': '0.613', 'bagging_fraction': '0.853', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7351 ... score_F1 = 0.1579 ... score_MCC = 0.1549\n",
      "Count = 2 ... score_ROC = 0.7465 ... score_F1 = 0.1600 ... score_MCC = 0.1601\n",
      "Count = 3 ... score_ROC = 0.7399 ... score_F1 = 0.1576 ... score_MCC = 0.1556\n",
      "Count = 4 ... score_ROC = 0.7293 ... score_F1 = 0.1494 ... score_MCC = 0.1376\n",
      "Count = 5 ... score_ROC = 0.7415 ... score_F1 = 0.1586 ... score_MCC = 0.1565\n",
      "Count = 6 ... score_ROC = 0.7380 ... score_F1 = 0.1581 ... score_MCC = 0.1551\n",
      "Count = 7 ... score_ROC = 0.7360 ... score_F1 = 0.1565 ... score_MCC = 0.1527\n",
      "Count = 8 ... score_ROC = 0.7299 ... score_F1 = 0.1548 ... score_MCC = 0.1495\n",
      "Count = 9 ... score_ROC = 0.7314 ... score_F1 = 0.1530 ... score_MCC = 0.1459\n",
      "Count = 10 ... score_ROC = 0.7275 ... score_F1 = 0.1476 ... score_MCC = 0.1354\n",
      "Mean ROC_AUC = 0.7355                                                        \n",
      "#########################                                                    \n",
      "Params = {'max_depth': 7, 'gamma': '0.433', 'subsample': '0.70', 'reg_alpha': '0.018', 'reg_lambda': '0.032', 'learning_rate': '0.052', 'num_leaves': '230.000', 'colsample_bytree': '0.380', 'min_child_samples': '190.000', 'feature_fraction': '0.630', 'bagging_fraction': '0.796', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7302 ... score_F1 = 0.1604 ... score_MCC = 0.1522\n",
      "Count = 2 ... score_ROC = 0.7420 ... score_F1 = 0.1616 ... score_MCC = 0.1566\n",
      "Count = 3 ... score_ROC = 0.7369 ... score_F1 = 0.1605 ... score_MCC = 0.1535\n",
      "Count = 4 ... score_ROC = 0.7241 ... score_F1 = 0.1559 ... score_MCC = 0.1446\n",
      "Count = 5 ... score_ROC = 0.7410 ... score_F1 = 0.1599 ... score_MCC = 0.1513\n",
      "Count = 6 ... score_ROC = 0.7344 ... score_F1 = 0.1591 ... score_MCC = 0.1489\n",
      "Count = 7 ... score_ROC = 0.7313 ... score_F1 = 0.1578 ... score_MCC = 0.1480\n",
      "Count = 8 ... score_ROC = 0.7249 ... score_F1 = 0.1557 ... score_MCC = 0.1440\n",
      "Count = 9 ... score_ROC = 0.7307 ... score_F1 = 0.1562 ... score_MCC = 0.1454\n",
      "Count = 10 ... score_ROC = 0.7268 ... score_F1 = 0.1526 ... score_MCC = 0.1393\n",
      "Mean ROC_AUC = 0.7322                                                        \n",
      "#########################                                                    \n",
      "Params = {'max_depth': 7, 'gamma': '0.269', 'subsample': '0.50', 'reg_alpha': '0.030', 'reg_lambda': '0.025', 'learning_rate': '0.020', 'num_leaves': '220.000', 'colsample_bytree': '0.656', 'min_child_samples': '150.000', 'feature_fraction': '0.783', 'bagging_fraction': '0.782', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7324 ... score_F1 = 0.1566 ... score_MCC = 0.1516\n",
      "Count = 2 ... score_ROC = 0.7433 ... score_F1 = 0.1601 ... score_MCC = 0.1593\n",
      "Count = 3 ... score_ROC = 0.7392 ... score_F1 = 0.1570 ... score_MCC = 0.1535\n",
      "Count = 4 ... score_ROC = 0.7245 ... score_F1 = 0.1495 ... score_MCC = 0.1368\n",
      "Count = 5 ... score_ROC = 0.7414 ... score_F1 = 0.1578 ... score_MCC = 0.1536\n",
      "Count = 6 ... score_ROC = 0.7363 ... score_F1 = 0.1560 ... score_MCC = 0.1501\n",
      "Count = 7 ... score_ROC = 0.7354 ... score_F1 = 0.1570 ... score_MCC = 0.1532\n",
      "Count = 8 ... score_ROC = 0.7283 ... score_F1 = 0.1543 ... score_MCC = 0.1482\n",
      "Count = 9 ... score_ROC = 0.7317 ... score_F1 = 0.1551 ... score_MCC = 0.1496\n",
      "Count = 10 ... score_ROC = 0.7284 ... score_F1 = 0.1493 ... score_MCC = 0.1380\n",
      "Mean ROC_AUC = 0.7341                                                        \n",
      "#########################                                                    \n",
      "Params = {'max_depth': 7, 'gamma': '0.087', 'subsample': '0.90', 'reg_alpha': '0.022', 'reg_lambda': '0.049', 'learning_rate': '0.104', 'num_leaves': '230.000', 'colsample_bytree': '0.787', 'min_child_samples': '210.000', 'feature_fraction': '0.465', 'bagging_fraction': '0.703', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7172 ... score_F1 = 0.1588 ... score_MCC = 0.1389\n",
      "Count = 2 ... score_ROC = 0.7351 ... score_F1 = 0.1647 ... score_MCC = 0.1499\n",
      "Count = 3 ... score_ROC = 0.7318 ... score_F1 = 0.1672 ... score_MCC = 0.1537\n",
      "Count = 4 ... score_ROC = 0.7159 ... score_F1 = 0.1541 ... score_MCC = 0.1314\n",
      "Count = 5 ... score_ROC = 0.7292 ... score_F1 = 0.1623 ... score_MCC = 0.1450\n",
      "Count = 6 ... score_ROC = 0.7301 ... score_F1 = 0.1624 ... score_MCC = 0.1447\n",
      "Count = 7 ... score_ROC = 0.7253 ... score_F1 = 0.1608 ... score_MCC = 0.1420\n",
      "Count = 8 ... score_ROC = 0.7152 ... score_F1 = 0.1558 ... score_MCC = 0.1333\n",
      "Count = 9 ... score_ROC = 0.7211 ... score_F1 = 0.1576 ... score_MCC = 0.1382\n",
      "Count = 10 ... score_ROC = 0.7229 ... score_F1 = 0.1605 ... score_MCC = 0.1437\n",
      "Mean ROC_AUC = 0.7244                                                        \n",
      "#########################                                                    \n",
      "Params = {'max_depth': 7, 'gamma': '0.023', 'subsample': '0.80', 'reg_alpha': '0.045', 'reg_lambda': '0.020', 'learning_rate': '0.122', 'num_leaves': '150.000', 'colsample_bytree': '0.324', 'min_child_samples': '160.000', 'feature_fraction': '0.649', 'bagging_fraction': '0.828', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7182 ... score_F1 = 0.1574 ... score_MCC = 0.1366\n",
      "Count = 2 ... score_ROC = 0.7296 ... score_F1 = 0.1632 ... score_MCC = 0.1462\n",
      "Count = 3 ... score_ROC = 0.7303 ... score_F1 = 0.1647 ... score_MCC = 0.1499\n",
      "Count = 4 ... score_ROC = 0.7122 ... score_F1 = 0.1556 ... score_MCC = 0.1337\n",
      "Count = 5 ... score_ROC = 0.7314 ... score_F1 = 0.1647 ... score_MCC = 0.1482\n",
      "Count = 6 ... score_ROC = 0.7275 ... score_F1 = 0.1626 ... score_MCC = 0.1445\n",
      "Count = 7 ... score_ROC = 0.7186 ... score_F1 = 0.1571 ... score_MCC = 0.1361\n",
      "Count = 8 ... score_ROC = 0.7198 ... score_F1 = 0.1608 ... score_MCC = 0.1412\n",
      "Count = 9 ... score_ROC = 0.7119 ... score_F1 = 0.1507 ... score_MCC = 0.1257\n",
      "Count = 10 ... score_ROC = 0.7212 ... score_F1 = 0.1544 ... score_MCC = 0.1328\n",
      "Mean ROC_AUC = 0.7221                                                        \n",
      "#########################                                                    \n",
      "Params = {'max_depth': 7, 'gamma': '0.328', 'subsample': '0.70', 'reg_alpha': '0.026', 'reg_lambda': '0.011', 'learning_rate': '0.146', 'num_leaves': '230.000', 'colsample_bytree': '0.605', 'min_child_samples': '200.000', 'feature_fraction': '0.450', 'bagging_fraction': '0.871', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7095 ... score_F1 = 0.1572 ... score_MCC = 0.1327\n",
      "Count = 2 ... score_ROC = 0.7199 ... score_F1 = 0.1652 ... score_MCC = 0.1451\n",
      "Count = 3 ... score_ROC = 0.7183 ... score_F1 = 0.1611 ... score_MCC = 0.1389\n",
      "Count = 4 ... score_ROC = 0.7107 ... score_F1 = 0.1602 ... score_MCC = 0.1362\n",
      "Count = 5 ... score_ROC = 0.7217 ... score_F1 = 0.1586 ... score_MCC = 0.1329\n",
      "Count = 6 ... score_ROC = 0.7177 ... score_F1 = 0.1611 ... score_MCC = 0.1372\n",
      "Count = 7 ... score_ROC = 0.7061 ... score_F1 = 0.1508 ... score_MCC = 0.1207\n",
      "Count = 8 ... score_ROC = 0.7104 ... score_F1 = 0.1634 ... score_MCC = 0.1415\n",
      "Count = 9 ... score_ROC = 0.7097 ... score_F1 = 0.1561 ... score_MCC = 0.1304\n",
      "Count = 10 ... score_ROC = 0.7097 ... score_F1 = 0.1505 ... score_MCC = 0.1214\n",
      "Mean ROC_AUC = 0.7134                                                        \n",
      "#########################                                                    \n",
      "Params = {'max_depth': 7, 'gamma': '0.145', 'subsample': '0.60', 'reg_alpha': '0.028', 'reg_lambda': '0.031', 'learning_rate': '0.019', 'num_leaves': '80.000', 'colsample_bytree': '0.433', 'min_child_samples': '190.000', 'feature_fraction': '0.499', 'bagging_fraction': '0.648', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7320 ... score_F1 = 0.1549 ... score_MCC = 0.1516\n",
      "Count = 2 ... score_ROC = 0.7428 ... score_F1 = 0.1569 ... score_MCC = 0.1554\n",
      "Count = 3 ... score_ROC = 0.7393 ... score_F1 = 0.1574 ... score_MCC = 0.1568\n",
      "Count = 4 ... score_ROC = 0.7243 ... score_F1 = 0.1523 ... score_MCC = 0.1449\n",
      "Count = 5 ... score_ROC = 0.7429 ... score_F1 = 0.1555 ... score_MCC = 0.1515\n",
      "Count = 6 ... score_ROC = 0.7363 ... score_F1 = 0.1545 ... score_MCC = 0.1488\n",
      "Count = 7 ... score_ROC = 0.7357 ... score_F1 = 0.1589 ... score_MCC = 0.1587\n",
      "Count = 8 ... score_ROC = 0.7320 ... score_F1 = 0.1542 ... score_MCC = 0.1501\n",
      "Count = 9 ... score_ROC = 0.7316 ... score_F1 = 0.1525 ... score_MCC = 0.1458\n",
      "Count = 10 ... score_ROC = 0.7275 ... score_F1 = 0.1496 ... score_MCC = 0.1409\n",
      "Mean ROC_AUC = 0.7344                                                        \n",
      "#########################                                                    \n",
      "Params = {'max_depth': 6, 'gamma': '0.205', 'subsample': '0.40', 'reg_alpha': '0.028', 'reg_lambda': '0.014', 'learning_rate': '0.107', 'num_leaves': '140.000', 'colsample_bytree': '0.334', 'min_child_samples': '220.000', 'feature_fraction': '0.667', 'bagging_fraction': '0.619', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7216 ... score_F1 = 0.1544 ... score_MCC = 0.1396\n",
      "Count = 2 ... score_ROC = 0.7337 ... score_F1 = 0.1591 ... score_MCC = 0.1489\n",
      "Count = 3 ... score_ROC = 0.7345 ... score_F1 = 0.1621 ... score_MCC = 0.1545\n",
      "Count = 4 ... score_ROC = 0.7192 ... score_F1 = 0.1560 ... score_MCC = 0.1417\n",
      "Count = 5 ... score_ROC = 0.7307 ... score_F1 = 0.1604 ... score_MCC = 0.1515\n",
      "Count = 6 ... score_ROC = 0.7292 ... score_F1 = 0.1555 ... score_MCC = 0.1421\n",
      "Count = 7 ... score_ROC = 0.7265 ... score_F1 = 0.1600 ... score_MCC = 0.1489\n",
      "Count = 8 ... score_ROC = 0.7221 ... score_F1 = 0.1592 ... score_MCC = 0.1502\n",
      "Count = 9 ... score_ROC = 0.7229 ... score_F1 = 0.1546 ... score_MCC = 0.1406\n",
      "Count = 10 ... score_ROC = 0.7206 ... score_F1 = 0.1532 ... score_MCC = 0.1389\n",
      "Mean ROC_AUC = 0.7261                                                        \n",
      "#########################                                                    \n",
      "Params = {'max_depth': 7, 'gamma': '0.260', 'subsample': '0.60', 'reg_alpha': '0.034', 'reg_lambda': '0.014', 'learning_rate': '0.051', 'num_leaves': '50.000', 'colsample_bytree': '0.591', 'min_child_samples': '200.000', 'feature_fraction': '0.754', 'bagging_fraction': '0.480', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7285 ... score_F1 = 0.1574 ... score_MCC = 0.1465\n",
      "Count = 2 ... score_ROC = 0.7394 ... score_F1 = 0.1611 ... score_MCC = 0.1545\n",
      "Count = 3 ... score_ROC = 0.7365 ... score_F1 = 0.1621 ... score_MCC = 0.1568\n",
      "Count = 4 ... score_ROC = 0.7238 ... score_F1 = 0.1503 ... score_MCC = 0.1337\n",
      "Count = 5 ... score_ROC = 0.7404 ... score_F1 = 0.1624 ... score_MCC = 0.1562\n",
      "Count = 6 ... score_ROC = 0.7390 ... score_F1 = 0.1598 ... score_MCC = 0.1511\n",
      "Count = 7 ... score_ROC = 0.7299 ... score_F1 = 0.1586 ... score_MCC = 0.1498\n",
      "Count = 8 ... score_ROC = 0.7237 ... score_F1 = 0.1571 ... score_MCC = 0.1466\n",
      "Count = 9 ... score_ROC = 0.7262 ... score_F1 = 0.1557 ... score_MCC = 0.1442\n",
      "Count = 10 ... score_ROC = 0.7271 ... score_F1 = 0.1529 ... score_MCC = 0.1396\n",
      "Mean ROC_AUC = 0.7314                                                        \n",
      "#########################                                                    \n",
      "Params = {'max_depth': 6, 'gamma': '0.036', 'subsample': '0.60', 'reg_alpha': '0.011', 'reg_lambda': '0.011', 'learning_rate': '0.012', 'num_leaves': '20.000', 'colsample_bytree': '0.508', 'min_child_samples': '180.000', 'feature_fraction': '0.476', 'bagging_fraction': '0.465', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7363 ... score_F1 = 0.1543 ... score_MCC = 0.1535\n",
      "Count = 2 ... score_ROC = 0.7441 ... score_F1 = 0.1562 ... score_MCC = 0.1580\n",
      "Count = 3 ... score_ROC = 0.7390 ... score_F1 = 0.1507 ... score_MCC = 0.1473\n",
      "Count = 4 ... score_ROC = 0.7275 ... score_F1 = 0.1503 ... score_MCC = 0.1438\n",
      "Count = 5 ... score_ROC = 0.7435 ... score_F1 = 0.1563 ... score_MCC = 0.1569\n",
      "Count = 6 ... score_ROC = 0.7375 ... score_F1 = 0.1544 ... score_MCC = 0.1516\n",
      "Count = 7 ... score_ROC = 0.7357 ... score_F1 = 0.1551 ... score_MCC = 0.1541\n",
      "Count = 8 ... score_ROC = 0.7307 ... score_F1 = 0.1496 ... score_MCC = 0.1442\n",
      "Count = 9 ... score_ROC = 0.7298 ... score_F1 = 0.1509 ... score_MCC = 0.1462\n",
      "Count = 10 ... score_ROC = 0.7279 ... score_F1 = 0.1482 ... score_MCC = 0.1412\n",
      "Mean ROC_AUC = 0.7352                                                        \n",
      "#########################                                                    \n",
      "Params = {'max_depth': 8, 'gamma': '0.392', 'subsample': '0.20', 'reg_alpha': '0.039', 'reg_lambda': '0.049', 'learning_rate': '0.194', 'num_leaves': '160.000', 'colsample_bytree': '0.899', 'min_child_samples': '110.000', 'feature_fraction': '0.553', 'bagging_fraction': '0.551', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6475 ... score_F1 = 0.1361 ... score_MCC = 0.0932\n",
      "Count = 2 ... score_ROC = 0.6584 ... score_F1 = 0.1442 ... score_MCC = 0.1079\n",
      "Count = 3 ... score_ROC = 0.6664 ... score_F1 = 0.1450 ... score_MCC = 0.1103\n",
      "Count = 4 ... score_ROC = 0.6446 ... score_F1 = 0.1386 ... score_MCC = 0.0968\n",
      "Count = 5 ... score_ROC = 0.6463 ... score_F1 = 0.1361 ... score_MCC = 0.0954\n",
      "Count = 6 ... score_ROC = 0.6458 ... score_F1 = 0.1379 ... score_MCC = 0.0964\n",
      "Count = 7 ... score_ROC = 0.6511 ... score_F1 = 0.1404 ... score_MCC = 0.1006\n",
      "Count = 8 ... score_ROC = 0.6285 ... score_F1 = 0.1305 ... score_MCC = 0.0855\n",
      "Count = 9 ... score_ROC = 0.6481 ... score_F1 = 0.1326 ... score_MCC = 0.0879\n",
      "Count = 10 ... score_ROC = 0.6569 ... score_F1 = 0.1405 ... score_MCC = 0.1033\n",
      "Mean ROC_AUC = 0.6494                                                        \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.366', 'subsample': '0.20', 'reg_alpha': '0.049', 'reg_lambda': '0.049', 'learning_rate': '0.187', 'num_leaves': '40.000', 'colsample_bytree': '0.896', 'min_child_samples': '110.000', 'feature_fraction': '0.406', 'bagging_fraction': '0.561', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6456 ... score_F1 = 0.1345 ... score_MCC = 0.0924 \n",
      "Count = 2 ... score_ROC = 0.6532 ... score_F1 = 0.1348 ... score_MCC = 0.0939 \n",
      "Count = 3 ... score_ROC = 0.6642 ... score_F1 = 0.1422 ... score_MCC = 0.1037 \n",
      "Count = 4 ... score_ROC = 0.6491 ... score_F1 = 0.1419 ... score_MCC = 0.1044 \n",
      "Count = 5 ... score_ROC = 0.6703 ... score_F1 = 0.1454 ... score_MCC = 0.1108 \n",
      "Count = 6 ... score_ROC = 0.6535 ... score_F1 = 0.1409 ... score_MCC = 0.1029 \n",
      "Count = 7 ... score_ROC = 0.6459 ... score_F1 = 0.1362 ... score_MCC = 0.0938 \n",
      "Count = 8 ... score_ROC = 0.6586 ... score_F1 = 0.1396 ... score_MCC = 0.0993 \n",
      "Count = 9 ... score_ROC = 0.6472 ... score_F1 = 0.1392 ... score_MCC = 0.0978 \n",
      "Count = 10 ... score_ROC = 0.6606 ... score_F1 = 0.1462 ... score_MCC = 0.1097\n",
      "Mean ROC_AUC = 0.6548                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.390', 'subsample': '0.20', 'reg_alpha': '0.040', 'reg_lambda': '0.048', 'learning_rate': '0.187', 'num_leaves': '180.000', 'colsample_bytree': '0.888', 'min_child_samples': '110.000', 'feature_fraction': '0.411', 'bagging_fraction': '0.568', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6426 ... score_F1 = 0.1333 ... score_MCC = 0.0898 \n",
      "Count = 2 ... score_ROC = 0.6509 ... score_F1 = 0.1352 ... score_MCC = 0.0929 \n",
      "Count = 3 ... score_ROC = 0.6729 ... score_F1 = 0.1471 ... score_MCC = 0.1119 \n",
      "Count = 4 ... score_ROC = 0.6474 ... score_F1 = 0.1379 ... score_MCC = 0.0984 \n",
      "Count = 5 ... score_ROC = 0.6677 ... score_F1 = 0.1417 ... score_MCC = 0.1047 \n",
      "Count = 6 ... score_ROC = 0.6537 ... score_F1 = 0.1402 ... score_MCC = 0.1005 \n",
      "Count = 7 ... score_ROC = 0.6344 ... score_F1 = 0.1229 ... score_MCC = 0.0724 \n",
      "Count = 8 ... score_ROC = 0.6558 ... score_F1 = 0.1403 ... score_MCC = 0.1002 \n",
      "Count = 9 ... score_ROC = 0.6463 ... score_F1 = 0.1346 ... score_MCC = 0.0919 \n",
      "Count = 10 ... score_ROC = 0.6450 ... score_F1 = 0.1369 ... score_MCC = 0.0940\n",
      "Mean ROC_AUC = 0.6517                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.569', 'subsample': '0.20', 'reg_alpha': '0.039', 'reg_lambda': '0.043', 'learning_rate': '0.198', 'num_leaves': '170.000', 'colsample_bytree': '0.899', 'min_child_samples': '110.000', 'feature_fraction': '0.401', 'bagging_fraction': '0.581', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6420 ... score_F1 = 0.1355 ... score_MCC = 0.0926 \n",
      "Count = 2 ... score_ROC = 0.6475 ... score_F1 = 0.1374 ... score_MCC = 0.0952 \n",
      "Count = 3 ... score_ROC = 0.6455 ... score_F1 = 0.1342 ... score_MCC = 0.0911 \n",
      "Count = 4 ... score_ROC = 0.6363 ... score_F1 = 0.1254 ... score_MCC = 0.0768 \n",
      "Count = 5 ... score_ROC = 0.6580 ... score_F1 = 0.1394 ... score_MCC = 0.1004 \n",
      "Count = 6 ... score_ROC = 0.6495 ... score_F1 = 0.1394 ... score_MCC = 0.0998 \n",
      "Count = 7 ... score_ROC = 0.6437 ... score_F1 = 0.1348 ... score_MCC = 0.0921 \n",
      "Count = 8 ... score_ROC = 0.6372 ... score_F1 = 0.1293 ... score_MCC = 0.0833 \n",
      "Count = 9 ... score_ROC = 0.6590 ... score_F1 = 0.1397 ... score_MCC = 0.1002 \n",
      "Count = 10 ... score_ROC = 0.6562 ... score_F1 = 0.1441 ... score_MCC = 0.1069\n",
      "Mean ROC_AUC = 0.6475                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.605', 'subsample': '0.20', 'reg_alpha': '0.039', 'reg_lambda': '0.042', 'learning_rate': '0.166', 'num_leaves': '170.000', 'colsample_bytree': '0.852', 'min_child_samples': '110.000', 'feature_fraction': '0.547', 'bagging_fraction': '0.687', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6488 ... score_F1 = 0.1319 ... score_MCC = 0.0873 \n",
      "Count = 2 ... score_ROC = 0.6668 ... score_F1 = 0.1425 ... score_MCC = 0.1044 \n",
      "Count = 3 ... score_ROC = 0.6757 ... score_F1 = 0.1463 ... score_MCC = 0.1121 \n",
      "Count = 4 ... score_ROC = 0.6640 ... score_F1 = 0.1391 ... score_MCC = 0.0998 \n",
      "Count = 5 ... score_ROC = 0.6699 ... score_F1 = 0.1377 ... score_MCC = 0.0980 \n",
      "Count = 6 ... score_ROC = 0.6722 ... score_F1 = 0.1449 ... score_MCC = 0.1097 \n",
      "Count = 7 ... score_ROC = 0.6646 ... score_F1 = 0.1459 ... score_MCC = 0.1085 \n",
      "Count = 8 ... score_ROC = 0.6555 ... score_F1 = 0.1409 ... score_MCC = 0.1019 \n",
      "Count = 9 ... score_ROC = 0.6636 ... score_F1 = 0.1358 ... score_MCC = 0.0931 \n",
      "Count = 10 ... score_ROC = 0.6610 ... score_F1 = 0.1417 ... score_MCC = 0.1037\n",
      "Mean ROC_AUC = 0.6642                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.542', 'subsample': '0.20', 'reg_alpha': '0.037', 'reg_lambda': '0.038', 'learning_rate': '0.198', 'num_leaves': '240.000', 'colsample_bytree': '0.843', 'min_child_samples': '120.000', 'feature_fraction': '0.556', 'bagging_fraction': '0.413', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6433 ... score_F1 = 0.1325 ... score_MCC = 0.0887 \n",
      "Count = 2 ... score_ROC = 0.6625 ... score_F1 = 0.1414 ... score_MCC = 0.1054 \n",
      "Count = 3 ... score_ROC = 0.6494 ... score_F1 = 0.1354 ... score_MCC = 0.0928 \n",
      "Count = 4 ... score_ROC = 0.6446 ... score_F1 = 0.1406 ... score_MCC = 0.1026 \n",
      "Count = 5 ... score_ROC = 0.6554 ... score_F1 = 0.1454 ... score_MCC = 0.1098 \n",
      "Count = 6 ... score_ROC = 0.6525 ... score_F1 = 0.1369 ... score_MCC = 0.0963 \n",
      "Count = 7 ... score_ROC = 0.6492 ... score_F1 = 0.1346 ... score_MCC = 0.0915 \n",
      "Count = 8 ... score_ROC = 0.6378 ... score_F1 = 0.1362 ... score_MCC = 0.0938 \n",
      "Count = 9 ... score_ROC = 0.6521 ... score_F1 = 0.1345 ... score_MCC = 0.0922 \n",
      "Count = 10 ... score_ROC = 0.6463 ... score_F1 = 0.1377 ... score_MCC = 0.0965\n",
      "Mean ROC_AUC = 0.6493                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.565', 'subsample': '0.20', 'reg_alpha': '0.037', 'reg_lambda': '0.037', 'learning_rate': '0.169', 'num_leaves': '130.000', 'colsample_bytree': '0.838', 'min_child_samples': '120.000', 'feature_fraction': '0.505', 'bagging_fraction': '0.413', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6466 ... score_F1 = 0.1335 ... score_MCC = 0.0890 \n",
      "Count = 2 ... score_ROC = 0.6604 ... score_F1 = 0.1468 ... score_MCC = 0.1100 \n",
      "Count = 3 ... score_ROC = 0.6675 ... score_F1 = 0.1418 ... score_MCC = 0.1021 \n",
      "Count = 4 ... score_ROC = 0.6583 ... score_F1 = 0.1372 ... score_MCC = 0.0967 \n",
      "Count = 5 ... score_ROC = 0.6635 ... score_F1 = 0.1387 ... score_MCC = 0.0994 \n",
      "Count = 6 ... score_ROC = 0.6614 ... score_F1 = 0.1470 ... score_MCC = 0.1119 \n",
      "Count = 7 ... score_ROC = 0.6580 ... score_F1 = 0.1396 ... score_MCC = 0.0990 \n",
      "Count = 8 ... score_ROC = 0.6466 ... score_F1 = 0.1339 ... score_MCC = 0.0908 \n",
      "Count = 9 ... score_ROC = 0.6564 ... score_F1 = 0.1410 ... score_MCC = 0.1019 \n",
      "Count = 10 ... score_ROC = 0.6672 ... score_F1 = 0.1435 ... score_MCC = 0.1062\n",
      "Mean ROC_AUC = 0.6586                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.532', 'subsample': '0.20', 'reg_alpha': '0.032', 'reg_lambda': '0.039', 'learning_rate': '0.166', 'num_leaves': '240.000', 'colsample_bytree': '0.835', 'min_child_samples': '120.000', 'feature_fraction': '0.438', 'bagging_fraction': '0.436', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6543 ... score_F1 = 0.1449 ... score_MCC = 0.1084 \n",
      "Count = 2 ... score_ROC = 0.6583 ... score_F1 = 0.1434 ... score_MCC = 0.1045 \n",
      "Count = 3 ... score_ROC = 0.6698 ... score_F1 = 0.1417 ... score_MCC = 0.1027 \n",
      "Count = 4 ... score_ROC = 0.6667 ... score_F1 = 0.1461 ... score_MCC = 0.1093 \n",
      "Count = 5 ... score_ROC = 0.6749 ... score_F1 = 0.1452 ... score_MCC = 0.1090 \n",
      "Count = 6 ... score_ROC = 0.6642 ... score_F1 = 0.1462 ... score_MCC = 0.1113 \n",
      "Count = 7 ... score_ROC = 0.6547 ... score_F1 = 0.1364 ... score_MCC = 0.0953 \n",
      "Count = 8 ... score_ROC = 0.6469 ... score_F1 = 0.1398 ... score_MCC = 0.1011 \n",
      "Count = 9 ... score_ROC = 0.6654 ... score_F1 = 0.1452 ... score_MCC = 0.1090 \n",
      "Count = 10 ... score_ROC = 0.6558 ... score_F1 = 0.1390 ... score_MCC = 0.0991\n",
      "Mean ROC_AUC = 0.6611                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.687', 'subsample': '0.20', 'reg_alpha': '0.046', 'reg_lambda': '0.035', 'learning_rate': '0.139', 'num_leaves': '170.000', 'colsample_bytree': '0.790', 'min_child_samples': '240.000', 'feature_fraction': '0.401', 'bagging_fraction': '0.700', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6689 ... score_F1 = 0.1452 ... score_MCC = 0.1087 \n",
      "Count = 2 ... score_ROC = 0.6743 ... score_F1 = 0.1443 ... score_MCC = 0.1091 \n",
      "Count = 3 ... score_ROC = 0.6840 ... score_F1 = 0.1466 ... score_MCC = 0.1119 \n",
      "Count = 4 ... score_ROC = 0.6794 ... score_F1 = 0.1535 ... score_MCC = 0.1230 \n",
      "Count = 5 ... score_ROC = 0.6884 ... score_F1 = 0.1512 ... score_MCC = 0.1187 \n",
      "Count = 6 ... score_ROC = 0.6748 ... score_F1 = 0.1463 ... score_MCC = 0.1125 \n",
      "Count = 7 ... score_ROC = 0.6707 ... score_F1 = 0.1410 ... score_MCC = 0.1028 \n",
      "Count = 8 ... score_ROC = 0.6631 ... score_F1 = 0.1442 ... score_MCC = 0.1061 \n",
      "Count = 9 ... score_ROC = 0.6703 ... score_F1 = 0.1394 ... score_MCC = 0.1009 \n",
      "Count = 10 ... score_ROC = 0.6691 ... score_F1 = 0.1443 ... score_MCC = 0.1088\n",
      "Mean ROC_AUC = 0.6743                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.497', 'subsample': '0.20', 'reg_alpha': '0.037', 'reg_lambda': '0.040', 'learning_rate': '0.075', 'num_leaves': '210.000', 'colsample_bytree': '0.727', 'min_child_samples': '140.000', 'feature_fraction': '0.574', 'bagging_fraction': '0.578', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6884 ... score_F1 = 0.1493 ... score_MCC = 0.1195 \n",
      "Count = 2 ... score_ROC = 0.7089 ... score_F1 = 0.1568 ... score_MCC = 0.1343 \n",
      "Count = 3 ... score_ROC = 0.7108 ... score_F1 = 0.1605 ... score_MCC = 0.1393 \n",
      "Count = 4 ... score_ROC = 0.7006 ... score_F1 = 0.1527 ... score_MCC = 0.1271 \n",
      "Count = 5 ... score_ROC = 0.7037 ... score_F1 = 0.1480 ... score_MCC = 0.1171 \n",
      "Count = 6 ... score_ROC = 0.7084 ... score_F1 = 0.1574 ... score_MCC = 0.1326 \n",
      "Count = 7 ... score_ROC = 0.6998 ... score_F1 = 0.1502 ... score_MCC = 0.1217 \n",
      "Count = 8 ... score_ROC = 0.7047 ... score_F1 = 0.1559 ... score_MCC = 0.1314 \n",
      "Count = 9 ... score_ROC = 0.7064 ... score_F1 = 0.1502 ... score_MCC = 0.1220 \n",
      "Count = 10 ... score_ROC = 0.6942 ... score_F1 = 0.1521 ... score_MCC = 0.1236\n",
      "Mean ROC_AUC = 0.7026                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.581', 'subsample': '0.50', 'reg_alpha': '0.032', 'reg_lambda': '0.044', 'learning_rate': '0.199', 'num_leaves': '100.000', 'colsample_bytree': '0.858', 'min_child_samples': '120.000', 'feature_fraction': '0.507', 'bagging_fraction': '0.449', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6689 ... score_F1 = 0.1543 ... score_MCC = 0.1177 \n",
      "Count = 2 ... score_ROC = 0.6797 ... score_F1 = 0.1488 ... score_MCC = 0.1089 \n",
      "Count = 3 ... score_ROC = 0.6840 ... score_F1 = 0.1526 ... score_MCC = 0.1138 \n",
      "Count = 4 ... score_ROC = 0.6622 ... score_F1 = 0.1459 ... score_MCC = 0.1034 \n",
      "Count = 5 ... score_ROC = 0.6713 ... score_F1 = 0.1379 ... score_MCC = 0.0936 \n",
      "Count = 6 ... score_ROC = 0.6782 ... score_F1 = 0.1513 ... score_MCC = 0.1122 \n",
      "Count = 7 ... score_ROC = 0.6689 ... score_F1 = 0.1387 ... score_MCC = 0.0943 \n",
      "Count = 8 ... score_ROC = 0.6738 ... score_F1 = 0.1516 ... score_MCC = 0.1123 \n",
      "Count = 9 ... score_ROC = 0.6751 ... score_F1 = 0.1486 ... score_MCC = 0.1091 \n",
      "Count = 10 ... score_ROC = 0.6803 ... score_F1 = 0.1500 ... score_MCC = 0.1122\n",
      "Mean ROC_AUC = 0.6742                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.662', 'subsample': '0.40', 'reg_alpha': '0.050', 'reg_lambda': '0.033', 'learning_rate': '0.131', 'num_leaves': '120.000', 'colsample_bytree': '0.803', 'min_child_samples': '130.000', 'feature_fraction': '0.528', 'bagging_fraction': '0.525', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6952 ... score_F1 = 0.1598 ... score_MCC = 0.1311 \n",
      "Count = 2 ... score_ROC = 0.6962 ... score_F1 = 0.1544 ... score_MCC = 0.1230 \n",
      "Count = 3 ... score_ROC = 0.6944 ... score_F1 = 0.1544 ... score_MCC = 0.1223 \n",
      "Count = 4 ... score_ROC = 0.6924 ... score_F1 = 0.1515 ... score_MCC = 0.1202 \n",
      "Count = 5 ... score_ROC = 0.7013 ... score_F1 = 0.1591 ... score_MCC = 0.1296 \n",
      "Count = 6 ... score_ROC = 0.7045 ... score_F1 = 0.1653 ... score_MCC = 0.1409 \n",
      "Count = 7 ... score_ROC = 0.6879 ... score_F1 = 0.1503 ... score_MCC = 0.1170 \n",
      "Count = 8 ... score_ROC = 0.6803 ... score_F1 = 0.1469 ... score_MCC = 0.1115 \n",
      "Count = 9 ... score_ROC = 0.6938 ... score_F1 = 0.1487 ... score_MCC = 0.1143 \n",
      "Count = 10 ... score_ROC = 0.6885 ... score_F1 = 0.1493 ... score_MCC = 0.1161\n",
      "Mean ROC_AUC = 0.6934                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.488', 'subsample': '0.90', 'reg_alpha': '0.043', 'reg_lambda': '0.046', 'learning_rate': '0.177', 'num_leaves': '90.000', 'colsample_bytree': '0.755', 'min_child_samples': '170.000', 'feature_fraction': '0.435', 'bagging_fraction': '0.401', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6772 ... score_F1 = 0.1522 ... score_MCC = 0.1119 \n",
      "Count = 2 ... score_ROC = 0.7046 ... score_F1 = 0.1616 ... score_MCC = 0.1259 \n",
      "Count = 3 ... score_ROC = 0.7023 ... score_F1 = 0.1567 ... score_MCC = 0.1188 \n",
      "Count = 4 ... score_ROC = 0.6924 ... score_F1 = 0.1619 ... score_MCC = 0.1248 \n",
      "Count = 5 ... score_ROC = 0.7022 ... score_F1 = 0.1592 ... score_MCC = 0.1219 \n",
      "Count = 6 ... score_ROC = 0.6995 ... score_F1 = 0.1605 ... score_MCC = 0.1218 \n",
      "Count = 7 ... score_ROC = 0.6848 ... score_F1 = 0.1433 ... score_MCC = 0.0992 \n",
      "Count = 8 ... score_ROC = 0.6977 ... score_F1 = 0.1618 ... score_MCC = 0.1248 \n",
      "Count = 9 ... score_ROC = 0.6950 ... score_F1 = 0.1564 ... score_MCC = 0.1174 \n",
      "Count = 10 ... score_ROC = 0.6971 ... score_F1 = 0.1498 ... score_MCC = 0.1083\n",
      "Mean ROC_AUC = 0.6953                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.540', 'subsample': '0.20', 'reg_alpha': '0.046', 'reg_lambda': '0.046', 'learning_rate': '0.152', 'num_leaves': '240.000', 'colsample_bytree': '0.564', 'min_child_samples': '120.000', 'feature_fraction': '0.572', 'bagging_fraction': '0.597', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6642 ... score_F1 = 0.1445 ... score_MCC = 0.1078 \n",
      "Count = 2 ... score_ROC = 0.6805 ... score_F1 = 0.1539 ... score_MCC = 0.1257 \n",
      "Count = 3 ... score_ROC = 0.6735 ... score_F1 = 0.1446 ... score_MCC = 0.1098 \n",
      "Count = 4 ... score_ROC = 0.6644 ... score_F1 = 0.1378 ... score_MCC = 0.0983 \n",
      "Count = 5 ... score_ROC = 0.6669 ... score_F1 = 0.1364 ... score_MCC = 0.0971 \n",
      "Count = 6 ... score_ROC = 0.6722 ... score_F1 = 0.1472 ... score_MCC = 0.1128 \n",
      "Count = 7 ... score_ROC = 0.6744 ... score_F1 = 0.1481 ... score_MCC = 0.1140 \n",
      "Count = 8 ... score_ROC = 0.6717 ... score_F1 = 0.1529 ... score_MCC = 0.1229 \n",
      "Count = 9 ... score_ROC = 0.6645 ... score_F1 = 0.1422 ... score_MCC = 0.1048 \n",
      "Count = 10 ... score_ROC = 0.6564 ... score_F1 = 0.1357 ... score_MCC = 0.0938\n",
      "Mean ROC_AUC = 0.6689                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.457', 'subsample': '0.20', 'reg_alpha': '0.042', 'reg_lambda': '0.038', 'learning_rate': '0.080', 'num_leaves': '70.000', 'colsample_bytree': '0.883', 'min_child_samples': '180.000', 'feature_fraction': '0.480', 'bagging_fraction': '0.670', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6835 ... score_F1 = 0.1448 ... score_MCC = 0.1120 \n",
      "Count = 2 ... score_ROC = 0.7071 ... score_F1 = 0.1522 ... score_MCC = 0.1248 \n",
      "Count = 3 ... score_ROC = 0.7052 ... score_F1 = 0.1538 ... score_MCC = 0.1264 \n",
      "Count = 4 ... score_ROC = 0.6921 ... score_F1 = 0.1520 ... score_MCC = 0.1240 \n",
      "Count = 5 ... score_ROC = 0.7099 ... score_F1 = 0.1541 ... score_MCC = 0.1285 \n",
      "Count = 6 ... score_ROC = 0.6969 ... score_F1 = 0.1501 ... score_MCC = 0.1216 \n",
      "Count = 7 ... score_ROC = 0.6945 ... score_F1 = 0.1482 ... score_MCC = 0.1173 \n",
      "Count = 8 ... score_ROC = 0.6889 ... score_F1 = 0.1495 ... score_MCC = 0.1185 \n",
      "Count = 9 ... score_ROC = 0.7007 ... score_F1 = 0.1523 ... score_MCC = 0.1258 \n",
      "Count = 10 ... score_ROC = 0.6877 ... score_F1 = 0.1468 ... score_MCC = 0.1141\n",
      "Mean ROC_AUC = 0.6966                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.608', 'subsample': '0.20', 'reg_alpha': '0.037', 'reg_lambda': '0.041', 'learning_rate': '0.200', 'num_leaves': '190.000', 'colsample_bytree': '0.718', 'min_child_samples': '240.000', 'feature_fraction': '0.421', 'bagging_fraction': '0.519', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6494 ... score_F1 = 0.1386 ... score_MCC = 0.0973 \n",
      "Count = 2 ... score_ROC = 0.6445 ... score_F1 = 0.1340 ... score_MCC = 0.0898 \n",
      "Count = 3 ... score_ROC = 0.6645 ... score_F1 = 0.1400 ... score_MCC = 0.1007 \n",
      "Count = 4 ... score_ROC = 0.6551 ... score_F1 = 0.1408 ... score_MCC = 0.1010 \n",
      "Count = 5 ... score_ROC = 0.6489 ... score_F1 = 0.1335 ... score_MCC = 0.0911 \n",
      "Count = 6 ... score_ROC = 0.6486 ... score_F1 = 0.1435 ... score_MCC = 0.1055 \n",
      "Count = 7 ... score_ROC = 0.6365 ... score_F1 = 0.1335 ... score_MCC = 0.0893 \n",
      "Count = 8 ... score_ROC = 0.6584 ... score_F1 = 0.1391 ... score_MCC = 0.0974 \n",
      "Count = 9 ... score_ROC = 0.6564 ... score_F1 = 0.1365 ... score_MCC = 0.0949 \n",
      "Count = 10 ... score_ROC = 0.6395 ... score_F1 = 0.1322 ... score_MCC = 0.0896\n",
      "Mean ROC_AUC = 0.6502                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.557', 'subsample': '0.50', 'reg_alpha': '0.033', 'reg_lambda': '0.034', 'learning_rate': '0.176', 'num_leaves': '200.000', 'colsample_bytree': '0.817', 'min_child_samples': '140.000', 'feature_fraction': '0.704', 'bagging_fraction': '0.729', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6615 ... score_F1 = 0.1479 ... score_MCC = 0.1092 \n",
      "Count = 2 ... score_ROC = 0.6848 ... score_F1 = 0.1489 ... score_MCC = 0.1089 \n",
      "Count = 3 ... score_ROC = 0.6883 ... score_F1 = 0.1518 ... score_MCC = 0.1132 \n",
      "Count = 4 ... score_ROC = 0.6734 ... score_F1 = 0.1496 ... score_MCC = 0.1107 \n",
      "Count = 5 ... score_ROC = 0.6889 ... score_F1 = 0.1528 ... score_MCC = 0.1161 \n",
      "Count = 6 ... score_ROC = 0.6900 ... score_F1 = 0.1515 ... score_MCC = 0.1149 \n",
      "Count = 7 ... score_ROC = 0.6635 ... score_F1 = 0.1348 ... score_MCC = 0.0887 \n",
      "Count = 8 ... score_ROC = 0.6795 ... score_F1 = 0.1574 ... score_MCC = 0.1208 \n",
      "Count = 9 ... score_ROC = 0.6766 ... score_F1 = 0.1463 ... score_MCC = 0.1066 \n",
      "Count = 10 ... score_ROC = 0.6760 ... score_F1 = 0.1433 ... score_MCC = 0.1028\n",
      "Mean ROC_AUC = 0.6783                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.475', 'subsample': '0.70', 'reg_alpha': '0.030', 'reg_lambda': '0.044', 'learning_rate': '0.159', 'num_leaves': '170.000', 'colsample_bytree': '0.760', 'min_child_samples': '220.000', 'feature_fraction': '0.628', 'bagging_fraction': '0.899', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6875 ... score_F1 = 0.1518 ... score_MCC = 0.1128 \n",
      "Count = 2 ... score_ROC = 0.7019 ... score_F1 = 0.1607 ... score_MCC = 0.1266 \n",
      "Count = 3 ... score_ROC = 0.6869 ... score_F1 = 0.1486 ... score_MCC = 0.1084 \n",
      "Count = 4 ... score_ROC = 0.6931 ... score_F1 = 0.1608 ... score_MCC = 0.1254 \n",
      "Count = 5 ... score_ROC = 0.7017 ... score_F1 = 0.1557 ... score_MCC = 0.1189 \n",
      "Count = 6 ... score_ROC = 0.6998 ... score_F1 = 0.1603 ... score_MCC = 0.1250 \n",
      "Count = 7 ... score_ROC = 0.6912 ... score_F1 = 0.1553 ... score_MCC = 0.1174 \n",
      "Count = 8 ... score_ROC = 0.6906 ... score_F1 = 0.1597 ... score_MCC = 0.1246 \n",
      "Count = 9 ... score_ROC = 0.7023 ... score_F1 = 0.1637 ... score_MCC = 0.1301 \n",
      "Count = 10 ... score_ROC = 0.6970 ... score_F1 = 0.1600 ... score_MCC = 0.1254\n",
      "Mean ROC_AUC = 0.6952                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.648', 'subsample': '0.80', 'reg_alpha': '0.045', 'reg_lambda': '0.023', 'learning_rate': '0.089', 'num_leaves': '240.000', 'colsample_bytree': '0.671', 'min_child_samples': '150.000', 'feature_fraction': '0.525', 'bagging_fraction': '0.419', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7103 ... score_F1 = 0.1605 ... score_MCC = 0.1358 \n",
      "Count = 2 ... score_ROC = 0.7199 ... score_F1 = 0.1631 ... score_MCC = 0.1399 \n",
      "Count = 3 ... score_ROC = 0.7254 ... score_F1 = 0.1629 ... score_MCC = 0.1399 \n",
      "Count = 4 ... score_ROC = 0.7163 ... score_F1 = 0.1594 ... score_MCC = 0.1339 \n",
      "Count = 5 ... score_ROC = 0.7279 ... score_F1 = 0.1659 ... score_MCC = 0.1434 \n",
      "Count = 6 ... score_ROC = 0.7206 ... score_F1 = 0.1633 ... score_MCC = 0.1392 \n",
      "Count = 7 ... score_ROC = 0.7127 ... score_F1 = 0.1598 ... score_MCC = 0.1339 \n",
      "Count = 8 ... score_ROC = 0.7093 ... score_F1 = 0.1577 ... score_MCC = 0.1310 \n",
      "Count = 9 ... score_ROC = 0.7146 ... score_F1 = 0.1604 ... score_MCC = 0.1354 \n",
      "Count = 10 ... score_ROC = 0.7127 ... score_F1 = 0.1549 ... score_MCC = 0.1278\n",
      "Mean ROC_AUC = 0.717                                                          \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 6, 'gamma': '0.414', 'subsample': '0.90', 'reg_alpha': '0.024', 'reg_lambda': '0.029', 'learning_rate': '0.182', 'num_leaves': '60.000', 'colsample_bytree': '0.865', 'min_child_samples': '230.000', 'feature_fraction': '0.672', 'bagging_fraction': '0.494', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7106 ... score_F1 = 0.1589 ... score_MCC = 0.1400 \n",
      "Count = 2 ... score_ROC = 0.7295 ... score_F1 = 0.1635 ... score_MCC = 0.1484 \n",
      "Count = 3 ... score_ROC = 0.7254 ... score_F1 = 0.1629 ... score_MCC = 0.1469 \n",
      "Count = 4 ... score_ROC = 0.7150 ... score_F1 = 0.1569 ... score_MCC = 0.1370 \n",
      "Count = 5 ... score_ROC = 0.7232 ... score_F1 = 0.1595 ... score_MCC = 0.1395 \n",
      "Count = 6 ... score_ROC = 0.7194 ... score_F1 = 0.1617 ... score_MCC = 0.1435 \n",
      "Count = 7 ... score_ROC = 0.7242 ... score_F1 = 0.1600 ... score_MCC = 0.1422 \n",
      "Count = 8 ... score_ROC = 0.7136 ... score_F1 = 0.1598 ... score_MCC = 0.1420 \n",
      "Count = 9 ... score_ROC = 0.7151 ... score_F1 = 0.1537 ... score_MCC = 0.1304 \n",
      "Count = 10 ... score_ROC = 0.7184 ... score_F1 = 0.1547 ... score_MCC = 0.1333\n",
      "Mean ROC_AUC = 0.7194                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.697', 'subsample': '0.40', 'reg_alpha': '0.038', 'reg_lambda': '0.047', 'learning_rate': '0.134', 'num_leaves': '130.000', 'colsample_bytree': '0.709', 'min_child_samples': '160.000', 'feature_fraction': '0.729', 'bagging_fraction': '0.595', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6767 ... score_F1 = 0.1433 ... score_MCC = 0.1059 \n",
      "Count = 2 ... score_ROC = 0.6926 ... score_F1 = 0.1502 ... score_MCC = 0.1193 \n",
      "Count = 3 ... score_ROC = 0.6959 ... score_F1 = 0.1490 ... score_MCC = 0.1154 \n",
      "Count = 4 ... score_ROC = 0.6905 ... score_F1 = 0.1525 ... score_MCC = 0.1199 \n",
      "Count = 5 ... score_ROC = 0.7037 ... score_F1 = 0.1549 ... score_MCC = 0.1229 \n",
      "Count = 6 ... score_ROC = 0.6947 ... score_F1 = 0.1515 ... score_MCC = 0.1182 \n",
      "Count = 7 ... score_ROC = 0.6863 ... score_F1 = 0.1468 ... score_MCC = 0.1114 \n",
      "Count = 8 ... score_ROC = 0.6945 ... score_F1 = 0.1579 ... score_MCC = 0.1291 \n",
      "Count = 9 ... score_ROC = 0.6847 ... score_F1 = 0.1479 ... score_MCC = 0.1124 \n",
      "Count = 10 ... score_ROC = 0.6899 ... score_F1 = 0.1475 ... score_MCC = 0.1136\n",
      "Mean ROC_AUC = 0.6909                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 7, 'gamma': '0.522', 'subsample': '0.20', 'reg_alpha': '0.013', 'reg_lambda': '0.041', 'learning_rate': '0.117', 'num_leaves': '30.000', 'colsample_bytree': '0.613', 'min_child_samples': '210.000', 'feature_fraction': '0.564', 'bagging_fraction': '0.547', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6897 ... score_F1 = 0.1500 ... score_MCC = 0.1228 \n",
      "Count = 2 ... score_ROC = 0.7164 ... score_F1 = 0.1589 ... score_MCC = 0.1414 \n",
      "Count = 3 ... score_ROC = 0.7108 ... score_F1 = 0.1545 ... score_MCC = 0.1340 \n",
      "Count = 4 ... score_ROC = 0.6972 ... score_F1 = 0.1474 ... score_MCC = 0.1212 \n",
      "Count = 5 ... score_ROC = 0.6959 ... score_F1 = 0.1477 ... score_MCC = 0.1200 \n",
      "Count = 6 ... score_ROC = 0.6986 ... score_F1 = 0.1480 ... score_MCC = 0.1220 \n",
      "Count = 7 ... score_ROC = 0.6934 ... score_F1 = 0.1462 ... score_MCC = 0.1180 \n",
      "Count = 8 ... score_ROC = 0.6952 ... score_F1 = 0.1527 ... score_MCC = 0.1301 \n",
      "Count = 9 ... score_ROC = 0.7000 ... score_F1 = 0.1504 ... score_MCC = 0.1263 \n",
      "Count = 10 ... score_ROC = 0.6931 ... score_F1 = 0.1471 ... score_MCC = 0.1190\n",
      "Mean ROC_AUC = 0.699                                                          \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.584', 'subsample': '0.50', 'reg_alpha': '0.043', 'reg_lambda': '0.038', 'learning_rate': '0.200', 'num_leaves': '110.000', 'colsample_bytree': '0.537', 'min_child_samples': '170.000', 'feature_fraction': '0.605', 'bagging_fraction': '0.733', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6777 ... score_F1 = 0.1481 ... score_MCC = 0.1090 \n",
      "Count = 2 ... score_ROC = 0.6784 ... score_F1 = 0.1478 ... score_MCC = 0.1076 \n",
      "Count = 3 ... score_ROC = 0.6941 ... score_F1 = 0.1571 ... score_MCC = 0.1211 \n",
      "Count = 4 ... score_ROC = 0.6715 ... score_F1 = 0.1436 ... score_MCC = 0.1014 \n",
      "Count = 5 ... score_ROC = 0.6868 ... score_F1 = 0.1478 ... score_MCC = 0.1070 \n",
      "Count = 6 ... score_ROC = 0.6917 ... score_F1 = 0.1654 ... score_MCC = 0.1330 \n",
      "Count = 7 ... score_ROC = 0.6781 ... score_F1 = 0.1550 ... score_MCC = 0.1191 \n",
      "Count = 8 ... score_ROC = 0.6753 ... score_F1 = 0.1500 ... score_MCC = 0.1106 \n",
      "Count = 9 ... score_ROC = 0.6734 ... score_F1 = 0.1444 ... score_MCC = 0.1024 \n",
      "Count = 10 ... score_ROC = 0.6756 ... score_F1 = 0.1468 ... score_MCC = 0.1072\n",
      "Mean ROC_AUC = 0.6803                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 7, 'gamma': '0.326', 'subsample': '0.80', 'reg_alpha': '0.035', 'reg_lambda': '0.017', 'learning_rate': '0.066', 'num_leaves': '150.000', 'colsample_bytree': '0.765', 'min_child_samples': '100.000', 'feature_fraction': '0.462', 'bagging_fraction': '0.655', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7288 ... score_F1 = 0.1602 ... score_MCC = 0.1489 \n",
      "Count = 2 ... score_ROC = 0.7390 ... score_F1 = 0.1650 ... score_MCC = 0.1585 \n",
      "Count = 3 ... score_ROC = 0.7353 ... score_F1 = 0.1635 ... score_MCC = 0.1545 \n",
      "Count = 4 ... score_ROC = 0.7238 ... score_F1 = 0.1544 ... score_MCC = 0.1387 \n",
      "Count = 5 ... score_ROC = 0.7354 ... score_F1 = 0.1621 ... score_MCC = 0.1509 \n",
      "Count = 6 ... score_ROC = 0.7360 ... score_F1 = 0.1616 ... score_MCC = 0.1501 \n",
      "Count = 7 ... score_ROC = 0.7277 ... score_F1 = 0.1648 ... score_MCC = 0.1570 \n",
      "Count = 8 ... score_ROC = 0.7211 ... score_F1 = 0.1590 ... score_MCC = 0.1469 \n",
      "Count = 9 ... score_ROC = 0.7283 ... score_F1 = 0.1598 ... score_MCC = 0.1484 \n",
      "Count = 10 ... score_ROC = 0.7250 ... score_F1 = 0.1506 ... score_MCC = 0.1327\n",
      "Mean ROC_AUC = 0.73                                                           \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.430', 'subsample': '0.70', 'reg_alpha': '0.030', 'reg_lambda': '0.036', 'learning_rate': '0.158', 'num_leaves': '190.000', 'colsample_bytree': '0.816', 'min_child_samples': '130.000', 'feature_fraction': '0.491', 'bagging_fraction': '0.444', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6888 ... score_F1 = 0.1554 ... score_MCC = 0.1184 \n",
      "Count = 2 ... score_ROC = 0.7019 ... score_F1 = 0.1593 ... score_MCC = 0.1248 \n",
      "Count = 3 ... score_ROC = 0.7021 ... score_F1 = 0.1614 ... score_MCC = 0.1262 \n",
      "Count = 4 ... score_ROC = 0.6997 ... score_F1 = 0.1642 ... score_MCC = 0.1317 \n",
      "Count = 5 ... score_ROC = 0.7047 ... score_F1 = 0.1615 ... score_MCC = 0.1258 \n",
      "Count = 6 ... score_ROC = 0.6910 ... score_F1 = 0.1519 ... score_MCC = 0.1117 \n",
      "Count = 7 ... score_ROC = 0.6971 ... score_F1 = 0.1523 ... score_MCC = 0.1137 \n",
      "Count = 8 ... score_ROC = 0.6910 ... score_F1 = 0.1612 ... score_MCC = 0.1259 \n",
      "Count = 9 ... score_ROC = 0.6940 ... score_F1 = 0.1507 ... score_MCC = 0.1112 \n",
      "Count = 10 ... score_ROC = 0.6943 ... score_F1 = 0.1522 ... score_MCC = 0.1144\n",
      "Mean ROC_AUC = 0.6965                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 7, 'gamma': '0.659', 'subsample': '0.90', 'reg_alpha': '0.048', 'reg_lambda': '0.028', 'learning_rate': '0.003', 'num_leaves': '90.000', 'colsample_bytree': '0.685', 'min_child_samples': '110.000', 'feature_fraction': '0.586', 'bagging_fraction': '0.537', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7347 ... score_F1 = 0.1555 ... score_MCC = 0.1546 \n",
      "Count = 2 ... score_ROC = 0.7431 ... score_F1 = 0.1561 ... score_MCC = 0.1582 \n",
      "Count = 3 ... score_ROC = 0.7369 ... score_F1 = 0.1521 ... score_MCC = 0.1499 \n",
      "Count = 4 ... score_ROC = 0.7264 ... score_F1 = 0.1471 ... score_MCC = 0.1379 \n",
      "Count = 5 ... score_ROC = 0.7437 ... score_F1 = 0.1560 ... score_MCC = 0.1559 \n",
      "Count = 6 ... score_ROC = 0.7365 ... score_F1 = 0.1533 ... score_MCC = 0.1500 \n",
      "Count = 7 ... score_ROC = 0.7333 ... score_F1 = 0.1512 ... score_MCC = 0.1466 \n",
      "Count = 8 ... score_ROC = 0.7289 ... score_F1 = 0.1501 ... score_MCC = 0.1464 \n",
      "Count = 9 ... score_ROC = 0.7295 ... score_F1 = 0.1508 ... score_MCC = 0.1455 \n",
      "Count = 10 ... score_ROC = 0.7287 ... score_F1 = 0.1479 ... score_MCC = 0.1398\n",
      "Mean ROC_AUC = 0.7342                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 6, 'gamma': '0.615', 'subsample': '0.60', 'reg_alpha': '0.035', 'reg_lambda': '0.043', 'learning_rate': '0.094', 'num_leaves': '80.000', 'colsample_bytree': '0.439', 'min_child_samples': '120.000', 'feature_fraction': '0.626', 'bagging_fraction': '0.503', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7230 ... score_F1 = 0.1594 ... score_MCC = 0.1497 \n",
      "Count = 2 ... score_ROC = 0.7405 ... score_F1 = 0.1630 ... score_MCC = 0.1583 \n",
      "Count = 3 ... score_ROC = 0.7374 ... score_F1 = 0.1615 ... score_MCC = 0.1552 \n",
      "Count = 4 ... score_ROC = 0.7227 ... score_F1 = 0.1534 ... score_MCC = 0.1396 \n",
      "Count = 5 ... score_ROC = 0.7383 ... score_F1 = 0.1614 ... score_MCC = 0.1536 \n",
      "Count = 6 ... score_ROC = 0.7316 ... score_F1 = 0.1566 ... score_MCC = 0.1444 \n",
      "Count = 7 ... score_ROC = 0.7304 ... score_F1 = 0.1594 ... score_MCC = 0.1502 \n",
      "Count = 8 ... score_ROC = 0.7249 ... score_F1 = 0.1573 ... score_MCC = 0.1460 \n",
      "Count = 9 ... score_ROC = 0.7290 ... score_F1 = 0.1556 ... score_MCC = 0.1443 \n",
      "Count = 10 ... score_ROC = 0.7228 ... score_F1 = 0.1489 ... score_MCC = 0.1322\n",
      "Mean ROC_AUC = 0.7301                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 7, 'gamma': '0.462', 'subsample': '0.20', 'reg_alpha': '0.020', 'reg_lambda': '0.025', 'learning_rate': '0.041', 'num_leaves': '140.000', 'colsample_bytree': '0.640', 'min_child_samples': '230.000', 'feature_fraction': '0.653', 'bagging_fraction': '0.605', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7177 ... score_F1 = 0.1549 ... score_MCC = 0.1394 \n",
      "Count = 2 ... score_ROC = 0.7339 ... score_F1 = 0.1615 ... score_MCC = 0.1520 \n",
      "Count = 3 ... score_ROC = 0.7277 ... score_F1 = 0.1582 ... score_MCC = 0.1457 \n",
      "Count = 4 ... score_ROC = 0.7203 ... score_F1 = 0.1540 ... score_MCC = 0.1378 \n",
      "Count = 5 ... score_ROC = 0.7349 ... score_F1 = 0.1593 ... score_MCC = 0.1487 \n",
      "Count = 6 ... score_ROC = 0.7258 ... score_F1 = 0.1552 ... score_MCC = 0.1394 \n",
      "Count = 7 ... score_ROC = 0.7251 ... score_F1 = 0.1572 ... score_MCC = 0.1450 \n",
      "Count = 8 ... score_ROC = 0.7170 ... score_F1 = 0.1556 ... score_MCC = 0.1415 \n",
      "Count = 9 ... score_ROC = 0.7212 ... score_F1 = 0.1537 ... score_MCC = 0.1380 \n",
      "Count = 10 ... score_ROC = 0.7200 ... score_F1 = 0.1503 ... score_MCC = 0.1309\n",
      "Mean ROC_AUC = 0.7244                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.312', 'subsample': '0.40', 'reg_alpha': '0.025', 'reg_lambda': '0.031', 'learning_rate': '0.110', 'num_leaves': '20.000', 'colsample_bytree': '0.391', 'min_child_samples': '150.000', 'feature_fraction': '0.797', 'bagging_fraction': '0.811', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6980 ... score_F1 = 0.1538 ... score_MCC = 0.1262 \n",
      "Count = 2 ... score_ROC = 0.7016 ... score_F1 = 0.1507 ... score_MCC = 0.1202 \n",
      "Count = 3 ... score_ROC = 0.7122 ... score_F1 = 0.1639 ... score_MCC = 0.1421 \n",
      "Count = 4 ... score_ROC = 0.6981 ... score_F1 = 0.1619 ... score_MCC = 0.1393 \n",
      "Count = 5 ... score_ROC = 0.7134 ... score_F1 = 0.1608 ... score_MCC = 0.1375 \n",
      "Count = 6 ... score_ROC = 0.7049 ... score_F1 = 0.1528 ... score_MCC = 0.1228 \n",
      "Count = 7 ... score_ROC = 0.6952 ... score_F1 = 0.1443 ... score_MCC = 0.1103 \n",
      "Count = 8 ... score_ROC = 0.6969 ... score_F1 = 0.1520 ... score_MCC = 0.1227 \n",
      "Count = 9 ... score_ROC = 0.7064 ... score_F1 = 0.1574 ... score_MCC = 0.1322 \n",
      "Count = 10 ... score_ROC = 0.6950 ... score_F1 = 0.1463 ... score_MCC = 0.1157\n",
      "Mean ROC_AUC = 0.7022                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 6, 'gamma': '0.240', 'subsample': '0.80', 'reg_alpha': '0.041', 'reg_lambda': '0.047', 'learning_rate': '0.193', 'num_leaves': '60.000', 'colsample_bytree': '0.484', 'min_child_samples': '190.000', 'feature_fraction': '0.746', 'bagging_fraction': '0.643', 'objective': 'binary:logistic', 'scale_pos_weight': 20, 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7084 ... score_F1 = 0.1513 ... score_MCC = 0.1262 \n",
      "Count = 2 ... score_ROC = 0.7269 ... score_F1 = 0.1624 ... score_MCC = 0.1476 \n",
      "Count = 3 ... score_ROC = 0.7268 ... score_F1 = 0.1671 ... score_MCC = 0.1549 \n",
      "Count = 4 ... score_ROC = 0.7101 ... score_F1 = 0.1567 ... score_MCC = 0.1360 \n",
      "Count = 5 ... score_ROC = 0.7255 ... score_F1 = 0.1600 ... score_MCC = 0.1409 \n",
      "Count = 6 ... score_ROC = 0.7161 ... score_F1 = 0.1544 ... score_MCC = 0.1317 \n",
      "Count = 7 ... score_ROC = 0.7109 ... score_F1 = 0.1535 ... score_MCC = 0.1304 \n",
      "Count = 8 ... score_ROC = 0.7107 ... score_F1 = 0.1571 ... score_MCC = 0.1355 \n",
      "Count = 9 ... score_ROC = 0.7195 ... score_F1 = 0.1553 ... score_MCC = 0.1341 \n",
      "Count = 10 ... score_ROC = 0.7069 ... score_F1 = 0.1481 ... score_MCC = 0.1221\n",
      "Mean ROC_AUC = 0.7162                                                         \n",
      "100%|| 50/50 [22:21<00:00, 26.82s/it, best loss: 0.6474667663932181]\n",
      "CPU times: user 18min 12s, sys: 4min 9s, total: 22min 22s\n",
      "Wall time: 22min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set algoritm parameters\n",
    "best = fmin(fn = hyperparameter_tuning,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 50)\n",
    "\n",
    "# Print best parameters\n",
    "best_params = space_eval(space, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28825 16563]\n",
      " [  650  1483]]\n"
     ]
    }
   ],
   "source": [
    "# final chosen parameter\n",
    "params = {\n",
    "    'max_depth': 6, \n",
    "    'gamma': '0.452', \n",
    "    'subsample': '0.80', \n",
    "    'reg_alpha': '0.011', \n",
    "    'reg_lambda': '0.019', \n",
    "    'learning_rate': '0.015', \n",
    "    'num_leaves': '50.000', \n",
    "    'colsample_bytree': '0.748', \n",
    "    'min_child_samples': '170.000', \n",
    "    'feature_fraction': '0.538', \n",
    "    'bagging_fraction': '0.756', \n",
    "    'objective': 'binary:logistic', \n",
    "    'scale_pos_weight': 20, \n",
    "    'eval_metric': 'error'\n",
    "}\n",
    "\n",
    "\n",
    "# define the classifier\n",
    "xgb_clf = xgb.XGBClassifier(random_state = 42, \n",
    "                            verbose = True, \n",
    "                            tree_method = \"gpu_hist\",\n",
    "                            **params)\n",
    "\n",
    "# fit the classifier\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "\n",
    "# encoding the x_test\n",
    "x_test = woe_transform(x_test, categorical_column = \"app_code\", encoder_dict = app_code_dict)\n",
    "x_test = woe_transform(x_test, categorical_column = \"count_unique_app\", encoder_dict = count_unique_app_dict)\n",
    "\n",
    "# predict with the trained classifier\n",
    "preds = xgb_clf.predict(x_test)\n",
    "\n",
    "# printing the confusion matrix\n",
    "con_mat = confusion_matrix(y_test.values, preds)\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 63.78%\n",
      "Precision = 0.082\n",
      "Recall = 0.695\n",
      "F1 Score = 0.147\n"
     ]
    }
   ],
   "source": [
    "# Model Performance\n",
    "print(\"Accuracy = {:.2f}%\".format(accuracy_score(y_test.values, preds)*100))\n",
    "print(\"Precision = {:.3f}\".format(precision_score(y_test.values, preds)))\n",
    "print(\"Recall = {:.3f}\".format(recall_score(y_test.values, preds)))\n",
    "print(\"F1 Score = {:.3f}\".format(f1_score(y_test.values, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Looking at the above *confusion matrix*, two conclusions can be drawn:-\n",
    "- the number of false positives is insanely high.\n",
    "- the hyperparameter tuning may not give us the good performance. So, we need to explore new other techniques.\n",
    "\n",
    "As, we already have tried the **StratifiedKFold**, we need to now explore other sampling algorithms, that can allow our model to learn better. One solution to this problem could be using *Majority Under-Sampling, Minority Over-Sampling*. The way we can implement this is by **SMOTE**, which stands for Synthetic Minority Over-sampling Technique. The following code snippet will implement SMOTE from scratch (to understand the algorithm better, though a library called imblearn is also available). \n",
    "\n",
    "This algorithm is attributed to [this post](https://medium.com/@breya.heysoftware/synthetic-minority-over-sampling-technique-smote-from-scratch-e1167f788434):-\n",
    "- Identify the feature vector and its nearest neighbour\n",
    "- Take the difference between the two\n",
    "- Multiply the difference with a random number between 0 and 1\n",
    "- Identify a new point on the line segment by adding the random number to feature vector\n",
    "- Repeat the process for identified feature vector\n",
    "\n",
    "**NOTE** - for the best performance of the SMOTE, the data should be normalized. As I used XGBoost algorithm, I didn't scaled the data. That's because, tree based algorithm are immune to scale of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_neighbors(x_trainset):\n",
    "    \"\"\"\n",
    "    inp: trainset without labels\n",
    "    outp: indices for nearest neighbors\n",
    "    \"\"\"\n",
    "    neighbors = NearestNeighbors(n_neighbors = 5, metric = \"euclidean\", algorithm = \"kd_tree\").fit(x_trainset)\n",
    "    euclidean, indices = neighbors.kneighbors(x_trainset)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote(minclass_arr):\n",
    "    \"\"\"\n",
    "    implements SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "    \n",
    "    inp: trainset without labels,\n",
    "         minority class array\n",
    "    outp: matrix\n",
    "    \"\"\"\n",
    "    # get indices from n_neighbors function defined earlier\n",
    "    indices = n_neighbors(minclass_arr)\n",
    "    matrix = []\n",
    "    for m in range(0, len(indices)):\n",
    "        temp = minclass_arr[indices[m]]\n",
    "        temp = pd.DataFrame(temp)\n",
    "        matrix.append([])\n",
    "        for j in range(0, len(temp.columns)):\n",
    "            matrix[m].append(random.choice(temp[j]))\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train_oversampled = (198817, 27) ... y_train_oversampled = (198817, 1)\n",
      "Class ratio = 10.388303356627334\n"
     ]
    }
   ],
   "source": [
    "# getting minority classes instances in the trainset\n",
    "unique, counts = np.unique(y_train, return_counts = True)\n",
    "\n",
    "# Create a minority_shape variable which contains the dimension of the minority class\n",
    "minority_shape = dict(zip(unique, counts))[1]\n",
    "\n",
    "# storing minority class instances seperately\n",
    "minclass_arr = np.ones((minority_shape, x_train_scaled.shape[1]))\n",
    "minclass_arr = [x_train.iloc[i] for i, v in enumerate(y_train) if v == 1.0]\n",
    "minclass_arr = np.array(minclass_arr)\n",
    "\n",
    "# apply SMOTE\n",
    "sampled_instances = smote(minclass_arr)\n",
    "\n",
    "# Keeping the artificial instances and original instances together\n",
    "x_train_oversampled = np.concatenate((x_train_scaled, sampled_instances), axis = 0)\n",
    "y_sampled_instances = np.ones(minority_shape)\n",
    "y_train_oversampled = np.concatenate((y_train, y_sampled_instances), axis=0)\n",
    "\n",
    "x_train_oversampled = pd.DataFrame(x_train_oversampled)\n",
    "y_train_oversampled = pd.DataFrame(y_train_oversampled)\n",
    "x_train_oversampled.columns = cols \n",
    "\n",
    "print(\"Shape of x_train_oversampled = {} ... y_train_oversampled = {}\".format(x_train_oversampled.shape, y_train_oversampled.shape))\n",
    "print(\"Class ratio = {}\".format(len(y_train_oversampled[y_train_oversampled == 0].dropna())/len(y_train_oversampled[y_train_oversampled == 1].dropna())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41197  4191]\n",
      " [ 1516   617]]\n"
     ]
    }
   ],
   "source": [
    "# final chosen parameter\n",
    "params = {\n",
    "    'max_depth': 6, \n",
    "    'gamma': '0.452', \n",
    "    'subsample': '0.80', \n",
    "    'reg_alpha': '0.011', \n",
    "    'reg_lambda': '0.019', \n",
    "    'learning_rate': '0.015', \n",
    "    'num_leaves': '50.000', \n",
    "    'colsample_bytree': '0.748', \n",
    "    'min_child_samples': '170.000', \n",
    "    'feature_fraction': '0.538', \n",
    "    'bagging_fraction': '0.756', \n",
    "    'objective': 'binary:logistic', \n",
    "    'scale_pos_weight': 10, \n",
    "    'eval_metric': 'error'\n",
    "}\n",
    "\n",
    "# define the classifier\n",
    "xgb_clf = xgb.XGBClassifier(random_state = 42, \n",
    "                            verbose = True, \n",
    "                            tree_method = \"gpu_hist\",\n",
    "                            **params)\n",
    "\n",
    "# fit the classifier\n",
    "xgb_clf.fit(x_train_oversampled, y_train_oversampled)\n",
    "\n",
    "# predict with the trained classifier\n",
    "x_test_scaled = train_scaler.transform(x_test)\n",
    "x_test_scaled = pd.DataFrame(x_test_scaled)\n",
    "x_test_scaled.columns = cols\n",
    "preds = xgb_clf.predict(x_test_scaled)\n",
    "\n",
    "# printing the confusion matrix\n",
    "con_mat = confusion_matrix(y_test.values, preds)\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 87.99%\n",
      "Precision = 0.128\n",
      "Recall = 0.289\n",
      "F1 Score = 0.178\n"
     ]
    }
   ],
   "source": [
    "# Model Performance after SMOTE\n",
    "print(\"Accuracy = {:.2f}%\".format(accuracy_score(y_test.values, preds)*100))\n",
    "print(\"Precision = {:.3f}\".format(precision_score(y_test.values, preds)))\n",
    "print(\"Recall = {:.3f}\".format(recall_score(y_test.values, preds)))\n",
    "print(\"F1 Score = {:.3f}\".format(f1_score(y_test.values, preds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
