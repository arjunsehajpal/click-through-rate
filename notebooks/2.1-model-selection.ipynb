{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import roc_auc_score, make_scorer, matthews_corrcoef, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the parameters\n",
    "\n",
    "root_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "pd.set_option(\"display.max_rows\", 16)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataframe, validation_ratio):\n",
    "    \"\"\"\n",
    "    randomly splits the dataset into train and valid sets\n",
    "    \n",
    "    input: dataframe, validation ratio (the %age of data to feed into the )\n",
    "    output: trainset and validset\n",
    "    \"\"\"\n",
    "    num_train = len(dataframe)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(validation_ratio*num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_df, valid_df = dataframe.iloc[train_idx], dataframe.iloc[valid_idx]\n",
    "    return train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_of_evidence(target_df, predictor_df, categorical_col, min_percentage):\n",
    "    \"\"\"\n",
    "    calculates weight of evidence for the said column\n",
    "    \n",
    "    inp: target_df (dataframe of the variable to be predicted)\n",
    "         predictor_df (dataframe of the independent variables)\n",
    "         categorical_column (column to be WoE encoded)\n",
    "         min_percentage you want to take into consideration. Classes less than this proportion won't be considered\n",
    "    outp: transformed predicted_df[col], dict containing WoE.\n",
    "    \"\"\"\n",
    "    # creating new dataframe with groupby-agg clause. We will calculate the positives (i.e. events) of every class\n",
    "    woe_df = target_df.groupby(predictor_df[categorical_col]).agg([\"sum\", \"count\"]).rename({\"sum\": \"positives\"}, axis = 1)\n",
    "    \n",
    "    woe_df[\"negatives\"] = woe_df[\"count\"] - woe_df[\"positives\"]                      # calculating negatives (i.e. non-events)\n",
    "    woe_df[[\"positives\", \"negatives\"]] /= woe_df[[\"positives\", \"negatives\"]].sum()   # normalize\n",
    "    min_fraction = min_percentage / 100                                              # converting to fraction\n",
    "    \n",
    "    # checking classes with proportion less than min_percentage, or ones who have positives or negatives equal to zero\n",
    "    undefined = (woe_df[\"count\"]/len(predictor_df) < min_fraction) | (woe_df[\"positives\"] == 0) | (woe_df[\"negatives\"] == 0)\n",
    "    # replacing undefined with -1\n",
    "    woe_df.loc[undefined, [\"positives\", \"negatives\"]] = -1\n",
    "    \n",
    "    # calculating weight of evidence\n",
    "    woe_df[\"woe_value\"] = np.log(woe_df[\"positives\"] / woe_df[\"negatives\"])\n",
    "    woe_df[\"info_value\"] = (woe_df[\"positives\"] - woe_df[\"negatives\"]) * woe_df[\"woe_value\"]\n",
    "    \n",
    "    # calculate total information_value\n",
    "    total_iv = sum(woe_df[\"info_value\"])\n",
    "    print(\"Information value of the {} is = {}\".format(categorical_col, total_iv))\n",
    "    \n",
    "    # convert the woe_df into dictionary and map the changes to predictor column\n",
    "    woe_dict = woe_df[\"woe_value\"].to_dict()\n",
    "    predictor_df[categorical_col] = predictor_df[categorical_col].map(woe_dict)\n",
    "    \n",
    "    return predictor_df, woe_dict\n",
    "\n",
    "\n",
    "def woe_transform(test_df, categorical_column, encoder_dict):\n",
    "    \"\"\"\n",
    "    transforms the testset with WoE calculated from test set\n",
    "    \n",
    "    inp: test_df, \n",
    "         categorical_column to be encoded,\n",
    "         encoder_dict created from categorical column in trainset\n",
    "    outp: test_df mapped with woe values\n",
    "    \"\"\"\n",
    "    test_df[categorical_column] = test_df[categorical_column].map(encoder_dict)\n",
    "    \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(object_to_be_saved, path):\n",
    "    \"\"\"\n",
    "    saves the object as pickle at the defined path\n",
    "    \n",
    "    inp: object to be saved,\n",
    "         path\n",
    "    returns: None\n",
    "    \"\"\"\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(object_to_be_saved, f)\n",
    "\n",
    "def load_pickle(path):\n",
    "    \"\"\"\n",
    "    saves the object as pickle at the defined path\n",
    "    \n",
    "    inp: path\n",
    "    returns: pickle_object\n",
    "    \"\"\"\n",
    "    with open(path, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing the data for Machine Learning Model\n",
    "With the aggregation of data behind us, we still need to work on the data in order to feed the data to the Machine Learning model, so it can train on the data in the best way possible. One transformation that is required is the **Scaling** of the data, as most algorithms, like Deep Neural Nets, works considerably better when fed with scaled data. Other Machine Learning models like XGBoost are immune to scaling. So, scaling has no effect on XGBoost. \n",
    "\n",
    "Only continuous columns go through scaling. For categorical columns, we face other challenges. Foremost of these challenges is the high cardinality. For instance, the `app_code` column has 477 different values, which gives a very high cardinality to that particular column. To deal with this, we will use **Weight of Evidence**. In the weight of evidence algorithm, total number of records with the positive and negative class labels are also taken into account. For class imbalanced data, this algorithm works better. The advantages of using Weight of evidence are:-\n",
    "- Handles missing values\n",
    "- Handles outliers\n",
    "- The transformation is based on logarithmic value of distributions. This is aligned with the logistic regression output function\n",
    "- No need for dummy variables\n",
    "- By using proper binning technique, it can establish monotonic relationship (either increase or decrease) between the independent and dependent variable\n",
    "\n",
    "For the categorical variables, with fewer classes, we will use OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impression_id</th>\n",
       "      <th>impression_time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>app_code</th>\n",
       "      <th>os_version</th>\n",
       "      <th>is_4G</th>\n",
       "      <th>is_click</th>\n",
       "      <th>diff_time_mean</th>\n",
       "      <th>diff_time_max</th>\n",
       "      <th>diff_time_min</th>\n",
       "      <th>count_unique_app</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>vc_app_code</th>\n",
       "      <th>vc_user_id</th>\n",
       "      <th>app_code_count_unique_user</th>\n",
       "      <th>click_count_user_mean</th>\n",
       "      <th>time_elapsed_user</th>\n",
       "      <th>click_count_app_mean</th>\n",
       "      <th>time_elapsed_app</th>\n",
       "      <th>inst_count</th>\n",
       "      <th>user_unique_sessions</th>\n",
       "      <th>user_unique_item_ids</th>\n",
       "      <th>user_unique_category_1</th>\n",
       "      <th>user_unique_category_2</th>\n",
       "      <th>user_unique_category_3</th>\n",
       "      <th>user_unique_product_type</th>\n",
       "      <th>user_item_id_mode</th>\n",
       "      <th>user_category_1_mode</th>\n",
       "      <th>user_category_2_mode</th>\n",
       "      <th>user_category_3_mode</th>\n",
       "      <th>user_product_type_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>c4ca4238a0b923820dcc509a6f75849b</td>\n",
       "      <td>2018-11-15 00:00:00</td>\n",
       "      <td>87862</td>\n",
       "      <td>422</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74670.000000</td>\n",
       "      <td>148200.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>395</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43886</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5622.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>c81e728d9d4c2f636f067f89cc14862c</td>\n",
       "      <td>2018-11-15 00:00:00</td>\n",
       "      <td>89464</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101901.818182</td>\n",
       "      <td>347520.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7050</td>\n",
       "      <td>23</td>\n",
       "      <td>2000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>226</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>132</td>\n",
       "      <td>38517</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>8028.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>eccbc87e4b5ce2fe28308fd9f2a7baf3</td>\n",
       "      <td>2018-11-15 00:00:00</td>\n",
       "      <td>58442</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68812.727273</td>\n",
       "      <td>165720.0</td>\n",
       "      <td>8400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10851</td>\n",
       "      <td>34</td>\n",
       "      <td>2039</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>73224</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>5164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>a87ff679a2f3e71d9181a67b7542122c</td>\n",
       "      <td>2018-11-15 00:00:00</td>\n",
       "      <td>4238</td>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>540.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9343</td>\n",
       "      <td>2</td>\n",
       "      <td>1819</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>109</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>37336</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>45c48cce2e2d7fbdea1afc51c7c6ad26</td>\n",
       "      <td>2018-11-15 00:01:00</td>\n",
       "      <td>63410</td>\n",
       "      <td>467</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45745.882353</td>\n",
       "      <td>167340.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>422</td>\n",
       "      <td>52</td>\n",
       "      <td>24</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>43209</td>\n",
       "      <td>4.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>577.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      impression_id      impression_time  user_id  app_code  \\\n",
       "0  c4ca4238a0b923820dcc509a6f75849b  2018-11-15 00:00:00    87862       422   \n",
       "1  c81e728d9d4c2f636f067f89cc14862c  2018-11-15 00:00:00    89464       129   \n",
       "2  eccbc87e4b5ce2fe28308fd9f2a7baf3  2018-11-15 00:00:00    58442       127   \n",
       "3  a87ff679a2f3e71d9181a67b7542122c  2018-11-15 00:00:00     4238       371   \n",
       "4  45c48cce2e2d7fbdea1afc51c7c6ad26  2018-11-15 00:01:00    63410       467   \n",
       "\n",
       "   os_version  is_4G  is_click  diff_time_mean  diff_time_max  diff_time_min  \\\n",
       "0           2      0         0    74670.000000       148200.0         1140.0   \n",
       "1           0      0         0   101901.818182       347520.0          180.0   \n",
       "2           1      0         0    68812.727273       165720.0         8400.0   \n",
       "3           1      0         0      540.000000          540.0          540.0   \n",
       "4           1      1         1    45745.882353       167340.0          360.0   \n",
       "\n",
       "   count_unique_app  hour  minute  vc_app_code  vc_user_id  \\\n",
       "0                 1     0       0          395           3   \n",
       "1                 1     0       0         7050          23   \n",
       "2                 1     0       0        10851          34   \n",
       "3                 1     0       0         9343           2   \n",
       "4                 2     0       1          422          52   \n",
       "\n",
       "   app_code_count_unique_user  click_count_user_mean  time_elapsed_user  \\\n",
       "0                          51                   -1.0               -1.0   \n",
       "1                        2000                   -1.0               -1.0   \n",
       "2                        2039                   -1.0               -1.0   \n",
       "3                        1819                   -1.0               -1.0   \n",
       "4                          24                   -1.0               -1.0   \n",
       "\n",
       "   click_count_app_mean  time_elapsed_app  inst_count  user_unique_sessions  \\\n",
       "0                  -1.0              -1.0           1                     1   \n",
       "1                  -1.0              -1.0         226                    40   \n",
       "2                  -1.0              -1.0          32                    15   \n",
       "3                  -1.0              -1.0         109                    30   \n",
       "4                  -1.0              -1.0           7                     5   \n",
       "\n",
       "   user_unique_item_ids  user_unique_category_1  user_unique_category_2  \\\n",
       "0                     1                       1                       1   \n",
       "1                   150                      15                      50   \n",
       "2                    12                       8                      10   \n",
       "3                    52                      12                      28   \n",
       "4                     3                       2                       2   \n",
       "\n",
       "   user_unique_category_3  user_unique_product_type  user_item_id_mode  \\\n",
       "0                       1                         1              43886   \n",
       "1                      90                       132              38517   \n",
       "2                      10                        12              73224   \n",
       "3                      40                        50              37336   \n",
       "4                       2                         3              43209   \n",
       "\n",
       "   user_category_1_mode  user_category_2_mode  user_category_3_mode  \\\n",
       "0                  11.0                  35.0                  20.0   \n",
       "1                  17.0                   9.0                  62.0   \n",
       "2                   1.0                  64.0                 263.0   \n",
       "3                  17.0                   8.0                  84.0   \n",
       "4                   4.0                  74.0                 292.0   \n",
       "\n",
       "   user_product_type_mode  \n",
       "0                  5622.0  \n",
       "1                  8028.0  \n",
       "2                  5164.0  \n",
       "3                   231.0  \n",
       "4                   577.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the dataset\n",
    "df = pd.read_csv(os.path.join(root_dir, \"data\", \"processed_data\", \"train_aggdf.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train_df = (190088, 32)\n",
      "shape of test_df = (47521, 32)\n",
      "----------\n",
      "Shape of x_train = (190088, 27) ... y_train = (190088,)\n",
      "Shape of x_test = (47521, 27) ... y_test = (47521,)\n"
     ]
    }
   ],
   "source": [
    "# spliting the dataset\n",
    "train_df, test_df = train_test_split(df, validation_ratio = 0.2)\n",
    "\n",
    "print(\"shape of train_df = {}\".format(train_df.shape))\n",
    "print(\"shape of test_df = {}\".format(test_df.shape))\n",
    "\n",
    "# define predictors and targets in trainset and testset\n",
    "x_train, y_train = train_df.drop(columns = [\"impression_id\", \"user_id\", \"impression_time\", \"is_click\", \"minute\"]), train_df[\"is_click\"]\n",
    "x_test, y_test = test_df.drop(columns = [\"impression_id\", \"user_id\", \"impression_time\", \"is_click\", \"minute\"]), test_df[\"is_click\"]\n",
    "\n",
    "print(\"-\"*10)\n",
    "print(\"Shape of x_train = {} ... y_train = {}\".format(x_train.shape, y_train.shape))\n",
    "print(\"Shape of x_test = {} ... y_test = {}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Encoding the Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>app_code</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>os_version</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>is_4G</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count_unique_app</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    s\n",
       "app_code          472\n",
       "os_version          3\n",
       "is_4G               2\n",
       "count_unique_app    9"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = [\"app_code\", \"os_version\", \"is_4G\", \"count_unique_app\"]\n",
    "pd.DataFrame({\"s\": x_train[categorical_columns].nunique()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, it is pretty much clear that the predictor ``app_code`` and ``count_unique_app`` exhibits high cardinality. Because of this, we can't use techniques like one_hot_encoding, as it will give immense sparsity to the data and can't use LabelEncoding, as it will encode the values in ordinal manner, which might give unneccessary high weight to some classes. One of the techniques, we can use here is the Weigh of Evidence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information value of the app_code is = 0.5977002218699673\n",
      "Information value of the count_unique_app is = 0.006652631066726943\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "####### Calculating Weight of Evidence ##########\n",
    "#################################################\n",
    "\n",
    "x_train, app_code_dict = weight_of_evidence(y_train, x_train, categorical_col = \"app_code\", min_percentage = 0.01)\n",
    "x_train, count_unique_app_dict = weight_of_evidence(y_train, x_train, categorical_col = \"count_unique_app\", min_percentage = 0.01)\n",
    "\n",
    "save_pickle(app_code_dict, os.path.join(root_dir, \"models\", \"app_code_dict.pkl\"))\n",
    "save_pickle(count_unique_app_dict, os.path.join(root_dir, \"models\", \"count_unique_app_dict.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Scaling the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_code</th>\n",
       "      <th>os_version</th>\n",
       "      <th>is_4G</th>\n",
       "      <th>diff_time_mean</th>\n",
       "      <th>diff_time_max</th>\n",
       "      <th>diff_time_min</th>\n",
       "      <th>count_unique_app</th>\n",
       "      <th>hour</th>\n",
       "      <th>vc_app_code</th>\n",
       "      <th>vc_user_id</th>\n",
       "      <th>app_code_count_unique_user</th>\n",
       "      <th>click_count_user_mean</th>\n",
       "      <th>time_elapsed_user</th>\n",
       "      <th>click_count_app_mean</th>\n",
       "      <th>time_elapsed_app</th>\n",
       "      <th>inst_count</th>\n",
       "      <th>user_unique_sessions</th>\n",
       "      <th>user_unique_item_ids</th>\n",
       "      <th>user_unique_category_1</th>\n",
       "      <th>user_unique_category_2</th>\n",
       "      <th>user_unique_category_3</th>\n",
       "      <th>user_unique_product_type</th>\n",
       "      <th>user_item_id_mode</th>\n",
       "      <th>user_category_1_mode</th>\n",
       "      <th>user_category_2_mode</th>\n",
       "      <th>user_category_3_mode</th>\n",
       "      <th>user_product_type_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.532252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>0.176679</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516175</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.195613</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.520612</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.025273</td>\n",
       "      <td>0.060714</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.144654</td>\n",
       "      <td>0.060914</td>\n",
       "      <td>0.412167</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>0.589736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.246897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169827</td>\n",
       "      <td>0.441469</td>\n",
       "      <td>0.015928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.761696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506712</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.022975</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.125786</td>\n",
       "      <td>0.048223</td>\n",
       "      <td>0.580442</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.780645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.677651</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038489</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.159854</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.055873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.441643</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.248538</td>\n",
       "      <td>0.645119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.246897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.761696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506277</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.924353</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.108187</td>\n",
       "      <td>0.094887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.698108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091357</td>\n",
       "      <td>0.380107</td>\n",
       "      <td>0.009304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.153313</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.167620</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.380107</td>\n",
       "      <td>0.538417</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.083285</td>\n",
       "      <td>0.096429</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.459119</td>\n",
       "      <td>0.241117</td>\n",
       "      <td>0.729402</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.327485</td>\n",
       "      <td>0.021076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app_code  os_version  is_4G  diff_time_mean  diff_time_max  diff_time_min  \\\n",
       "0  0.532252         1.0    0.0        0.035887       0.176679       0.000152   \n",
       "1  0.246897         1.0    0.0        0.169827       0.441469       0.015928   \n",
       "2  0.677651         0.5    0.0        0.038489       0.077316       0.000152   \n",
       "3  0.246897         0.0    0.0        0.000961       0.000961       0.000961   \n",
       "4  0.698108         0.0    0.0        0.091357       0.380107       0.009304   \n",
       "\n",
       "   count_unique_app      hour  vc_app_code  vc_user_id  \\\n",
       "0          0.984925  0.000000     0.516175    0.069444   \n",
       "1          1.000000  0.000000     1.000000    0.041667   \n",
       "2          1.000000  0.782609     0.159854    0.041667   \n",
       "3          1.000000  0.608696     1.000000    0.013889   \n",
       "4          1.000000  0.869565     0.153313    0.083333   \n",
       "\n",
       "   app_code_count_unique_user  click_count_user_mean  time_elapsed_user  \\\n",
       "0                    0.195613               0.500000           0.000683   \n",
       "1                    0.761696               0.000000           0.000000   \n",
       "2                    0.055873               0.000000           0.000000   \n",
       "3                    0.761696               0.000000           0.000000   \n",
       "4                    0.167620               0.583333           0.380107   \n",
       "\n",
       "   click_count_app_mean  time_elapsed_app  inst_count  user_unique_sessions  \\\n",
       "0              0.520612          0.000027    0.025273              0.060714   \n",
       "1              0.506712          0.000053    0.022975              0.025000   \n",
       "2              0.542373          0.000106    0.000574              0.003571   \n",
       "3              0.506277          0.000027    0.000574              0.003571   \n",
       "4              0.538417          0.001162    0.083285              0.096429   \n",
       "\n",
       "   user_unique_item_ids  user_unique_category_1  user_unique_category_2  \\\n",
       "0                 0.052                0.866667                0.283582   \n",
       "1                 0.040                0.733333                0.283582   \n",
       "2                 0.002                0.066667                0.014925   \n",
       "3                 0.002                0.066667                0.014925   \n",
       "4                 0.200                0.933333                0.641791   \n",
       "\n",
       "   user_unique_category_3  user_unique_product_type  user_item_id_mode  \\\n",
       "0                0.144654                  0.060914           0.412167   \n",
       "1                0.125786                  0.048223           0.580442   \n",
       "2                0.006289                  0.002538           0.441643   \n",
       "3                0.006289                  0.002538           0.924353   \n",
       "4                0.459119                  0.241117           0.729402   \n",
       "\n",
       "   user_category_1_mode  user_category_2_mode  user_category_3_mode  \\\n",
       "0              0.111111                0.1000              0.903509   \n",
       "1              0.444444                0.3000              0.643275   \n",
       "2              0.500000                0.5125              0.248538   \n",
       "3              0.500000                0.5250              0.108187   \n",
       "4              0.111111                0.0250              0.327485   \n",
       "\n",
       "   user_product_type_mode  \n",
       "0                0.589736  \n",
       "1                0.780645  \n",
       "2                0.645119  \n",
       "3                0.094887  \n",
       "4                0.021076  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################\n",
    "############## Scaling the data #####################\n",
    "#####################################################\n",
    "\n",
    "# define the scaler\n",
    "scaler = MinMaxScaler()\n",
    "train_scaler = scaler.fit(x_train)\n",
    "\n",
    "# data columns\n",
    "cols = x_train.columns\n",
    "\n",
    "# save scaler object\n",
    "save_pickle(train_scaler, os.path.join(root_dir, \"models\", \"train_scaler.pkl\"))\n",
    "\n",
    "x_train_scaled = train_scaler.transform(x_train)\n",
    "\n",
    "# scaled dataset would be of type ndarray. Converting it back to Pandas\n",
    "x_train_scaled = pd.DataFrame(x_train_scaled)\n",
    "x_train_scaled.columns = cols\n",
    "\n",
    "x_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_code</th>\n",
       "      <th>os_version</th>\n",
       "      <th>is_4G</th>\n",
       "      <th>diff_time_mean</th>\n",
       "      <th>diff_time_max</th>\n",
       "      <th>diff_time_min</th>\n",
       "      <th>count_unique_app</th>\n",
       "      <th>hour</th>\n",
       "      <th>vc_app_code</th>\n",
       "      <th>vc_user_id</th>\n",
       "      <th>app_code_count_unique_user</th>\n",
       "      <th>click_count_user_mean</th>\n",
       "      <th>time_elapsed_user</th>\n",
       "      <th>click_count_app_mean</th>\n",
       "      <th>time_elapsed_app</th>\n",
       "      <th>inst_count</th>\n",
       "      <th>user_unique_sessions</th>\n",
       "      <th>user_unique_item_ids</th>\n",
       "      <th>user_unique_category_1</th>\n",
       "      <th>user_unique_category_2</th>\n",
       "      <th>user_unique_category_3</th>\n",
       "      <th>user_unique_product_type</th>\n",
       "      <th>user_item_id_mode</th>\n",
       "      <th>user_category_1_mode</th>\n",
       "      <th>user_category_2_mode</th>\n",
       "      <th>user_category_3_mode</th>\n",
       "      <th>user_product_type_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>112863</td>\n",
       "      <td>-0.085755</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>85164.0</td>\n",
       "      <td>419280.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0</td>\n",
       "      <td>17441</td>\n",
       "      <td>6</td>\n",
       "      <td>3488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>0.041224</td>\n",
       "      <td>60.0</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>54757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>6239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53943</td>\n",
       "      <td>-1.202252</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>403020.0</td>\n",
       "      <td>1047660.0</td>\n",
       "      <td>37800.0</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>0</td>\n",
       "      <td>33788</td>\n",
       "      <td>4</td>\n",
       "      <td>13579</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.013424</td>\n",
       "      <td>120.0</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>77113</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>8259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40321</td>\n",
       "      <td>0.483139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91340.0</td>\n",
       "      <td>183480.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>18</td>\n",
       "      <td>5402</td>\n",
       "      <td>4</td>\n",
       "      <td>997</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58673</td>\n",
       "      <td>8.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>6825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18836</td>\n",
       "      <td>-1.202252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>14</td>\n",
       "      <td>33788</td>\n",
       "      <td>2</td>\n",
       "      <td>13579</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.012555</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122803</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236556</td>\n",
       "      <td>0.563182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>216800.0</td>\n",
       "      <td>902040.0</td>\n",
       "      <td>22080.0</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>20</td>\n",
       "      <td>5181</td>\n",
       "      <td>7</td>\n",
       "      <td>2989</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>902040.0</td>\n",
       "      <td>0.076834</td>\n",
       "      <td>2640.0</td>\n",
       "      <td>145</td>\n",
       "      <td>27</td>\n",
       "      <td>100</td>\n",
       "      <td>14</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>95</td>\n",
       "      <td>96903</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        app_code  os_version  is_4G  diff_time_mean  diff_time_max  \\\n",
       "112863 -0.085755           2      0         85164.0       419280.0   \n",
       "53943  -1.202252           2      0        403020.0      1047660.0   \n",
       "40321   0.483139           1      0         91340.0       183480.0   \n",
       "18836  -1.202252           0      0          2280.0         2280.0   \n",
       "236556  0.563182           0      0        216800.0       902040.0   \n",
       "\n",
       "        diff_time_min  count_unique_app  hour  vc_app_code  vc_user_id  \\\n",
       "112863          360.0          0.003354     0        17441           6   \n",
       "53943         37800.0          0.019672     0        33788           4   \n",
       "40321           360.0          0.019672    18         5402           4   \n",
       "18836          2280.0          0.019672    14        33788           2   \n",
       "236556        22080.0          0.019672    20         5181           7   \n",
       "\n",
       "        app_code_count_unique_user  click_count_user_mean  time_elapsed_user  \\\n",
       "112863                        3488               0.000000             1620.0   \n",
       "53943                        13579              -1.000000               -1.0   \n",
       "40321                          997              -1.000000               -1.0   \n",
       "18836                        13579              -1.000000               -1.0   \n",
       "236556                        2989               0.166667           902040.0   \n",
       "\n",
       "        click_count_app_mean  time_elapsed_app  inst_count  \\\n",
       "112863              0.041224              60.0          44   \n",
       "53943               0.013424             120.0          40   \n",
       "40321               0.084746             240.0           1   \n",
       "18836               0.012555              60.0           1   \n",
       "236556              0.076834            2640.0         145   \n",
       "\n",
       "        user_unique_sessions  user_unique_item_ids  user_unique_category_1  \\\n",
       "112863                    17                    26                      13   \n",
       "53943                      7                    20                      11   \n",
       "40321                      1                     1                       1   \n",
       "18836                      1                     1                       1   \n",
       "236556                    27                   100                      14   \n",
       "\n",
       "        user_unique_category_2  user_unique_category_3  \\\n",
       "112863                      19                      23   \n",
       "53943                       19                      20   \n",
       "40321                        1                       1   \n",
       "18836                        1                       1   \n",
       "236556                      43                      73   \n",
       "\n",
       "        user_unique_product_type  user_item_id_mode  user_category_1_mode  \\\n",
       "112863                        24              54757                   1.0   \n",
       "53943                         19              77113                   7.0   \n",
       "40321                          1              58673                   8.0   \n",
       "18836                          1             122803                   8.0   \n",
       "236556                        95              96903                   1.0   \n",
       "\n",
       "        user_category_2_mode  user_category_3_mode  user_product_type_mode  \n",
       "112863                   7.0                 308.0                  6239.0  \n",
       "53943                   23.0                 219.0                  8259.0  \n",
       "40321                   40.0                  84.0                  6825.0  \n",
       "18836                   41.0                  36.0                  1003.0  \n",
       "236556                   1.0                 111.0                   222.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Machine Learning Models\n",
    "### 2.1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_eval(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    custom eval metric for XGBClassifier\n",
    "    \"\"\"\n",
    "    err = 1 - f1_score(y_true, np.round(y_pred))\n",
    "    return \"f1_err\", err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(params):\n",
    "    \"\"\"\n",
    "    hypertunes a XGBoost model\n",
    "    \n",
    "    inp: parameters\n",
    "    outp: score per fold\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"max_depth\": int(params[\"max_depth\"]),                              # max depth of the tree\n",
    "        \"gamma\": \"{:.3f}\".format(params[\"gamma\"]),                          # min loss reduction required to make a split\n",
    "        \"subsample\": \"{:.2f}\".format(params[\"subsample\"]),                  # denotes the fraction of observations to be randomly samples for each tree\n",
    "        \"reg_alpha\": \"{:.3f}\".format(params[\"reg_alpha\"]),                  # L1 regularization weight\n",
    "        \"reg_lambda\": \"{:.3f}\".format(params[\"reg_lambda\"]),                # L2 regularization weight\n",
    "        \"learning_rate\": \"{:.3f}\".format(params[\"learning_rate\"]),          # learning rate of XGB\n",
    "        \"num_leaves\": \"{:.3f}\".format(params[\"num_leaves\"]),                 \n",
    "        \"colsample_bytree\": \"{:.3f}\".format(params[\"colsample_bytree\"]),\n",
    "        \"min_child_samples\": \"{:.3f}\".format(params[\"min_child_samples\"]),\n",
    "        \"feature_fraction\": \"{:.3f}\".format(params[\"feature_fraction\"]),\n",
    "        \"bagging_fraction\": \"{:.3f}\".format(params[\"bagging_fraction\"]),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        #\"f_eval\": f1_eval,\n",
    "        \"eval_metric\": \"error\"\n",
    "    }\n",
    "    \n",
    "    print(\"#\"*25)\n",
    "    print(\"Params = {}\".format(params))\n",
    "    FOLDS = 10  # defining the folds required\n",
    "    count = 1   # count of HPT cycles\n",
    "    skf = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = 42)\n",
    "    y_oof = np.zeros(x_train.shape[0])\n",
    "    ROC_mean = 0\n",
    "    for trn_idx, val_idx in skf.split(x_train, y_train):\n",
    "        # define the classifier\n",
    "        clf = xgb.XGBClassifier(random_state = 42, \n",
    "                                verbose = True, \n",
    "                                tree_method = \"gpu_hist\",\n",
    "                                **params)\n",
    "        # spliting data into train and valid sets\n",
    "        train_x, valid_x = x_train.iloc[trn_idx], x_train.iloc[val_idx]\n",
    "        train_y, valid_y = y_train.iloc[trn_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        # fit the estimator and predict\n",
    "        clf.fit(train_x, train_y)\n",
    "        pred = clf.predict(valid_x)\n",
    "        # eval metrics\n",
    "        score_ROC = make_scorer(roc_auc_score, needs_proba = True)(clf, valid_x, valid_y)\n",
    "        score_F1 = f1_score(valid_y.values, pred, average = \"binary\")\n",
    "        score_MCC = matthews_corrcoef(valid_y.values, pred)\n",
    "        ROC_mean += score_ROC\n",
    "        print(\"Count = {} ... score_ROC = {:.4f} ... score_F1 = {:.4f} ... score_MCC = {:.4f}\".format(count, score_ROC, score_F1, score_MCC))\n",
    "        count += 1\n",
    "    \n",
    "    gc.collect()\n",
    "    print(\"Mean ROC_AUC = {:.4}\".format(ROC_mean / FOLDS))\n",
    "    del train_x, valid_x, train_y, valid_y, clf, score_ROC\n",
    "    \n",
    "    return (ROC_mean/FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    \"max_depth\": hp.quniform(\"max_depth\", 6, 8, 1),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0.01, 0.05),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0.01, 0.05),\n",
    "    \"learning_rate\": hp.uniform(\"learning_rate\", 0.001, 0.2),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.3, 0.9),\n",
    "    \"gamma\": hp.uniform(\"gamma\", 0.01, 0.7),\n",
    "    \"num_leaves\": hp.choice(\"num_leaves\", list(range(20, 250, 10))),\n",
    "    \"min_child_samples\": hp.choice(\"min_child_samples\", list(range(100, 250, 10))),\n",
    "    \"subsample\": hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.4, .8),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, .9)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################                           \n",
      "Params = {'max_depth': 6, 'gamma': '0.359', 'subsample': '0.80', 'reg_alpha': '0.020', 'reg_lambda': '0.034', 'learning_rate': '0.173', 'num_leaves': '220.000', 'colsample_bytree': '0.352', 'min_child_samples': '140.000', 'feature_fraction': '0.584', 'bagging_fraction': '0.589', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7134 ... score_F1 = 0.0046 ... score_MCC = 0.0202\n",
      "Count = 2 ... score_ROC = 0.7293 ... score_F1 = 0.0046 ... score_MCC = 0.0277\n",
      "Count = 3 ... score_ROC = 0.7276 ... score_F1 = 0.0046 ... score_MCC = 0.0158\n",
      "Count = 4 ... score_ROC = 0.7224 ... score_F1 = 0.0069 ... score_MCC = 0.0281\n",
      "Count = 5 ... score_ROC = 0.7136 ... score_F1 = 0.0046 ... score_MCC = 0.0222\n",
      "Count = 6 ... score_ROC = 0.7279 ... score_F1 = 0.0137 ... score_MCC = 0.0479\n",
      "Count = 7 ... score_ROC = 0.7349 ... score_F1 = 0.0115 ... score_MCC = 0.0572\n",
      "Count = 8 ... score_ROC = 0.7332 ... score_F1 = 0.0091 ... score_MCC = 0.0314\n",
      "Count = 9 ... score_ROC = 0.7428 ... score_F1 = 0.0046 ... score_MCC = 0.0317\n",
      "Count = 10 ... score_ROC = 0.7327 ... score_F1 = 0.0092 ... score_MCC = 0.0348\n",
      "Mean ROC_AUC = 0.7278                               \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.118', 'subsample': '0.20', 'reg_alpha': '0.047', 'reg_lambda': '0.049', 'learning_rate': '0.163', 'num_leaves': '70.000', 'colsample_bytree': '0.700', 'min_child_samples': '100.000', 'feature_fraction': '0.686', 'bagging_fraction': '0.591', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6850 ... score_F1 = 0.0216 ... score_MCC = 0.0310 \n",
      "Count = 2 ... score_ROC = 0.6813 ... score_F1 = 0.0260 ... score_MCC = 0.0413 \n",
      "Count = 3 ... score_ROC = 0.6864 ... score_F1 = 0.0379 ... score_MCC = 0.0522 \n",
      "Count = 4 ... score_ROC = 0.6756 ... score_F1 = 0.0237 ... score_MCC = 0.0336 \n",
      "Count = 5 ... score_ROC = 0.6805 ... score_F1 = 0.0345 ... score_MCC = 0.0553 \n",
      "Count = 6 ... score_ROC = 0.6854 ... score_F1 = 0.0489 ... score_MCC = 0.0757 \n",
      "Count = 7 ... score_ROC = 0.6971 ... score_F1 = 0.0407 ... score_MCC = 0.0642 \n",
      "Count = 8 ... score_ROC = 0.6817 ... score_F1 = 0.0442 ... score_MCC = 0.0629 \n",
      "Count = 9 ... score_ROC = 0.6952 ... score_F1 = 0.0386 ... score_MCC = 0.0613 \n",
      "Count = 10 ... score_ROC = 0.6889 ... score_F1 = 0.0320 ... score_MCC = 0.0459\n",
      "Mean ROC_AUC = 0.6857                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.425', 'subsample': '0.50', 'reg_alpha': '0.029', 'reg_lambda': '0.022', 'learning_rate': '0.150', 'num_leaves': '100.000', 'colsample_bytree': '0.326', 'min_child_samples': '100.000', 'feature_fraction': '0.466', 'bagging_fraction': '0.722', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7080 ... score_F1 = 0.0159 ... score_MCC = 0.0460 \n",
      "Count = 2 ... score_ROC = 0.7157 ... score_F1 = 0.0182 ... score_MCC = 0.0612 \n",
      "Count = 3 ... score_ROC = 0.7158 ... score_F1 = 0.0091 ... score_MCC = 0.0241 \n",
      "Count = 4 ... score_ROC = 0.7114 ... score_F1 = 0.0157 ... score_MCC = 0.0378 \n",
      "Count = 5 ... score_ROC = 0.7111 ... score_F1 = 0.0114 ... score_MCC = 0.0344 \n",
      "Count = 6 ... score_ROC = 0.7144 ... score_F1 = 0.0268 ... score_MCC = 0.0626 \n",
      "Count = 7 ... score_ROC = 0.7192 ... score_F1 = 0.0227 ... score_MCC = 0.0732 \n",
      "Count = 8 ... score_ROC = 0.7195 ... score_F1 = 0.0225 ... score_MCC = 0.0590 \n",
      "Count = 9 ... score_ROC = 0.7325 ... score_F1 = 0.0203 ... score_MCC = 0.0522 \n",
      "Count = 10 ... score_ROC = 0.7115 ... score_F1 = 0.0201 ... score_MCC = 0.0456\n",
      "Mean ROC_AUC = 0.7159                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.285', 'subsample': '0.60', 'reg_alpha': '0.034', 'reg_lambda': '0.017', 'learning_rate': '0.184', 'num_leaves': '150.000', 'colsample_bytree': '0.597', 'min_child_samples': '230.000', 'feature_fraction': '0.786', 'bagging_fraction': '0.702', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6972 ... score_F1 = 0.0202 ... score_MCC = 0.0522 \n",
      "Count = 2 ... score_ROC = 0.7079 ... score_F1 = 0.0224 ... score_MCC = 0.0551 \n",
      "Count = 3 ... score_ROC = 0.7046 ... score_F1 = 0.0265 ... score_MCC = 0.0519 \n",
      "Count = 4 ... score_ROC = 0.7018 ... score_F1 = 0.0243 ... score_MCC = 0.0474 \n",
      "Count = 5 ... score_ROC = 0.6999 ... score_F1 = 0.0222 ... score_MCC = 0.0452 \n",
      "Count = 6 ... score_ROC = 0.7184 ... score_F1 = 0.0221 ... score_MCC = 0.0408 \n",
      "Count = 7 ... score_ROC = 0.7126 ... score_F1 = 0.0333 ... score_MCC = 0.0740 \n",
      "Count = 8 ... score_ROC = 0.6998 ... score_F1 = 0.0265 ... score_MCC = 0.0519 \n",
      "Count = 9 ... score_ROC = 0.7243 ... score_F1 = 0.0134 ... score_MCC = 0.0274 \n",
      "Count = 10 ... score_ROC = 0.7036 ... score_F1 = 0.0265 ... score_MCC = 0.0535\n",
      "Mean ROC_AUC = 0.707                                                          \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 6, 'gamma': '0.034', 'subsample': '0.80', 'reg_alpha': '0.013', 'reg_lambda': '0.016', 'learning_rate': '0.198', 'num_leaves': '110.000', 'colsample_bytree': '0.391', 'min_child_samples': '100.000', 'feature_fraction': '0.762', 'bagging_fraction': '0.601', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7151 ... score_F1 = 0.0114 ... score_MCC = 0.0449 \n",
      "Count = 2 ... score_ROC = 0.7220 ... score_F1 = 0.0161 ... score_MCC = 0.0819 \n",
      "Count = 3 ... score_ROC = 0.7262 ... score_F1 = 0.0205 ... score_MCC = 0.0673 \n",
      "Count = 4 ... score_ROC = 0.7201 ... score_F1 = 0.0068 ... score_MCC = 0.0189 \n",
      "Count = 5 ... score_ROC = 0.7146 ... score_F1 = 0.0069 ... score_MCC = 0.0325 \n",
      "Count = 6 ... score_ROC = 0.7272 ... score_F1 = 0.0114 ... score_MCC = 0.0358 \n",
      "Count = 7 ... score_ROC = 0.7318 ... score_F1 = 0.0092 ... score_MCC = 0.0486 \n",
      "Count = 8 ... score_ROC = 0.7220 ... score_F1 = 0.0046 ... score_MCC = 0.0147 \n",
      "Count = 9 ... score_ROC = 0.7380 ... score_F1 = 0.0138 ... score_MCC = 0.0579 \n",
      "Count = 10 ... score_ROC = 0.7218 ... score_F1 = 0.0114 ... score_MCC = 0.0373\n",
      "Mean ROC_AUC = 0.7239                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.211', 'subsample': '0.40', 'reg_alpha': '0.041', 'reg_lambda': '0.022', 'learning_rate': '0.003', 'num_leaves': '130.000', 'colsample_bytree': '0.305', 'min_child_samples': '230.000', 'feature_fraction': '0.750', 'bagging_fraction': '0.892', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7155 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 2 ... score_ROC = 0.7293 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 3 ... score_ROC = 0.7311 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 4 ... score_ROC = 0.7322 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 5 ... score_ROC = 0.7210 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 6 ... score_ROC = 0.7316 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 7 ... score_ROC = 0.7422 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 8 ... score_ROC = 0.7341 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 9 ... score_ROC = 0.7482 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 10 ... score_ROC = 0.7320 ... score_F1 = 0.0000 ... score_MCC = 0.0000\n",
      "Mean ROC_AUC = 0.7317                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.329', 'subsample': '0.70', 'reg_alpha': '0.024', 'reg_lambda': '0.038', 'learning_rate': '0.007', 'num_leaves': '80.000', 'colsample_bytree': '0.756', 'min_child_samples': '160.000', 'feature_fraction': '0.585', 'bagging_fraction': '0.841', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7229 ... score_F1 = 0.0000 ... score_MCC = -0.0016\n",
      "Count = 2 ... score_ROC = 0.7334 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 3 ... score_ROC = 0.7341 ... score_F1 = 0.0000 ... score_MCC = -0.0022\n",
      "Count = 4 ... score_ROC = 0.7321 ... score_F1 = 0.0023 ... score_MCC = 0.0224 \n",
      "Count = 5 ... score_ROC = 0.7280 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 6 ... score_ROC = 0.7349 ... score_F1 = 0.0046 ... score_MCC = 0.0471 \n",
      "Count = 7 ... score_ROC = 0.7416 ... score_F1 = 0.0046 ... score_MCC = 0.0471 \n",
      "Count = 8 ... score_ROC = 0.7379 ... score_F1 = 0.0023 ... score_MCC = 0.0224 \n",
      "Count = 9 ... score_ROC = 0.7528 ... score_F1 = 0.0023 ... score_MCC = 0.0224 \n",
      "Count = 10 ... score_ROC = 0.7371 ... score_F1 = 0.0023 ... score_MCC = 0.0143\n",
      "Mean ROC_AUC = 0.7355                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.689', 'subsample': '0.50', 'reg_alpha': '0.027', 'reg_lambda': '0.036', 'learning_rate': '0.159', 'num_leaves': '220.000', 'colsample_bytree': '0.454', 'min_child_samples': '220.000', 'feature_fraction': '0.504', 'bagging_fraction': '0.629', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7065 ... score_F1 = 0.0068 ... score_MCC = 0.0130\n",
      "Count = 2 ... score_ROC = 0.7069 ... score_F1 = 0.0203 ... score_MCC = 0.0522\n",
      "Count = 3 ... score_ROC = 0.7164 ... score_F1 = 0.0202 ... score_MCC = 0.0466\n",
      "Count = 4 ... score_ROC = 0.7031 ... score_F1 = 0.0158 ... score_MCC = 0.0399\n",
      "Count = 5 ... score_ROC = 0.7051 ... score_F1 = 0.0158 ... score_MCC = 0.0399\n",
      "Count = 6 ... score_ROC = 0.7087 ... score_F1 = 0.0180 ... score_MCC = 0.0467\n",
      "Count = 7 ... score_ROC = 0.7172 ... score_F1 = 0.0248 ... score_MCC = 0.0672\n",
      "Count = 8 ... score_ROC = 0.7120 ... score_F1 = 0.0200 ... score_MCC = 0.0420\n",
      "Count = 9 ... score_ROC = 0.7340 ... score_F1 = 0.0204 ... score_MCC = 0.0579\n",
      "Count = 10 ... score_ROC = 0.7100 ... score_F1 = 0.0136 ... score_MCC = 0.0350\n",
      "Mean ROC_AUC = 0.712                                                         \n",
      "#########################                                                    \n",
      "Params = {'max_depth': 7, 'gamma': '0.555', 'subsample': '0.20', 'reg_alpha': '0.021', 'reg_lambda': '0.032', 'learning_rate': '0.143', 'num_leaves': '100.000', 'colsample_bytree': '0.334', 'min_child_samples': '240.000', 'feature_fraction': '0.749', 'bagging_fraction': '0.411', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.6990 ... score_F1 = 0.0136 ... score_MCC = 0.0426\n",
      "Count = 2 ... score_ROC = 0.7009 ... score_F1 = 0.0091 ... score_MCC = 0.0299\n",
      "Count = 3 ... score_ROC = 0.7053 ... score_F1 = 0.0113 ... score_MCC = 0.0308\n",
      "Count = 4 ... score_ROC = 0.7003 ... score_F1 = 0.0090 ... score_MCC = 0.0200\n",
      "Count = 5 ... score_ROC = 0.6940 ... score_F1 = 0.0159 ... score_MCC = 0.0461\n",
      "Count = 6 ... score_ROC = 0.7073 ... score_F1 = 0.0136 ... score_MCC = 0.0361\n",
      "Count = 7 ... score_ROC = 0.7161 ... score_F1 = 0.0268 ... score_MCC = 0.0626\n",
      "Count = 8 ... score_ROC = 0.7111 ... score_F1 = 0.0089 ... score_MCC = 0.0147\n",
      "Count = 9 ... score_ROC = 0.7269 ... score_F1 = 0.0113 ... score_MCC = 0.0298\n",
      "Count = 10 ... score_ROC = 0.7142 ... score_F1 = 0.0202 ... score_MCC = 0.0466\n",
      "Mean ROC_AUC = 0.7075                                                        \n",
      "#########################                                                    \n",
      "Params = {'max_depth': 6, 'gamma': '0.242', 'subsample': '0.60', 'reg_alpha': '0.043', 'reg_lambda': '0.038', 'learning_rate': '0.116', 'num_leaves': '30.000', 'colsample_bytree': '0.889', 'min_child_samples': '170.000', 'feature_fraction': '0.778', 'bagging_fraction': '0.677', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7213 ... score_F1 = 0.0069 ... score_MCC = 0.0354\n",
      "Count = 2 ... score_ROC = 0.7303 ... score_F1 = 0.0069 ... score_MCC = 0.0433\n",
      "Count = 3 ... score_ROC = 0.7325 ... score_F1 = 0.0160 ... score_MCC = 0.0620\n",
      "Count = 4 ... score_ROC = 0.7284 ... score_F1 = 0.0069 ... score_MCC = 0.0281\n",
      "Count = 5 ... score_ROC = 0.7222 ... score_F1 = 0.0069 ... score_MCC = 0.0389\n",
      "Count = 6 ... score_ROC = 0.7316 ... score_F1 = 0.0115 ... score_MCC = 0.0502\n",
      "Count = 7 ... score_ROC = 0.7400 ... score_F1 = 0.0092 ... score_MCC = 0.0589\n",
      "Count = 8 ... score_ROC = 0.7374 ... score_F1 = 0.0092 ... score_MCC = 0.0348\n",
      "Count = 9 ... score_ROC = 0.7523 ... score_F1 = 0.0115 ... score_MCC = 0.0572\n",
      "Count = 10 ... score_ROC = 0.7379 ... score_F1 = 0.0069 ... score_MCC = 0.0354\n",
      "Mean ROC_AUC = 0.7334                                                        \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 7, 'gamma': '0.639', 'subsample': '0.90', 'reg_alpha': '0.044', 'reg_lambda': '0.034', 'learning_rate': '0.099', 'num_leaves': '200.000', 'colsample_bytree': '0.377', 'min_child_samples': '100.000', 'feature_fraction': '0.451', 'bagging_fraction': '0.473', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7201 ... score_F1 = 0.0069 ... score_MCC = 0.0325 \n",
      "Count = 2 ... score_ROC = 0.7294 ... score_F1 = 0.0023 ... score_MCC = 0.0174 \n",
      "Count = 3 ... score_ROC = 0.7316 ... score_F1 = 0.0069 ... score_MCC = 0.0301 \n",
      "Count = 4 ... score_ROC = 0.7293 ... score_F1 = 0.0069 ... score_MCC = 0.0433 \n",
      "Count = 5 ... score_ROC = 0.7260 ... score_F1 = 0.0046 ... score_MCC = 0.0277 \n",
      "Count = 6 ... score_ROC = 0.7330 ... score_F1 = 0.0092 ... score_MCC = 0.0449 \n",
      "Count = 7 ... score_ROC = 0.7403 ... score_F1 = 0.0092 ... score_MCC = 0.0531 \n",
      "Count = 8 ... score_ROC = 0.7360 ... score_F1 = 0.0046 ... score_MCC = 0.0222 \n",
      "Count = 9 ... score_ROC = 0.7506 ... score_F1 = 0.0092 ... score_MCC = 0.0486 \n",
      "Count = 10 ... score_ROC = 0.7392 ... score_F1 = 0.0069 ... score_MCC = 0.0325\n",
      "Mean ROC_AUC = 0.7335                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.507', 'subsample': '0.20', 'reg_alpha': '0.020', 'reg_lambda': '0.047', 'learning_rate': '0.099', 'num_leaves': '180.000', 'colsample_bytree': '0.558', 'min_child_samples': '100.000', 'feature_fraction': '0.788', 'bagging_fraction': '0.841', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7039 ... score_F1 = 0.0091 ... score_MCC = 0.0314 \n",
      "Count = 2 ... score_ROC = 0.7192 ... score_F1 = 0.0091 ... score_MCC = 0.0273 \n",
      "Count = 3 ... score_ROC = 0.7116 ... score_F1 = 0.0135 ... score_MCC = 0.0312 \n",
      "Count = 4 ... score_ROC = 0.7186 ... score_F1 = 0.0068 ... score_MCC = 0.0180 \n",
      "Count = 5 ... score_ROC = 0.7090 ... score_F1 = 0.0091 ... score_MCC = 0.0273 \n",
      "Count = 6 ... score_ROC = 0.7110 ... score_F1 = 0.0270 ... score_MCC = 0.0724 \n",
      "Count = 7 ... score_ROC = 0.7168 ... score_F1 = 0.0181 ... score_MCC = 0.0492 \n",
      "Count = 8 ... score_ROC = 0.7174 ... score_F1 = 0.0158 ... score_MCC = 0.0410 \n",
      "Count = 9 ... score_ROC = 0.7340 ... score_F1 = 0.0181 ... score_MCC = 0.0506 \n",
      "Count = 10 ... score_ROC = 0.7189 ... score_F1 = 0.0068 ... score_MCC = 0.0198\n",
      "Mean ROC_AUC = 0.7161                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.654', 'subsample': '0.50', 'reg_alpha': '0.041', 'reg_lambda': '0.033', 'learning_rate': '0.009', 'num_leaves': '90.000', 'colsample_bytree': '0.590', 'min_child_samples': '110.000', 'feature_fraction': '0.411', 'bagging_fraction': '0.840', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7212 ... score_F1 = 0.0000 ... score_MCC = -0.0016\n",
      "Count = 2 ... score_ROC = 0.7327 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 3 ... score_ROC = 0.7338 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 4 ... score_ROC = 0.7324 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 5 ... score_ROC = 0.7265 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 6 ... score_ROC = 0.7329 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 7 ... score_ROC = 0.7457 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 8 ... score_ROC = 0.7387 ... score_F1 = 0.0023 ... score_MCC = 0.0224 \n",
      "Count = 9 ... score_ROC = 0.7529 ... score_F1 = 0.0000 ... score_MCC = -0.0016\n",
      "Count = 10 ... score_ROC = 0.7386 ... score_F1 = 0.0023 ... score_MCC = 0.0143\n",
      "Mean ROC_AUC = 0.7356                                                         \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 7, 'gamma': '0.694', 'subsample': '0.50', 'reg_alpha': '0.017', 'reg_lambda': '0.021', 'learning_rate': '0.097', 'num_leaves': '30.000', 'colsample_bytree': '0.861', 'min_child_samples': '220.000', 'feature_fraction': '0.410', 'bagging_fraction': '0.725', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7183 ... score_F1 = 0.0046 ... score_MCC = 0.0202  \n",
      "Count = 2 ... score_ROC = 0.7282 ... score_F1 = 0.0069 ... score_MCC = 0.0389  \n",
      "Count = 3 ... score_ROC = 0.7317 ... score_F1 = 0.0069 ... score_MCC = 0.0325  \n",
      "Count = 4 ... score_ROC = 0.7234 ... score_F1 = 0.0091 ... score_MCC = 0.0314  \n",
      "Count = 5 ... score_ROC = 0.7244 ... score_F1 = 0.0115 ... score_MCC = 0.0502  \n",
      "Count = 6 ... score_ROC = 0.7294 ... score_F1 = 0.0115 ... score_MCC = 0.0474  \n",
      "Count = 7 ... score_ROC = 0.7402 ... score_F1 = 0.0092 ... score_MCC = 0.0449  \n",
      "Count = 8 ... score_ROC = 0.7336 ... score_F1 = 0.0114 ... score_MCC = 0.0407  \n",
      "Count = 9 ... score_ROC = 0.7504 ... score_F1 = 0.0115 ... score_MCC = 0.0534  \n",
      "Count = 10 ... score_ROC = 0.7294 ... score_F1 = 0.0115 ... score_MCC = 0.0449 \n",
      "Mean ROC_AUC = 0.7309                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 6, 'gamma': '0.590', 'subsample': '0.50', 'reg_alpha': '0.030', 'reg_lambda': '0.033', 'learning_rate': '0.024', 'num_leaves': '120.000', 'colsample_bytree': '0.888', 'min_child_samples': '230.000', 'feature_fraction': '0.656', 'bagging_fraction': '0.658', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7233 ... score_F1 = 0.0000 ... score_MCC = -0.0016 \n",
      "Count = 2 ... score_ROC = 0.7345 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 3 ... score_ROC = 0.7355 ... score_F1 = 0.0000 ... score_MCC = 0.0000  \n",
      "Count = 4 ... score_ROC = 0.7314 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 5 ... score_ROC = 0.7279 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 6 ... score_ROC = 0.7337 ... score_F1 = 0.0046 ... score_MCC = 0.0471  \n",
      "Count = 7 ... score_ROC = 0.7424 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 8 ... score_ROC = 0.7374 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 9 ... score_ROC = 0.7538 ... score_F1 = 0.0000 ... score_MCC = 0.0000  \n",
      "Count = 10 ... score_ROC = 0.7380 ... score_F1 = 0.0023 ... score_MCC = 0.0143 \n",
      "Mean ROC_AUC = 0.7358                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 7, 'gamma': '0.289', 'subsample': '0.80', 'reg_alpha': '0.042', 'reg_lambda': '0.047', 'learning_rate': '0.195', 'num_leaves': '180.000', 'colsample_bytree': '0.756', 'min_child_samples': '190.000', 'feature_fraction': '0.544', 'bagging_fraction': '0.544', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7062 ... score_F1 = 0.0068 ... score_MCC = 0.0149  \n",
      "Count = 2 ... score_ROC = 0.7208 ... score_F1 = 0.0204 ... score_MCC = 0.0596  \n",
      "Count = 3 ... score_ROC = 0.7181 ... score_F1 = 0.0136 ... score_MCC = 0.0361  \n",
      "Count = 4 ... score_ROC = 0.7116 ... score_F1 = 0.0114 ... score_MCC = 0.0331  \n",
      "Count = 5 ... score_ROC = 0.7073 ... score_F1 = 0.0137 ... score_MCC = 0.0460  \n",
      "Count = 6 ... score_ROC = 0.7176 ... score_F1 = 0.0269 ... score_MCC = 0.0651  \n",
      "Count = 7 ... score_ROC = 0.7249 ... score_F1 = 0.0272 ... score_MCC = 0.0841  \n",
      "Count = 8 ... score_ROC = 0.7236 ... score_F1 = 0.0289 ... score_MCC = 0.0618  \n",
      "Count = 9 ... score_ROC = 0.7331 ... score_F1 = 0.0226 ... score_MCC = 0.0635  \n",
      "Count = 10 ... score_ROC = 0.7196 ... score_F1 = 0.0203 ... score_MCC = 0.0535 \n",
      "Mean ROC_AUC = 0.7183                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 8, 'gamma': '0.092', 'subsample': '0.40', 'reg_alpha': '0.031', 'reg_lambda': '0.017', 'learning_rate': '0.017', 'num_leaves': '140.000', 'colsample_bytree': '0.742', 'min_child_samples': '220.000', 'feature_fraction': '0.779', 'bagging_fraction': '0.678', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7215 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 2 ... score_ROC = 0.7357 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 3 ... score_ROC = 0.7344 ... score_F1 = 0.0000 ... score_MCC = 0.0000  \n",
      "Count = 4 ... score_ROC = 0.7313 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 5 ... score_ROC = 0.7271 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 6 ... score_ROC = 0.7338 ... score_F1 = 0.0046 ... score_MCC = 0.0471  \n",
      "Count = 7 ... score_ROC = 0.7428 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 8 ... score_ROC = 0.7393 ... score_F1 = 0.0000 ... score_MCC = 0.0000  \n",
      "Count = 9 ... score_ROC = 0.7535 ... score_F1 = 0.0000 ... score_MCC = -0.0016 \n",
      "Count = 10 ... score_ROC = 0.7373 ... score_F1 = 0.0000 ... score_MCC = -0.0027\n",
      "Mean ROC_AUC = 0.7357                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 7, 'gamma': '0.439', 'subsample': '0.90', 'reg_alpha': '0.021', 'reg_lambda': '0.046', 'learning_rate': '0.060', 'num_leaves': '100.000', 'colsample_bytree': '0.873', 'min_child_samples': '240.000', 'feature_fraction': '0.662', 'bagging_fraction': '0.510', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7225 ... score_F1 = 0.0046 ... score_MCC = 0.0317  \n",
      "Count = 2 ... score_ROC = 0.7361 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 3 ... score_ROC = 0.7362 ... score_F1 = 0.0046 ... score_MCC = 0.0277  \n",
      "Count = 4 ... score_ROC = 0.7302 ... score_F1 = 0.0069 ... score_MCC = 0.0389  \n",
      "Count = 5 ... score_ROC = 0.7268 ... score_F1 = 0.0092 ... score_MCC = 0.0531  \n",
      "Count = 6 ... score_ROC = 0.7349 ... score_F1 = 0.0092 ... score_MCC = 0.0666  \n",
      "Count = 7 ... score_ROC = 0.7447 ... score_F1 = 0.0069 ... score_MCC = 0.0577  \n",
      "Count = 8 ... score_ROC = 0.7398 ... score_F1 = 0.0115 ... score_MCC = 0.0617  \n",
      "Count = 9 ... score_ROC = 0.7535 ... score_F1 = 0.0092 ... score_MCC = 0.0531  \n",
      "Count = 10 ... score_ROC = 0.7409 ... score_F1 = 0.0023 ... score_MCC = 0.0121 \n",
      "Mean ROC_AUC = 0.7366                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 8, 'gamma': '0.017', 'subsample': '0.20', 'reg_alpha': '0.040', 'reg_lambda': '0.027', 'learning_rate': '0.051', 'num_leaves': '40.000', 'colsample_bytree': '0.608', 'min_child_samples': '120.000', 'feature_fraction': '0.583', 'bagging_fraction': '0.874', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7144 ... score_F1 = 0.0046 ... score_MCC = 0.0317  \n",
      "Count = 2 ... score_ROC = 0.7304 ... score_F1 = 0.0069 ... score_MCC = 0.0577  \n",
      "Count = 3 ... score_ROC = 0.7327 ... score_F1 = 0.0069 ... score_MCC = 0.0492  \n",
      "Count = 4 ... score_ROC = 0.7281 ... score_F1 = 0.0046 ... score_MCC = 0.0375  \n",
      "Count = 5 ... score_ROC = 0.7242 ... score_F1 = 0.0046 ... score_MCC = 0.0375  \n",
      "Count = 6 ... score_ROC = 0.7283 ... score_F1 = 0.0046 ... score_MCC = 0.0471  \n",
      "Count = 7 ... score_ROC = 0.7413 ... score_F1 = 0.0069 ... score_MCC = 0.0433  \n",
      "Count = 8 ... score_ROC = 0.7344 ... score_F1 = 0.0092 ... score_MCC = 0.0449  \n",
      "Count = 9 ... score_ROC = 0.7471 ... score_F1 = 0.0115 ... score_MCC = 0.0673  \n",
      "Count = 10 ... score_ROC = 0.7312 ... score_F1 = 0.0023 ... score_MCC = 0.0121 \n",
      "Mean ROC_AUC = 0.7312                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 8, 'gamma': '0.414', 'subsample': '0.70', 'reg_alpha': '0.020', 'reg_lambda': '0.049', 'learning_rate': '0.016', 'num_leaves': '20.000', 'colsample_bytree': '0.592', 'min_child_samples': '100.000', 'feature_fraction': '0.472', 'bagging_fraction': '0.856', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7211 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 2 ... score_ROC = 0.7344 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 3 ... score_ROC = 0.7349 ... score_F1 = 0.0000 ... score_MCC = -0.0022 \n",
      "Count = 4 ... score_ROC = 0.7326 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 5 ... score_ROC = 0.7277 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 6 ... score_ROC = 0.7347 ... score_F1 = 0.0046 ... score_MCC = 0.0471  \n",
      "Count = 7 ... score_ROC = 0.7432 ... score_F1 = 0.0000 ... score_MCC = 0.0000  \n",
      "Count = 8 ... score_ROC = 0.7375 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 9 ... score_ROC = 0.7533 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 10 ... score_ROC = 0.7396 ... score_F1 = 0.0023 ... score_MCC = 0.0143 \n",
      "Mean ROC_AUC = 0.7359                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 7, 'gamma': '0.463', 'subsample': '0.90', 'reg_alpha': '0.010', 'reg_lambda': '0.043', 'learning_rate': '0.055', 'num_leaves': '20.000', 'colsample_bytree': '0.515', 'min_child_samples': '240.000', 'feature_fraction': '0.652', 'bagging_fraction': '0.772', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7221 ... score_F1 = 0.0000 ... score_MCC = -0.0022 \n",
      "Count = 2 ... score_ROC = 0.7342 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 3 ... score_ROC = 0.7364 ... score_F1 = 0.0046 ... score_MCC = 0.0277  \n",
      "Count = 4 ... score_ROC = 0.7322 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 5 ... score_ROC = 0.7285 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 6 ... score_ROC = 0.7335 ... score_F1 = 0.0069 ... score_MCC = 0.0577  \n",
      "Count = 7 ... score_ROC = 0.7465 ... score_F1 = 0.0046 ... score_MCC = 0.0471  \n",
      "Count = 8 ... score_ROC = 0.7389 ... score_F1 = 0.0092 ... score_MCC = 0.0486  \n",
      "Count = 9 ... score_ROC = 0.7523 ... score_F1 = 0.0069 ... score_MCC = 0.0492  \n",
      "Count = 10 ... score_ROC = 0.7391 ... score_F1 = 0.0023 ... score_MCC = 0.0121 \n",
      "Mean ROC_AUC = 0.7364                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 7, 'gamma': '0.480', 'subsample': '0.90', 'reg_alpha': '0.010', 'reg_lambda': '0.043', 'learning_rate': '0.054', 'num_leaves': '240.000', 'colsample_bytree': '0.487', 'min_child_samples': '240.000', 'feature_fraction': '0.666', 'bagging_fraction': '0.774', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7225 ... score_F1 = 0.0000 ... score_MCC = -0.0022 \n",
      "Count = 2 ... score_ROC = 0.7350 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 3 ... score_ROC = 0.7360 ... score_F1 = 0.0069 ... score_MCC = 0.0389  \n",
      "Count = 4 ... score_ROC = 0.7341 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 5 ... score_ROC = 0.7280 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 6 ... score_ROC = 0.7355 ... score_F1 = 0.0069 ... score_MCC = 0.0577  \n",
      "Count = 7 ... score_ROC = 0.7456 ... score_F1 = 0.0046 ... score_MCC = 0.0471  \n",
      "Count = 8 ... score_ROC = 0.7390 ... score_F1 = 0.0046 ... score_MCC = 0.0317  \n",
      "Count = 9 ... score_ROC = 0.7535 ... score_F1 = 0.0046 ... score_MCC = 0.0375  \n",
      "Count = 10 ... score_ROC = 0.7396 ... score_F1 = 0.0023 ... score_MCC = 0.0121 \n",
      "Mean ROC_AUC = 0.7369                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 7, 'gamma': '0.514', 'subsample': '0.90', 'reg_alpha': '0.015', 'reg_lambda': '0.042', 'learning_rate': '0.052', 'num_leaves': '240.000', 'colsample_bytree': '0.436', 'min_child_samples': '240.000', 'feature_fraction': '0.711', 'bagging_fraction': '0.501', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7230 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 2 ... score_ROC = 0.7340 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 3 ... score_ROC = 0.7351 ... score_F1 = 0.0046 ... score_MCC = 0.0246  \n",
      "Count = 4 ... score_ROC = 0.7332 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 5 ... score_ROC = 0.7257 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 6 ... score_ROC = 0.7358 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 7 ... score_ROC = 0.7444 ... score_F1 = 0.0000 ... score_MCC = 0.0000  \n",
      "Count = 8 ... score_ROC = 0.7390 ... score_F1 = 0.0023 ... score_MCC = 0.0174  \n",
      "Count = 9 ... score_ROC = 0.7538 ... score_F1 = 0.0092 ... score_MCC = 0.0589  \n",
      "Count = 10 ... score_ROC = 0.7381 ... score_F1 = 0.0023 ... score_MCC = 0.0121 \n",
      "Mean ROC_AUC = 0.7362                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 7, 'gamma': '0.378', 'subsample': '0.90', 'reg_alpha': '0.011', 'reg_lambda': '0.043', 'learning_rate': '0.074', 'num_leaves': '210.000', 'colsample_bytree': '0.670', 'min_child_samples': '210.000', 'feature_fraction': '0.628', 'bagging_fraction': '0.426', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7214 ... score_F1 = 0.0023 ... score_MCC = 0.0143  \n",
      "Count = 2 ... score_ROC = 0.7326 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 3 ... score_ROC = 0.7346 ... score_F1 = 0.0092 ... score_MCC = 0.0368  \n",
      "Count = 4 ... score_ROC = 0.7302 ... score_F1 = 0.0046 ... score_MCC = 0.0277  \n",
      "Count = 5 ... score_ROC = 0.7275 ... score_F1 = 0.0069 ... score_MCC = 0.0389  \n",
      "Count = 6 ... score_ROC = 0.7301 ... score_F1 = 0.0046 ... score_MCC = 0.0471  \n",
      "Count = 7 ... score_ROC = 0.7436 ... score_F1 = 0.0046 ... score_MCC = 0.0317  \n",
      "Count = 8 ... score_ROC = 0.7365 ... score_F1 = 0.0115 ... score_MCC = 0.0534  \n",
      "Count = 9 ... score_ROC = 0.7558 ... score_F1 = 0.0115 ... score_MCC = 0.0572  \n",
      "Count = 10 ... score_ROC = 0.7379 ... score_F1 = 0.0023 ... score_MCC = 0.0121 \n",
      "Mean ROC_AUC = 0.735                                                           \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 7, 'gamma': '0.469', 'subsample': '0.90', 'reg_alpha': '0.016', 'reg_lambda': '0.028', 'learning_rate': '0.077', 'num_leaves': '190.000', 'colsample_bytree': '0.816', 'min_child_samples': '200.000', 'feature_fraction': '0.703', 'bagging_fraction': '0.781', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7211 ... score_F1 = 0.0046 ... score_MCC = 0.0246  \n",
      "Count = 2 ... score_ROC = 0.7353 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 3 ... score_ROC = 0.7334 ... score_F1 = 0.0092 ... score_MCC = 0.0449  \n",
      "Count = 4 ... score_ROC = 0.7287 ... score_F1 = 0.0046 ... score_MCC = 0.0222  \n",
      "Count = 5 ... score_ROC = 0.7277 ... score_F1 = 0.0092 ... score_MCC = 0.0418  \n",
      "Count = 6 ... score_ROC = 0.7313 ... score_F1 = 0.0092 ... score_MCC = 0.0486  \n",
      "Count = 7 ... score_ROC = 0.7436 ... score_F1 = 0.0046 ... score_MCC = 0.0471  \n",
      "Count = 8 ... score_ROC = 0.7382 ... score_F1 = 0.0138 ... score_MCC = 0.0650  \n",
      "Count = 9 ... score_ROC = 0.7557 ... score_F1 = 0.0092 ... score_MCC = 0.0449  \n",
      "Count = 10 ... score_ROC = 0.7403 ... score_F1 = 0.0069 ... score_MCC = 0.0354 \n",
      "Mean ROC_AUC = 0.7355                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 7, 'gamma': '0.574', 'subsample': '0.90', 'reg_alpha': '0.025', 'reg_lambda': '0.040', 'learning_rate': '0.036', 'num_leaves': '170.000', 'colsample_bytree': '0.484', 'min_child_samples': '150.000', 'feature_fraction': '0.623', 'bagging_fraction': '0.772', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7237 ... score_F1 = 0.0000 ... score_MCC = 0.0000  \n",
      "Count = 2 ... score_ROC = 0.7338 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 3 ... score_ROC = 0.7347 ... score_F1 = 0.0000 ... score_MCC = -0.0016 \n",
      "Count = 4 ... score_ROC = 0.7325 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 5 ... score_ROC = 0.7268 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 6 ... score_ROC = 0.7354 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 7 ... score_ROC = 0.7449 ... score_F1 = 0.0000 ... score_MCC = 0.0000  \n",
      "Count = 8 ... score_ROC = 0.7379 ... score_F1 = 0.0069 ... score_MCC = 0.0577  \n",
      "Count = 9 ... score_ROC = 0.7540 ... score_F1 = 0.0092 ... score_MCC = 0.0589  \n",
      "Count = 10 ... score_ROC = 0.7390 ... score_F1 = 0.0023 ... score_MCC = 0.0143 \n",
      "Mean ROC_AUC = 0.7363                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 6, 'gamma': '0.186', 'subsample': '0.90', 'reg_alpha': '0.034', 'reg_lambda': '0.044', 'learning_rate': '0.124', 'num_leaves': '160.000', 'colsample_bytree': '0.669', 'min_child_samples': '180.000', 'feature_fraction': '0.554', 'bagging_fraction': '0.529', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7230 ... score_F1 = 0.0046 ... score_MCC = 0.0246  \n",
      "Count = 2 ... score_ROC = 0.7340 ... score_F1 = 0.0046 ... score_MCC = 0.0222  \n",
      "Count = 3 ... score_ROC = 0.7311 ... score_F1 = 0.0115 ... score_MCC = 0.0449  \n",
      "Count = 4 ... score_ROC = 0.7266 ... score_F1 = 0.0092 ... score_MCC = 0.0449  \n",
      "Count = 5 ... score_ROC = 0.7277 ... score_F1 = 0.0023 ... score_MCC = 0.0174  \n",
      "Count = 6 ... score_ROC = 0.7328 ... score_F1 = 0.0092 ... score_MCC = 0.0531  \n",
      "Count = 7 ... score_ROC = 0.7385 ... score_F1 = 0.0069 ... score_MCC = 0.0389  \n",
      "Count = 8 ... score_ROC = 0.7369 ... score_F1 = 0.0046 ... score_MCC = 0.0202  \n",
      "Count = 9 ... score_ROC = 0.7505 ... score_F1 = 0.0115 ... score_MCC = 0.0474  \n",
      "Count = 10 ... score_ROC = 0.7348 ... score_F1 = 0.0092 ... score_MCC = 0.0449 \n",
      "Mean ROC_AUC = 0.7336                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 7, 'gamma': '0.492', 'subsample': '0.90', 'reg_alpha': '0.010', 'reg_lambda': '0.046', 'learning_rate': '0.072', 'num_leaves': '230.000', 'colsample_bytree': '0.534', 'min_child_samples': '130.000', 'feature_fraction': '0.723', 'bagging_fraction': '0.483', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7198 ... score_F1 = 0.0046 ... score_MCC = 0.0276  \n",
      "Count = 2 ... score_ROC = 0.7353 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 3 ... score_ROC = 0.7342 ... score_F1 = 0.0069 ... score_MCC = 0.0354  \n",
      "Count = 4 ... score_ROC = 0.7300 ... score_F1 = 0.0023 ... score_MCC = 0.0121  \n",
      "Count = 5 ... score_ROC = 0.7282 ... score_F1 = 0.0046 ... score_MCC = 0.0317  \n",
      "Count = 6 ... score_ROC = 0.7345 ... score_F1 = 0.0069 ... score_MCC = 0.0577  \n",
      "Count = 7 ... score_ROC = 0.7467 ... score_F1 = 0.0046 ... score_MCC = 0.0471  \n",
      "Count = 8 ... score_ROC = 0.7398 ... score_F1 = 0.0092 ... score_MCC = 0.0486  \n",
      "Count = 9 ... score_ROC = 0.7547 ... score_F1 = 0.0092 ... score_MCC = 0.0486  \n",
      "Count = 10 ... score_ROC = 0.7410 ... score_F1 = 0.0046 ... score_MCC = 0.0246 \n",
      "Mean ROC_AUC = 0.7364                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 6, 'gamma': '0.385', 'subsample': '0.90', 'reg_alpha': '0.017', 'reg_lambda': '0.040', 'learning_rate': '0.033', 'num_leaves': '240.000', 'colsample_bytree': '0.421', 'min_child_samples': '140.000', 'feature_fraction': '0.662', 'bagging_fraction': '0.441', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7213 ... score_F1 = 0.0000 ... score_MCC = -0.0016 \n",
      "Count = 2 ... score_ROC = 0.7324 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 3 ... score_ROC = 0.7328 ... score_F1 = 0.0000 ... score_MCC = -0.0022 \n",
      "Count = 4 ... score_ROC = 0.7317 ... score_F1 = 0.0000 ... score_MCC = -0.0016 \n",
      "Count = 5 ... score_ROC = 0.7261 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 6 ... score_ROC = 0.7348 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 7 ... score_ROC = 0.7425 ... score_F1 = 0.0000 ... score_MCC = 0.0000  \n",
      "Count = 8 ... score_ROC = 0.7363 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 9 ... score_ROC = 0.7545 ... score_F1 = 0.0000 ... score_MCC = 0.0000  \n",
      "Count = 10 ... score_ROC = 0.7383 ... score_F1 = 0.0023 ... score_MCC = 0.0143 \n",
      "Mean ROC_AUC = 0.7351                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 7, 'gamma': '0.324', 'subsample': '0.60', 'reg_alpha': '0.023', 'reg_lambda': '0.012', 'learning_rate': '0.083', 'num_leaves': '60.000', 'colsample_bytree': '0.845', 'min_child_samples': '240.000', 'feature_fraction': '0.625', 'bagging_fraction': '0.547', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7209 ... score_F1 = 0.0046 ... score_MCC = 0.0222  \n",
      "Count = 2 ... score_ROC = 0.7325 ... score_F1 = 0.0069 ... score_MCC = 0.0433  \n",
      "Count = 3 ... score_ROC = 0.7348 ... score_F1 = 0.0092 ... score_MCC = 0.0368  \n",
      "Count = 4 ... score_ROC = 0.7300 ... score_F1 = 0.0069 ... score_MCC = 0.0354  \n",
      "Count = 5 ... score_ROC = 0.7227 ... score_F1 = 0.0069 ... score_MCC = 0.0301  \n",
      "Count = 6 ... score_ROC = 0.7338 ... score_F1 = 0.0069 ... score_MCC = 0.0354  \n",
      "Count = 7 ... score_ROC = 0.7430 ... score_F1 = 0.0092 ... score_MCC = 0.0589  \n",
      "Count = 8 ... score_ROC = 0.7364 ... score_F1 = 0.0046 ... score_MCC = 0.0202  \n",
      "Count = 9 ... score_ROC = 0.7545 ... score_F1 = 0.0069 ... score_MCC = 0.0354  \n",
      "Count = 10 ... score_ROC = 0.7387 ... score_F1 = 0.0092 ... score_MCC = 0.0391 \n",
      "Mean ROC_AUC = 0.7347                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 6, 'gamma': '0.433', 'subsample': '0.70', 'reg_alpha': '0.014', 'reg_lambda': '0.048', 'learning_rate': '0.063', 'num_leaves': '100.000', 'colsample_bytree': '0.479', 'min_child_samples': '240.000', 'feature_fraction': '0.677', 'bagging_fraction': '0.616', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7225 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 2 ... score_ROC = 0.7369 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 3 ... score_ROC = 0.7350 ... score_F1 = 0.0023 ... score_MCC = 0.0174  \n",
      "Count = 4 ... score_ROC = 0.7338 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 5 ... score_ROC = 0.7264 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 6 ... score_ROC = 0.7337 ... score_F1 = 0.0069 ... score_MCC = 0.0577  \n",
      "Count = 7 ... score_ROC = 0.7444 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 8 ... score_ROC = 0.7406 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 9 ... score_ROC = 0.7542 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 10 ... score_ROC = 0.7410 ... score_F1 = 0.0023 ... score_MCC = 0.0121 \n",
      "Mean ROC_AUC = 0.7369                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 6, 'gamma': '0.611', 'subsample': '0.70', 'reg_alpha': '0.013', 'reg_lambda': '0.050', 'learning_rate': '0.123', 'num_leaves': '50.000', 'colsample_bytree': '0.484', 'min_child_samples': '130.000', 'feature_fraction': '0.699', 'bagging_fraction': '0.797', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7215 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 2 ... score_ROC = 0.7305 ... score_F1 = 0.0069 ... score_MCC = 0.0433  \n",
      "Count = 3 ... score_ROC = 0.7296 ... score_F1 = 0.0092 ... score_MCC = 0.0391  \n",
      "Count = 4 ... score_ROC = 0.7243 ... score_F1 = 0.0092 ... score_MCC = 0.0418  \n",
      "Count = 5 ... score_ROC = 0.7228 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 6 ... score_ROC = 0.7315 ... score_F1 = 0.0092 ... score_MCC = 0.0391  \n",
      "Count = 7 ... score_ROC = 0.7394 ... score_F1 = 0.0069 ... score_MCC = 0.0577  \n",
      "Count = 8 ... score_ROC = 0.7310 ... score_F1 = 0.0092 ... score_MCC = 0.0368  \n",
      "Count = 9 ... score_ROC = 0.7532 ... score_F1 = 0.0092 ... score_MCC = 0.0531  \n",
      "Count = 10 ... score_ROC = 0.7361 ... score_F1 = 0.0023 ... score_MCC = 0.0121 \n",
      "Mean ROC_AUC = 0.732                                                           \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 6, 'gamma': '0.398', 'subsample': '0.70', 'reg_alpha': '0.049', 'reg_lambda': '0.025', 'learning_rate': '0.039', 'num_leaves': '70.000', 'colsample_bytree': '0.371', 'min_child_samples': '240.000', 'feature_fraction': '0.682', 'bagging_fraction': '0.618', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7223 ... score_F1 = 0.0000 ... score_MCC = -0.0016 \n",
      "Count = 2 ... score_ROC = 0.7350 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 3 ... score_ROC = 0.7334 ... score_F1 = 0.0000 ... score_MCC = -0.0016 \n",
      "Count = 4 ... score_ROC = 0.7321 ... score_F1 = 0.0000 ... score_MCC = -0.0016 \n",
      "Count = 5 ... score_ROC = 0.7260 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 6 ... score_ROC = 0.7351 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 7 ... score_ROC = 0.7444 ... score_F1 = 0.0000 ... score_MCC = 0.0000  \n",
      "Count = 8 ... score_ROC = 0.7363 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 9 ... score_ROC = 0.7540 ... score_F1 = 0.0000 ... score_MCC = -0.0016 \n",
      "Count = 10 ... score_ROC = 0.7398 ... score_F1 = 0.0023 ... score_MCC = 0.0143 \n",
      "Mean ROC_AUC = 0.7358                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 6, 'gamma': '0.544', 'subsample': '0.70', 'reg_alpha': '0.036', 'reg_lambda': '0.050', 'learning_rate': '0.090', 'num_leaves': '240.000', 'colsample_bytree': '0.417', 'min_child_samples': '210.000', 'feature_fraction': '0.733', 'bagging_fraction': '0.734', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7218 ... score_F1 = 0.0023 ... score_MCC = 0.0143  \n",
      "Count = 2 ... score_ROC = 0.7348 ... score_F1 = 0.0046 ... score_MCC = 0.0471  \n",
      "Count = 3 ... score_ROC = 0.7351 ... score_F1 = 0.0046 ... score_MCC = 0.0317  \n",
      "Count = 4 ... score_ROC = 0.7326 ... score_F1 = 0.0023 ... score_MCC = 0.0104  \n",
      "Count = 5 ... score_ROC = 0.7272 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 6 ... score_ROC = 0.7366 ... score_F1 = 0.0092 ... score_MCC = 0.0666  \n",
      "Count = 7 ... score_ROC = 0.7437 ... score_F1 = 0.0046 ... score_MCC = 0.0471  \n",
      "Count = 8 ... score_ROC = 0.7378 ... score_F1 = 0.0069 ... score_MCC = 0.0433  \n",
      "Count = 9 ... score_ROC = 0.7531 ... score_F1 = 0.0069 ... score_MCC = 0.0433  \n",
      "Count = 10 ... score_ROC = 0.7395 ... score_F1 = 0.0046 ... score_MCC = 0.0277 \n",
      "Mean ROC_AUC = 0.7362                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 6, 'gamma': '0.347', 'subsample': '0.80', 'reg_alpha': '0.013', 'reg_lambda': '0.041', 'learning_rate': '0.115', 'num_leaves': '100.000', 'colsample_bytree': '0.642', 'min_child_samples': '200.000', 'feature_fraction': '0.547', 'bagging_fraction': '0.807', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7202 ... score_F1 = 0.0046 ... score_MCC = 0.0202  \n",
      "Count = 2 ... score_ROC = 0.7317 ... score_F1 = 0.0046 ... score_MCC = 0.0375  \n",
      "Count = 3 ... score_ROC = 0.7280 ... score_F1 = 0.0069 ... score_MCC = 0.0281  \n",
      "Count = 4 ... score_ROC = 0.7272 ... score_F1 = 0.0092 ... score_MCC = 0.0486  \n",
      "Count = 5 ... score_ROC = 0.7257 ... score_F1 = 0.0046 ... score_MCC = 0.0277  \n",
      "Count = 6 ... score_ROC = 0.7320 ... score_F1 = 0.0184 ... score_MCC = 0.0883  \n",
      "Count = 7 ... score_ROC = 0.7435 ... score_F1 = 0.0069 ... score_MCC = 0.0577  \n",
      "Count = 8 ... score_ROC = 0.7369 ... score_F1 = 0.0115 ... score_MCC = 0.0502  \n",
      "Count = 9 ... score_ROC = 0.7520 ... score_F1 = 0.0115 ... score_MCC = 0.0572  \n",
      "Count = 10 ... score_ROC = 0.7359 ... score_F1 = 0.0092 ... score_MCC = 0.0449 \n",
      "Mean ROC_AUC = 0.7333                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 6, 'gamma': '0.278', 'subsample': '0.40', 'reg_alpha': '0.019', 'reg_lambda': '0.031', 'learning_rate': '0.062', 'num_leaves': '150.000', 'colsample_bytree': '0.500', 'min_child_samples': '170.000', 'feature_fraction': '0.598', 'bagging_fraction': '0.576', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7221 ... score_F1 = 0.0023 ... score_MCC = 0.0174  \n",
      "Count = 2 ... score_ROC = 0.7355 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 3 ... score_ROC = 0.7368 ... score_F1 = 0.0046 ... score_MCC = 0.0317  \n",
      "Count = 4 ... score_ROC = 0.7314 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 5 ... score_ROC = 0.7251 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 6 ... score_ROC = 0.7323 ... score_F1 = 0.0115 ... score_MCC = 0.0745  \n",
      "Count = 7 ... score_ROC = 0.7477 ... score_F1 = 0.0046 ... score_MCC = 0.0471  \n",
      "Count = 8 ... score_ROC = 0.7377 ... score_F1 = 0.0069 ... score_MCC = 0.0492  \n",
      "Count = 9 ... score_ROC = 0.7509 ... score_F1 = 0.0046 ... score_MCC = 0.0471  \n",
      "Count = 10 ... score_ROC = 0.7391 ... score_F1 = 0.0023 ... score_MCC = 0.0121 \n",
      "Mean ROC_AUC = 0.7359                                                          \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 7, 'gamma': '0.186', 'subsample': '0.70', 'reg_alpha': '0.015', 'reg_lambda': '0.036', 'learning_rate': '0.045', 'num_leaves': '110.000', 'colsample_bytree': '0.558', 'min_child_samples': '160.000', 'feature_fraction': '0.574', 'bagging_fraction': '0.745', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7229 ... score_F1 = 0.0000 ... score_MCC = -0.0022 \n",
      "Count = 2 ... score_ROC = 0.7355 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 3 ... score_ROC = 0.7340 ... score_F1 = 0.0023 ... score_MCC = 0.0174  \n",
      "Count = 4 ... score_ROC = 0.7342 ... score_F1 = 0.0023 ... score_MCC = 0.0224  \n",
      "Count = 5 ... score_ROC = 0.7280 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 6 ... score_ROC = 0.7335 ... score_F1 = 0.0023 ... score_MCC = 0.0333  \n",
      "Count = 7 ... score_ROC = 0.7456 ... score_F1 = 0.0069 ... score_MCC = 0.0577  \n",
      "Count = 8 ... score_ROC = 0.7391 ... score_F1 = 0.0046 ... score_MCC = 0.0375  \n",
      "Count = 9 ... score_ROC = 0.7558 ... score_F1 = 0.0069 ... score_MCC = 0.0433  \n",
      "Count = 10 ... score_ROC = 0.7412 ... score_F1 = 0.0023 ... score_MCC = 0.0121 \n",
      "Mean ROC_AUC = 0.737                                                           \n",
      "#########################                                                      \n",
      "Params = {'max_depth': 7, 'gamma': '0.142', 'subsample': '0.70', 'reg_alpha': '0.028', 'reg_lambda': '0.036', 'learning_rate': '0.027', 'num_leaves': '130.000', 'colsample_bytree': '0.540', 'min_child_samples': '160.000', 'feature_fraction': '0.516', 'bagging_fraction': '0.746', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7211 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 2 ... score_ROC = 0.7347 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 3 ... score_ROC = 0.7353 ... score_F1 = 0.0000 ... score_MCC = -0.0022\n",
      "Count = 4 ... score_ROC = 0.7328 ... score_F1 = 0.0023 ... score_MCC = 0.0224 \n",
      "Count = 5 ... score_ROC = 0.7279 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 6 ... score_ROC = 0.7338 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 7 ... score_ROC = 0.7441 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 8 ... score_ROC = 0.7361 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 9 ... score_ROC = 0.7529 ... score_F1 = 0.0046 ... score_MCC = 0.0471 \n",
      "Count = 10 ... score_ROC = 0.7379 ... score_F1 = 0.0023 ... score_MCC = 0.0143\n",
      "Mean ROC_AUC = 0.7356                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 7, 'gamma': '0.098', 'subsample': '0.60', 'reg_alpha': '0.023', 'reg_lambda': '0.038', 'learning_rate': '0.047', 'num_leaves': '110.000', 'colsample_bytree': '0.308', 'min_child_samples': '160.000', 'feature_fraction': '0.577', 'bagging_fraction': '0.702', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7196 ... score_F1 = 0.0000 ... score_MCC = -0.0016\n",
      "Count = 2 ... score_ROC = 0.7362 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 3 ... score_ROC = 0.7332 ... score_F1 = 0.0023 ... score_MCC = 0.0174 \n",
      "Count = 4 ... score_ROC = 0.7328 ... score_F1 = 0.0000 ... score_MCC = -0.0016\n",
      "Count = 5 ... score_ROC = 0.7232 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 6 ... score_ROC = 0.7345 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 7 ... score_ROC = 0.7433 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 8 ... score_ROC = 0.7378 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 9 ... score_ROC = 0.7525 ... score_F1 = 0.0046 ... score_MCC = 0.0375 \n",
      "Count = 10 ... score_ROC = 0.7377 ... score_F1 = 0.0023 ... score_MCC = 0.0143\n",
      "Mean ROC_AUC = 0.7351                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 7, 'gamma': '0.157', 'subsample': '0.80', 'reg_alpha': '0.015', 'reg_lambda': '0.035', 'learning_rate': '0.141', 'num_leaves': '110.000', 'colsample_bytree': '0.714', 'min_child_samples': '160.000', 'feature_fraction': '0.503', 'bagging_fraction': '0.888', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7163 ... score_F1 = 0.0046 ... score_MCC = 0.0119 \n",
      "Count = 2 ... score_ROC = 0.7225 ... score_F1 = 0.0092 ... score_MCC = 0.0391 \n",
      "Count = 3 ... score_ROC = 0.7270 ... score_F1 = 0.0137 ... score_MCC = 0.0443 \n",
      "Count = 4 ... score_ROC = 0.7250 ... score_F1 = 0.0159 ... score_MCC = 0.0492 \n",
      "Count = 5 ... score_ROC = 0.7181 ... score_F1 = 0.0091 ... score_MCC = 0.0314 \n",
      "Count = 6 ... score_ROC = 0.7215 ... score_F1 = 0.0114 ... score_MCC = 0.0373 \n",
      "Count = 7 ... score_ROC = 0.7320 ... score_F1 = 0.0183 ... score_MCC = 0.0660 \n",
      "Count = 8 ... score_ROC = 0.7288 ... score_F1 = 0.0159 ... score_MCC = 0.0527 \n",
      "Count = 9 ... score_ROC = 0.7461 ... score_F1 = 0.0137 ... score_MCC = 0.0550 \n",
      "Count = 10 ... score_ROC = 0.7232 ... score_F1 = 0.0205 ... score_MCC = 0.0722\n",
      "Mean ROC_AUC = 0.7261                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 7, 'gamma': '0.219', 'subsample': '0.40', 'reg_alpha': '0.011', 'reg_lambda': '0.030', 'learning_rate': '0.046', 'num_leaves': '80.000', 'colsample_bytree': '0.563', 'min_child_samples': '120.000', 'feature_fraction': '0.564', 'bagging_fraction': '0.819', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7241 ... score_F1 = 0.0000 ... score_MCC = -0.0022\n",
      "Count = 2 ... score_ROC = 0.7359 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 3 ... score_ROC = 0.7347 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 4 ... score_ROC = 0.7316 ... score_F1 = 0.0046 ... score_MCC = 0.0317 \n",
      "Count = 5 ... score_ROC = 0.7224 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 6 ... score_ROC = 0.7329 ... score_F1 = 0.0115 ... score_MCC = 0.0745 \n",
      "Count = 7 ... score_ROC = 0.7424 ... score_F1 = 0.0046 ... score_MCC = 0.0471 \n",
      "Count = 8 ... score_ROC = 0.7395 ... score_F1 = 0.0046 ... score_MCC = 0.0317 \n",
      "Count = 9 ... score_ROC = 0.7544 ... score_F1 = 0.0046 ... score_MCC = 0.0375 \n",
      "Count = 10 ... score_ROC = 0.7403 ... score_F1 = 0.0023 ... score_MCC = 0.0121\n",
      "Mean ROC_AUC = 0.7358                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.060', 'subsample': '0.20', 'reg_alpha': '0.026', 'reg_lambda': '0.024', 'learning_rate': '0.002', 'num_leaves': '110.000', 'colsample_bytree': '0.345', 'min_child_samples': '110.000', 'feature_fraction': '0.607', 'bagging_fraction': '0.697', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7181 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 2 ... score_ROC = 0.7316 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 3 ... score_ROC = 0.7322 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 4 ... score_ROC = 0.7272 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 5 ... score_ROC = 0.7209 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 6 ... score_ROC = 0.7307 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 7 ... score_ROC = 0.7440 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 8 ... score_ROC = 0.7314 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 9 ... score_ROC = 0.7487 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 10 ... score_ROC = 0.7323 ... score_F1 = 0.0000 ... score_MCC = 0.0000\n",
      "Mean ROC_AUC = 0.7317                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 7, 'gamma': '0.264', 'subsample': '0.70', 'reg_alpha': '0.037', 'reg_lambda': '0.045', 'learning_rate': '0.070', 'num_leaves': '220.000', 'colsample_bytree': '0.618', 'min_child_samples': '190.000', 'feature_fraction': '0.521', 'bagging_fraction': '0.648', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7213 ... score_F1 = 0.0023 ... score_MCC = 0.0143 \n",
      "Count = 2 ... score_ROC = 0.7362 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 3 ... score_ROC = 0.7317 ... score_F1 = 0.0092 ... score_MCC = 0.0418 \n",
      "Count = 4 ... score_ROC = 0.7313 ... score_F1 = 0.0023 ... score_MCC = 0.0143 \n",
      "Count = 5 ... score_ROC = 0.7243 ... score_F1 = 0.0069 ... score_MCC = 0.0389 \n",
      "Count = 6 ... score_ROC = 0.7352 ... score_F1 = 0.0046 ... score_MCC = 0.0471 \n",
      "Count = 7 ... score_ROC = 0.7453 ... score_F1 = 0.0092 ... score_MCC = 0.0666 \n",
      "Count = 8 ... score_ROC = 0.7382 ... score_F1 = 0.0023 ... score_MCC = 0.0104 \n",
      "Count = 9 ... score_ROC = 0.7524 ... score_F1 = 0.0069 ... score_MCC = 0.0389 \n",
      "Count = 10 ... score_ROC = 0.7410 ... score_F1 = 0.0046 ... score_MCC = 0.0246\n",
      "Mean ROC_AUC = 0.7357                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.185', 'subsample': '0.60', 'reg_alpha': '0.019', 'reg_lambda': '0.019', 'learning_rate': '0.108', 'num_leaves': '200.000', 'colsample_bytree': '0.458', 'min_child_samples': '180.000', 'feature_fraction': '0.444', 'bagging_fraction': '0.751', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7160 ... score_F1 = 0.0092 ... score_MCC = 0.0348 \n",
      "Count = 2 ... score_ROC = 0.7300 ... score_F1 = 0.0069 ... score_MCC = 0.0354 \n",
      "Count = 3 ... score_ROC = 0.7245 ... score_F1 = 0.0114 ... score_MCC = 0.0389 \n",
      "Count = 4 ... score_ROC = 0.7257 ... score_F1 = 0.0092 ... score_MCC = 0.0418 \n",
      "Count = 5 ... score_ROC = 0.7218 ... score_F1 = 0.0091 ... score_MCC = 0.0286 \n",
      "Count = 6 ... score_ROC = 0.7283 ... score_F1 = 0.0182 ... score_MCC = 0.0635 \n",
      "Count = 7 ... score_ROC = 0.7329 ... score_F1 = 0.0092 ... score_MCC = 0.0531 \n",
      "Count = 8 ... score_ROC = 0.7280 ... score_F1 = 0.0114 ... score_MCC = 0.0358 \n",
      "Count = 9 ... score_ROC = 0.7406 ... score_F1 = 0.0092 ... score_MCC = 0.0418 \n",
      "Count = 10 ... score_ROC = 0.7246 ... score_F1 = 0.0091 ... score_MCC = 0.0299\n",
      "Mean ROC_AUC = 0.7272                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 7, 'gamma': '0.310', 'subsample': '0.50', 'reg_alpha': '0.029', 'reg_lambda': '0.038', 'learning_rate': '0.017', 'num_leaves': '90.000', 'colsample_bytree': '0.572', 'min_child_samples': '140.000', 'feature_fraction': '0.479', 'bagging_fraction': '0.580', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7212 ... score_F1 = 0.0000 ... score_MCC = -0.0016\n",
      "Count = 2 ... score_ROC = 0.7341 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 3 ... score_ROC = 0.7327 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 4 ... score_ROC = 0.7323 ... score_F1 = 0.0000 ... score_MCC = -0.0016\n",
      "Count = 5 ... score_ROC = 0.7259 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 6 ... score_ROC = 0.7337 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 7 ... score_ROC = 0.7445 ... score_F1 = 0.0000 ... score_MCC = 0.0000 \n",
      "Count = 8 ... score_ROC = 0.7372 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 9 ... score_ROC = 0.7523 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 10 ... score_ROC = 0.7385 ... score_F1 = 0.0023 ... score_MCC = 0.0143\n",
      "Mean ROC_AUC = 0.7353                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.636', 'subsample': '0.80', 'reg_alpha': '0.015', 'reg_lambda': '0.035', 'learning_rate': '0.086', 'num_leaves': '120.000', 'colsample_bytree': '0.392', 'min_child_samples': '150.000', 'feature_fraction': '0.798', 'bagging_fraction': '0.652', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7180 ... score_F1 = 0.0069 ... score_MCC = 0.0388 \n",
      "Count = 2 ... score_ROC = 0.7365 ... score_F1 = 0.0023 ... score_MCC = 0.0174 \n",
      "Count = 3 ... score_ROC = 0.7319 ... score_F1 = 0.0069 ... score_MCC = 0.0301 \n",
      "Count = 4 ... score_ROC = 0.7262 ... score_F1 = 0.0092 ... score_MCC = 0.0486 \n",
      "Count = 5 ... score_ROC = 0.7269 ... score_F1 = 0.0046 ... score_MCC = 0.0246 \n",
      "Count = 6 ... score_ROC = 0.7304 ... score_F1 = 0.0115 ... score_MCC = 0.0617 \n",
      "Count = 7 ... score_ROC = 0.7403 ... score_F1 = 0.0138 ... score_MCC = 0.0650 \n",
      "Count = 8 ... score_ROC = 0.7352 ... score_F1 = 0.0069 ... score_MCC = 0.0354 \n",
      "Count = 9 ... score_ROC = 0.7458 ... score_F1 = 0.0138 ... score_MCC = 0.0695 \n",
      "Count = 10 ... score_ROC = 0.7384 ... score_F1 = 0.0069 ... score_MCC = 0.0301\n",
      "Mean ROC_AUC = 0.733                                                          \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 7, 'gamma': '0.233', 'subsample': '0.20', 'reg_alpha': '0.032', 'reg_lambda': '0.032', 'learning_rate': '0.042', 'num_leaves': '140.000', 'colsample_bytree': '0.635', 'min_child_samples': '160.000', 'feature_fraction': '0.633', 'bagging_fraction': '0.826', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7186 ... score_F1 = 0.0023 ... score_MCC = 0.0224 \n",
      "Count = 2 ... score_ROC = 0.7337 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 3 ... score_ROC = 0.7335 ... score_F1 = 0.0023 ... score_MCC = 0.0224 \n",
      "Count = 4 ... score_ROC = 0.7305 ... score_F1 = 0.0046 ... score_MCC = 0.0317 \n",
      "Count = 5 ... score_ROC = 0.7227 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 6 ... score_ROC = 0.7333 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 7 ... score_ROC = 0.7430 ... score_F1 = 0.0069 ... score_MCC = 0.0492 \n",
      "Count = 8 ... score_ROC = 0.7353 ... score_F1 = 0.0023 ... score_MCC = 0.0174 \n",
      "Count = 9 ... score_ROC = 0.7507 ... score_F1 = 0.0023 ... score_MCC = 0.0224 \n",
      "Count = 10 ... score_ROC = 0.7341 ... score_F1 = 0.0023 ... score_MCC = 0.0143\n",
      "Mean ROC_AUC = 0.7335                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 7, 'gamma': '0.255', 'subsample': '0.40', 'reg_alpha': '0.050', 'reg_lambda': '0.014', 'learning_rate': '0.176', 'num_leaves': '40.000', 'colsample_bytree': '0.529', 'min_child_samples': '230.000', 'feature_fraction': '0.604', 'bagging_fraction': '0.863', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7033 ... score_F1 = 0.0089 ... score_MCC = 0.0152 \n",
      "Count = 2 ... score_ROC = 0.7069 ... score_F1 = 0.0203 ... score_MCC = 0.0522 \n",
      "Count = 3 ... score_ROC = 0.7177 ... score_F1 = 0.0157 ... score_MCC = 0.0369 \n",
      "Count = 4 ... score_ROC = 0.7073 ... score_F1 = 0.0178 ... score_MCC = 0.0356 \n",
      "Count = 5 ... score_ROC = 0.7018 ... score_F1 = 0.0180 ... score_MCC = 0.0433 \n",
      "Count = 6 ... score_ROC = 0.7049 ... score_F1 = 0.0247 ... score_MCC = 0.0602 \n",
      "Count = 7 ... score_ROC = 0.7146 ... score_F1 = 0.0246 ... score_MCC = 0.0556 \n",
      "Count = 8 ... score_ROC = 0.7070 ... score_F1 = 0.0112 ... score_MCC = 0.0213 \n",
      "Count = 9 ... score_ROC = 0.7301 ... score_F1 = 0.0135 ... score_MCC = 0.0312 \n",
      "Count = 10 ... score_ROC = 0.7152 ... score_F1 = 0.0181 ... score_MCC = 0.0479\n",
      "Mean ROC_AUC = 0.7109                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 8, 'gamma': '0.068', 'subsample': '0.70', 'reg_alpha': '0.012', 'reg_lambda': '0.028', 'learning_rate': '0.029', 'num_leaves': '60.000', 'colsample_bytree': '0.686', 'min_child_samples': '170.000', 'feature_fraction': '0.754', 'bagging_fraction': '0.677', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7225 ... score_F1 = 0.0000 ... score_MCC = -0.0032\n",
      "Count = 2 ... score_ROC = 0.7368 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 3 ... score_ROC = 0.7375 ... score_F1 = 0.0000 ... score_MCC = -0.0022\n",
      "Count = 4 ... score_ROC = 0.7325 ... score_F1 = 0.0023 ... score_MCC = 0.0174 \n",
      "Count = 5 ... score_ROC = 0.7275 ... score_F1 = 0.0023 ... score_MCC = 0.0333 \n",
      "Count = 6 ... score_ROC = 0.7330 ... score_F1 = 0.0069 ... score_MCC = 0.0577 \n",
      "Count = 7 ... score_ROC = 0.7446 ... score_F1 = 0.0046 ... score_MCC = 0.0471 \n",
      "Count = 8 ... score_ROC = 0.7386 ... score_F1 = 0.0069 ... score_MCC = 0.0492 \n",
      "Count = 9 ... score_ROC = 0.7559 ... score_F1 = 0.0069 ... score_MCC = 0.0433 \n",
      "Count = 10 ... score_ROC = 0.7375 ... score_F1 = 0.0023 ... score_MCC = 0.0143\n",
      "Mean ROC_AUC = 0.7366                                                         \n",
      "#########################                                                     \n",
      "Params = {'max_depth': 7, 'gamma': '0.354', 'subsample': '0.50', 'reg_alpha': '0.047', 'reg_lambda': '0.042', 'learning_rate': '0.148', 'num_leaves': '210.000', 'colsample_bytree': '0.783', 'min_child_samples': '160.000', 'feature_fraction': '0.644', 'bagging_fraction': '0.748', 'objective': 'binary:logistic', 'eval_metric': 'error'}\n",
      "Count = 1 ... score_ROC = 0.7109 ... score_F1 = 0.0091 ... score_MCC = 0.0241 \n",
      "Count = 2 ... score_ROC = 0.7091 ... score_F1 = 0.0091 ... score_MCC = 0.0286 \n",
      "Count = 3 ... score_ROC = 0.7229 ... score_F1 = 0.0203 ... score_MCC = 0.0564 \n",
      "Count = 4 ... score_ROC = 0.7128 ... score_F1 = 0.0113 ... score_MCC = 0.0279 \n",
      "Count = 5 ... score_ROC = 0.7177 ... score_F1 = 0.0136 ... score_MCC = 0.0411 \n",
      "Count = 6 ... score_ROC = 0.7163 ... score_F1 = 0.0225 ... score_MCC = 0.0604 \n",
      "Count = 7 ... score_ROC = 0.7258 ... score_F1 = 0.0205 ... score_MCC = 0.0673 \n",
      "Count = 8 ... score_ROC = 0.7164 ... score_F1 = 0.0180 ... score_MCC = 0.0455 \n",
      "Count = 9 ... score_ROC = 0.7318 ... score_F1 = 0.0137 ... score_MCC = 0.0426 \n",
      "Count = 10 ... score_ROC = 0.7211 ... score_F1 = 0.0113 ... score_MCC = 0.0298\n",
      "Mean ROC_AUC = 0.7185                                                         \n",
      "100%|| 50/50 [22:44<00:00, 27.29s/it, best loss: -0.736971184776161]\n",
      "CPU times: user 18min 1s, sys: 4min 39s, total: 22min 41s\n",
      "Wall time: 22min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set algoritm parameters\n",
    "best = fmin(fn = hyperparameter_tuning,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 50)\n",
    "\n",
    "# Print best parameters\n",
    "best_params = space_eval(space, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45269     1]\n",
      " [ 2248     3]]\n"
     ]
    }
   ],
   "source": [
    "# final chosen parameter\n",
    "params = {'max_depth': 7, \n",
    "          'gamma': '0.186', \n",
    "          'subsample': '0.70', \n",
    "          'reg_alpha': '0.015', \n",
    "          'reg_lambda': '0.036', \n",
    "          'learning_rate': '0.045', \n",
    "          'num_leaves': '110.000', \n",
    "          'colsample_bytree': '0.558', \n",
    "          'min_child_samples': '160.000', \n",
    "          'feature_fraction': '0.574', \n",
    "          'bagging_fraction': '0.745', \n",
    "          'objective': 'binary:logistic', \n",
    "          'eval_metric': 'error'}\n",
    "\n",
    "# define the classifier\n",
    "xgb_clf = xgb.XGBClassifier(random_state = 42, \n",
    "                            verbose = True, \n",
    "                            tree_method = \"gpu_hist\",\n",
    "                            **params)\n",
    "\n",
    "# fit the classifier\n",
    "xgb_clf.fit(x_train, y_train)\n",
    "\n",
    "# encoding the x_test\n",
    "x_test = woe_transform(x_test, categorical_column = \"app_code\", encoder_dict = app_code_dict)\n",
    "x_test = woe_transform(x_test, categorical_column = \"count_unique_app\", encoder_dict = count_unique_app_dict)\n",
    "\n",
    "# predict with the trained classifier\n",
    "preds = xgb_clf.predict(x_test)\n",
    "\n",
    "# printing the confusion matrix\n",
    "con_mat = confusion_matrix(y_test.values, preds)\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Looking at the above *confusion matrix*, two conclusions can be drawn:-\n",
    "- the number of false negatives is insanely high.\n",
    "- the hyperparameter tuning may not give us the good performance. So, we need to explore new other techniques.\n",
    "\n",
    "As, we already have tried the **StratifiedKFold**, we need to now explore other sampling algorithms, that can allow our model to learn better. One solution to this problem could be using *Majority Under-Sampling, Minority Over-Sampling*. The way we can implement this is by **SMOTE**, which stands for Synthetic Minority Over-sampling Technique. The following code snippet will implement SMOTE from scratch (to understand the algorithm better, though a library called imblearn is also available). \n",
    "\n",
    "This algorithm is attributed to [this post](https://medium.com/@breya.heysoftware/synthetic-minority-over-sampling-technique-smote-from-scratch-e1167f788434):-\n",
    "- Identify the feature vector and its nearest neighbour\n",
    "- Take the difference between the two\n",
    "- Multiply the difference with a random number between 0 and 1\n",
    "- Identify a new point on the line segment by adding the random number to feature vector\n",
    "- Repeat the process for identified feature vector\n",
    "\n",
    "**NOTE** - for the best performance of the SMOTE, the data should be normalized. As I used XGBoost algorithm, I didn't scaled the data. That's because, tree based algorithm are immune to scale of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_neighbors(x_trainset):\n",
    "    \"\"\"\n",
    "    inp: trainset without labels\n",
    "    outp: indices for nearest neighbors\n",
    "    \"\"\"\n",
    "    neighbors = NearestNeighbors(n_neighbors = 5, metric = \"euclidean\", algorithm = \"kd_tree\").fit(x_trainset)\n",
    "    euclidean, indices = neighbors.kneighbors(x_trainset)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote(minclass_arr):\n",
    "    \"\"\"\n",
    "    implements SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "    \n",
    "    inp: trainset without labels,\n",
    "         minority class array\n",
    "    outp: matrix\n",
    "    \"\"\"\n",
    "    # get indices from n_neighbors function defined earlier\n",
    "    indices = n_neighbors(minclass_arr)\n",
    "    matrix = []\n",
    "    for m in range(0, len(indices)):\n",
    "        temp = minclass_arr[indices[m]]\n",
    "        temp = pd.DataFrame(temp)\n",
    "        matrix.append([])\n",
    "        for j in range(0, len(temp.columns)):\n",
    "            matrix[m].append(random.choice(temp[j]))\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train_oversampled = (198699, 27) ... y_train_oversampled = (198699, 1)\n"
     ]
    }
   ],
   "source": [
    "# getting minority classes instances in the trainset\n",
    "unique, counts = np.unique(y_train, return_counts = True)\n",
    "\n",
    "# Create a minority_shape variable which contains the dimension of the minority class\n",
    "minority_shape = dict(zip(unique, counts))[1]\n",
    "\n",
    "# storing minority class instances seperately\n",
    "minclass_arr = np.ones((minority_shape, x_train_scaled.shape[1]))\n",
    "minclass_arr = [x_train.iloc[i] for i, v in enumerate(y_train) if v == 1.0]\n",
    "minclass_arr = np.array(minclass_arr)\n",
    "\n",
    "# apply SMOTE\n",
    "sampled_instances = smote(minclass_arr)\n",
    "\n",
    "# Keeping the artificial instances and original instances together\n",
    "x_train_oversampled = np.concatenate((x_train_scaled, sampled_instances), axis = 0)\n",
    "y_sampled_instances = np.ones(minority_shape)\n",
    "y_train_oversampled = np.concatenate((y_train, y_sampled_instances), axis=0)\n",
    "\n",
    "x_train_oversampled = pd.DataFrame(x_train_oversampled)\n",
    "y_train_oversampled = pd.DataFrame(y_train_oversampled)\n",
    "x_train_oversampled.columns = cols \n",
    "\n",
    "print(\"Shape of x_train_oversampled = {} ... y_train_oversampled = {}\".format(x_train_oversampled.shape, y_train_oversampled.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45268     2]\n",
      " [ 2246     5]]\n"
     ]
    }
   ],
   "source": [
    "# final chosen parameter\n",
    "params = {'max_depth': 7, \n",
    "          'gamma': '0.186', \n",
    "          'subsample': '0.70', \n",
    "          'reg_alpha': '0.015', \n",
    "          'reg_lambda': '0.036', \n",
    "          'learning_rate': '0.045', \n",
    "          'num_leaves': '110.000', \n",
    "          'colsample_bytree': '0.558', \n",
    "          'min_child_samples': '160.000', \n",
    "          'feature_fraction': '0.574', \n",
    "          'bagging_fraction': '0.745', \n",
    "          'objective': 'binary:logistic', \n",
    "          'eval_metric': 'error'}\n",
    "\n",
    "# define the classifier\n",
    "xgb_clf = xgb.XGBClassifier(random_state = 42, \n",
    "                            verbose = True, \n",
    "                            tree_method = \"gpu_hist\",\n",
    "                            **params)\n",
    "\n",
    "# fit the classifier\n",
    "xgb_clf.fit(x_train_oversampled, y_train_oversampled)\n",
    "\n",
    "# predict with the trained classifier\n",
    "x_test_scaled = train_scaler.transform(x_test)\n",
    "x_test_scaled = pd.DataFrame(x_test_scaled)\n",
    "x_test_scaled.columns = cols\n",
    "preds = xgb_clf.predict(x_test_scaled)\n",
    "\n",
    "# printing the confusion matrix\n",
    "con_mat = confusion_matrix(y_test.values, preds)\n",
    "print(con_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
